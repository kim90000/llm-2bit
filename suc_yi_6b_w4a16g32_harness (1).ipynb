{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc03e98a407d48318bc5ec0e1cf5e6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754081607a03497aa0c3d9ef9c81f4d0",
              "IPY_MODEL_d1a513a61c2d4f168fd3b6237729653c",
              "IPY_MODEL_0066f4ff31f84323be82ffcda2d4bfa3"
            ],
            "layout": "IPY_MODEL_3abba4a469004a61a6c92237869672d9"
          }
        },
        "754081607a03497aa0c3d9ef9c81f4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fccfcf095b435e981692d144958fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_19dae95fde484c23a0a69cd8d51861fb",
            "value": "config.json: 100%"
          }
        },
        "d1a513a61c2d4f168fd3b6237729653c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a667e3880ddc41069437a448f48b4442",
            "max": 605,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa18803627c343988641f4fbd2c6369a",
            "value": 605
          }
        },
        "0066f4ff31f84323be82ffcda2d4bfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6915fc9b597c444187ed946277f100ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0512b923eb824d6bab4d500cd49b33dc",
            "value": " 605/605 [00:00&lt;00:00, 37.2kB/s]"
          }
        },
        "3abba4a469004a61a6c92237869672d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fccfcf095b435e981692d144958fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dae95fde484c23a0a69cd8d51861fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a667e3880ddc41069437a448f48b4442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa18803627c343988641f4fbd2c6369a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6915fc9b597c444187ed946277f100ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0512b923eb824d6bab4d500cd49b33dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0888e48296234b91a246dce7d46aebf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39f6290e51724e4cad56f41aec51cbe5",
              "IPY_MODEL_26a9d2af5a1f4292b60beaa70dbf91ac",
              "IPY_MODEL_ca7fe9ef63754b5bb47d42652c55569e"
            ],
            "layout": "IPY_MODEL_675349ec358d46139e362c3593351fec"
          }
        },
        "39f6290e51724e4cad56f41aec51cbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6ebd9a6d86a4f66a6e475192152f9ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e397b55e0b5748d8b45d307f30b1389b",
            "value": "model.safetensors: 100%"
          }
        },
        "26a9d2af5a1f4292b60beaa70dbf91ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53d360c6185940beab39193dd221603d",
            "max": 4038366080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50003a057322494991ec187521a32b40",
            "value": 4038366080
          }
        },
        "ca7fe9ef63754b5bb47d42652c55569e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378973a7274c483db81b908d64c9a180",
            "placeholder": "​",
            "style": "IPY_MODEL_8cf966dee5ac467985ef1c2a4a01caf4",
            "value": " 4.04G/4.04G [00:40&lt;00:00, 71.0MB/s]"
          }
        },
        "675349ec358d46139e362c3593351fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ebd9a6d86a4f66a6e475192152f9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e397b55e0b5748d8b45d307f30b1389b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53d360c6185940beab39193dd221603d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50003a057322494991ec187521a32b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "378973a7274c483db81b908d64c9a180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf966dee5ac467985ef1c2a4a01caf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f556fc80944bc5a6f4b78d647e3ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2a715f6da4344ee952e3413c0955738",
              "IPY_MODEL_c7e7f065478c488fb1def2902a7a82db",
              "IPY_MODEL_05815fd2725e4427abf8afda12b5de26"
            ],
            "layout": "IPY_MODEL_c5f5f94c1a6f433c82614811596218d1"
          }
        },
        "b2a715f6da4344ee952e3413c0955738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31a80d9b4984f53bf77ec210971c349",
            "placeholder": "​",
            "style": "IPY_MODEL_09d6018fd5de4ec990ee56a4bdbec5ca",
            "value": "generation_config.json: 100%"
          }
        },
        "c7e7f065478c488fb1def2902a7a82db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b36142028a48ff8a3e422db7123af6",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c941c1b379624037b6eddfb5b74d1eb9",
            "value": 132
          }
        },
        "05815fd2725e4427abf8afda12b5de26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85216b6a8b3445a7916fd19ec0f7f73d",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2fd9a23b254679ae7f68790e6bde3f",
            "value": " 132/132 [00:00&lt;00:00, 7.29kB/s]"
          }
        },
        "c5f5f94c1a6f433c82614811596218d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31a80d9b4984f53bf77ec210971c349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d6018fd5de4ec990ee56a4bdbec5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b36142028a48ff8a3e422db7123af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c941c1b379624037b6eddfb5b74d1eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85216b6a8b3445a7916fd19ec0f7f73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2fd9a23b254679ae7f68790e6bde3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b1109cca2694ea1a0f940ba0d6fd15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa74b14252148a9a2cfdc50cbbe6c6a",
              "IPY_MODEL_1ef3bbc40d3b4032a05d9ec9f3433c1c",
              "IPY_MODEL_7ff3a55d8d834a618cee8039e4eb633e"
            ],
            "layout": "IPY_MODEL_3c5f37b0c4a9419eb049130def0d1999"
          }
        },
        "2aa74b14252148a9a2cfdc50cbbe6c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6f61bdb40744bf8c613dc5ca45f445",
            "placeholder": "​",
            "style": "IPY_MODEL_642b29f7a477410f980bb92da9f8fe3c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1ef3bbc40d3b4032a05d9ec9f3433c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32e6f7033054029a96afd6858dc8783",
            "max": 320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97516306277848a5b584c30557f458ea",
            "value": 320
          }
        },
        "7ff3a55d8d834a618cee8039e4eb633e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f12e1076524f95a79a1a9951994f66",
            "placeholder": "​",
            "style": "IPY_MODEL_d4896203e2ca4933877779c3ff059a7c",
            "value": " 320/320 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "3c5f37b0c4a9419eb049130def0d1999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6f61bdb40744bf8c613dc5ca45f445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642b29f7a477410f980bb92da9f8fe3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32e6f7033054029a96afd6858dc8783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97516306277848a5b584c30557f458ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83f12e1076524f95a79a1a9951994f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4896203e2ca4933877779c3ff059a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70f1ef0b8874f90bf2454c985fc58d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_473a533cc9a242bea8d3effde9b3352c",
              "IPY_MODEL_f93abe8039264faaa8dac0e0039d4827",
              "IPY_MODEL_f75a50051ab64aed9c32dd07ece53a95"
            ],
            "layout": "IPY_MODEL_8e704ce0a82a41a9a9310d74a6b63fac"
          }
        },
        "473a533cc9a242bea8d3effde9b3352c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48cfef7ad62a440b92becae1a38a5180",
            "placeholder": "​",
            "style": "IPY_MODEL_a7943bbfbbef4520935e9652a3285e42",
            "value": "tokenizer.model: 100%"
          }
        },
        "f93abe8039264faaa8dac0e0039d4827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7494d083d7840b998dd0882914e1a86",
            "max": 1033105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d8b890e4fea407592d6a6947bb6e5a2",
            "value": 1033105
          }
        },
        "f75a50051ab64aed9c32dd07ece53a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028b508b46df4221b363d1a396ef29be",
            "placeholder": "​",
            "style": "IPY_MODEL_28afd464d6b3401e988b2e4573069492",
            "value": " 1.03M/1.03M [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "8e704ce0a82a41a9a9310d74a6b63fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cfef7ad62a440b92becae1a38a5180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7943bbfbbef4520935e9652a3285e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7494d083d7840b998dd0882914e1a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8b890e4fea407592d6a6947bb6e5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "028b508b46df4221b363d1a396ef29be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28afd464d6b3401e988b2e4573069492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4feb2080a3b04dc997c7ad8b8b68181a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7080442979a49e99698ec7d210b4b3a",
              "IPY_MODEL_c36e3db4c217450ab878b7da95ca4c3b",
              "IPY_MODEL_eb59e9483c824677895c3a7d5eeb3fd9"
            ],
            "layout": "IPY_MODEL_5a43c1baa16a4da8b38e71f30d348aab"
          }
        },
        "d7080442979a49e99698ec7d210b4b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1e648cca0947aead3c84e2f50d1b27",
            "placeholder": "​",
            "style": "IPY_MODEL_df5a5c19a1e54d15bfd171609578da69",
            "value": "tokenizer.json: 100%"
          }
        },
        "c36e3db4c217450ab878b7da95ca4c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb32232bb050483a8d212150b361936b",
            "max": 3560486,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d8642a23fcb48cfa4d1de9566cd0d63",
            "value": 3560486
          }
        },
        "eb59e9483c824677895c3a7d5eeb3fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6204b4f98834edfa5ad7ade0fec9353",
            "placeholder": "​",
            "style": "IPY_MODEL_933d627d4d364b6eb2f4d7df46f02d7a",
            "value": " 3.56M/3.56M [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "5a43c1baa16a4da8b38e71f30d348aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1e648cca0947aead3c84e2f50d1b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5a5c19a1e54d15bfd171609578da69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb32232bb050483a8d212150b361936b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8642a23fcb48cfa4d1de9566cd0d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6204b4f98834edfa5ad7ade0fec9353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933d627d4d364b6eb2f4d7df46f02d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "yhgشغال"
      ],
      "metadata": {
        "id": "mGPnrpYMxuba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UYlvgo61xuRC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mKxn6cOxbhE",
        "outputId": "35607f33-d75d-45e0-883a-410544bb02ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/low_bit_llama'...\n",
            "remote: Enumerating objects: 593, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (358/358), done.\u001b[K\n",
            "remote: Total 593 (delta 198), reused 390 (delta 124), pack-reused 108 (from 1)\u001b[K\n",
            "Receiving objects: 100% (593/593), 472.68 KiB | 1.82 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n",
            "From https://github.com/GreenBitAI/low_bit_llama\n",
            " * branch            low_bit_yi -> FETCH_HEAD\n",
            "Branch 'low_bit_yi' set up to track remote branch 'low_bit_yi' from 'origin'.\n",
            "Switched to a new branch 'low_bit_yi'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/GreenBitAI/low_bit_llama.git /content/low_bit_llama\n",
        "!cd /content/low_bit_llama && git fetch origin low_bit_yi\n",
        "!cd /content/low_bit_llama && git checkout low_bit_yi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsvtBjmRyp6b",
        "outputId": "cefb595d-1907-4b49-c429-3a56d61fe573"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-n8b_75fm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-n8b_75fm\n",
            "  Resolved https://github.com/huggingface/transformers to commit 69bc848480d5f19a537a70ce14f09816b00cd80f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git@70af02a2bca5a63921790036b2c9430edf4037e2 (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision 70af02a2bca5a63921790036b2c9430edf4037e2) to /tmp/pip-req-build-_ylg_8e6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-_ylg_8e6\n",
            "  Running command git rev-parse -q --verify 'sha^70af02a2bca5a63921790036b2c9430edf4037e2'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Running command git checkout -q 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting colorama (from -r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (4.67.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.17.0)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m850.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, peft\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10937642 sha256=e0f6cfccd4ad69d7550434f9842dafbbb255dd8c74d0ef112babe22f1850528a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u2bsgrfp/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=50434 sha256=5d7804a292b69547653b665bf899a70130d90e2b0086ae39ee78afd46b64a385\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/f8/88/d6b4d21588d8de0a84ab14903a4bbe0f7fe02f0f74f0a3c3ea\n",
            "Successfully built transformers peft\n",
            "Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, colorama, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed colorama-0.4.6 datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.3.0.dev0 transformers-4.50.0.dev0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token XXXXXXXXXXXXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PahZQlZ3zYs",
        "outputId": "00f4dd48-3aa4-45b6-a4ce-9d35e436325b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ayشغال"
      ],
      "metadata": {
        "id": "VUst6WSt4Re0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wjCvS-et4RdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash scripts/harness/yi_6b_w4a16g32_harness.sh --trust_remote_code=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APTn8nw2xgSU",
        "outputId": "c1f66e0a-a1d1-4e47-d90c-e44689845d5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-13 23:51:18.656961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741909878.677145    7182 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741909878.683488    7182 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-13 23:51:18.704742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 7.35 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mstart harness evaluation\u001b[0m\n",
            "\u001b[0mSelected Tasks: ['winogrande', 'arc_challenge', 'piqa', 'anli_r2', 'anli_r3', 'wic', 'rte', 'anli_r1', 'boolq', 'openbookqa', 'arc_easy', 'race', 'record', 'hellaswag', 'truthfulqa_mc']\u001b[0m\n",
            "README.md: 100% 9.97k/9.97k [00:00<00:00, 11.4MB/s]\u001b[0m\n",
            "winogrande.py: 100% 5.65k/5.65k [00:00<00:00, 27.8MB/s]\u001b[0m\n",
            "\u001b[0mThe repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] \u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 55, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mt_results = evaluator.simple_evaluate(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/utils.py\", line 160, in _wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/evaluator.py\", line 66, in simple_evaluate\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_dict = lm_eval.tasks.get_task_dict(task_names)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 342, in get_task_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name_dict = {\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 343, in <dictcomp>\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name: get_task(task_name)()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 412, in __init__\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.download(data_dir, cache_dir, download_mode)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 441, in download\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.dataset = datasets.load_dataset(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2129, in load_dataset\n",
            "\u001b[0m\u001b[0m    \u001b[0mbuilder_instance = load_dataset_builder(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1849, in load_dataset_builder\n",
            "\u001b[0m\u001b[0m    \u001b[0mdataset_module = dataset_module_factory(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1731, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise e1 from None\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1681, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0m).get_module()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1331, in get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mtrust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise ValueError(\u001b[0m\n",
            "\u001b[0m\u001b[0mValueError\u001b[0m: \u001b[0mThe repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande.\n",
            "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade torch torchvision torchaudio"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "uCgM5-568e32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SAM3QyN8haV",
        "outputId": "fb788a83-3c5e-4698-c1a0-9d795ea98767"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash /content/low_bit_llama/scripts/harness/yi_6b_w2a16g32_harness.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpgWowCvx2RK",
        "outputId": "554a7b5f-6cd4-41c2-e520-84b6f4bc19ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-13 23:38:53.860145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741909133.882169    4095 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741909133.888401    4095 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-13 23:38:53.911356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 406, in hf_raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mresponse.raise_for_status()\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise HTTPError(http_error_msg, response=self)\u001b[0m\n",
            "\u001b[0m\u001b[0mrequests.exceptions\u001b[0m.\u001b[0mHTTPError\u001b[0m: \u001b[0m404 Client Error: Not Found for url: https://huggingface.co/GreenBitAI/yi-6b-w2a16g32/resolve/main/config.json\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 424, in cached_files\n",
            "\u001b[0m\u001b[0m    \u001b[0mhf_hub_download(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn _hf_hub_download_to_cache_dir(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 967, in _hf_hub_download_to_cache_dir\n",
            "\u001b[0m\u001b[0m    \u001b[0m_raise_on_head_call_error(head_call_error, force_download, local_files_only)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1482, in _raise_on_head_call_error\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise head_call_error\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1374, in _get_metadata_or_catch_error\n",
            "\u001b[0m\u001b[0m    \u001b[0mmetadata = get_hf_file_metadata(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1294, in get_hf_file_metadata\n",
            "\u001b[0m\u001b[0m    \u001b[0mr = _request_wrapper(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 278, in _request_wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mresponse = _request_wrapper(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 302, in _request_wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mhf_raise_for_status(response)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 454, in hf_raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise _format(RepositoryNotFoundError, message, response) from e\u001b[0m\n",
            "\u001b[0m\u001b[0mhuggingface_hub.errors\u001b[0m.\u001b[0mRepositoryNotFoundError\u001b[0m: \u001b[0m404 Client Error. (Request ID: Root=1-67d36c91-737b91f739dc827d3faeb4d7;c0d47e50-6f8b-4307-8ff9-5eb29a38355d)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/GreenBitAI/yi-6b-w2a16g32/resolve/main/config.json.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 41, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer, config = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=bits, half=True, v1=v1, asym=asym, kquant=kquant, return_config=return_config)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 149, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig = AutoConfig.from_pretrained(model_uri, cache_dir=cache_dir)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1090, in from_pretrained\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 594, in get_config_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 653, in _get_config_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mresolved_config_file = cached_file(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 266, in cached_file\n",
            "\u001b[0m\u001b[0m    \u001b[0mfile = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 456, in cached_files\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise EnvironmentError(\u001b[0m\n",
            "\u001b[0m\u001b[0mOSError\u001b[0m: \u001b[0mGreenBitAI/yi-6b-w2a16g32 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycountry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FM3b64szrnq",
        "outputId": "3bfec4fe-76ba-493b-a15c-c4c78ee3cbf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycountry\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/6.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m5.5/6.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycountry\n",
            "Successfully installed pycountry-24.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score sacrebleu sqlitedict omegaconf pycountry"
      ],
      "metadata": {
        "id": "WhLNYxfX282E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxD72RCNzwop",
        "outputId": "cec37db7-20b2-430b-fcf5-bab004cc083f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                            Version\n",
            "---------------------------------- -------------------\n",
            "absl-py                            1.4.0\n",
            "accelerate                         1.3.0\n",
            "aiohappyeyeballs                   2.5.0\n",
            "aiohttp                            3.11.13\n",
            "aiosignal                          1.3.2\n",
            "alabaster                          1.0.0\n",
            "albucore                           0.0.23\n",
            "albumentations                     2.0.5\n",
            "ale-py                             0.10.2\n",
            "altair                             5.5.0\n",
            "annotated-types                    0.7.0\n",
            "antlr4-python3-runtime             4.9.3\n",
            "anyio                              3.7.1\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "array_record                       0.6.0\n",
            "arviz                              0.20.0\n",
            "astropy                            7.0.1\n",
            "astropy-iers-data                  0.2025.3.10.0.29.26\n",
            "astunparse                         1.6.3\n",
            "atpublic                           4.1.0\n",
            "attrs                              25.1.0\n",
            "audioread                          3.0.1\n",
            "autograd                           1.7.0\n",
            "babel                              2.17.0\n",
            "backcall                           0.2.0\n",
            "beautifulsoup4                     4.13.3\n",
            "betterproto                        2.0.0b6\n",
            "bigframes                          1.38.0\n",
            "bigquery-magics                    0.6.0\n",
            "bleach                             6.2.0\n",
            "blinker                            1.9.0\n",
            "blis                               0.7.11\n",
            "blosc2                             3.2.0\n",
            "bokeh                              3.6.3\n",
            "Bottleneck                         1.4.2\n",
            "bqplot                             0.12.44\n",
            "branca                             0.8.1\n",
            "CacheControl                       0.14.2\n",
            "cachetools                         5.5.2\n",
            "catalogue                          2.0.10\n",
            "certifi                            2025.1.31\n",
            "cffi                               1.17.1\n",
            "chardet                            5.2.0\n",
            "charset-normalizer                 3.4.1\n",
            "chex                               0.1.89\n",
            "clarabel                           0.10.0\n",
            "click                              8.1.8\n",
            "cloudpathlib                       0.21.0\n",
            "cloudpickle                        3.1.1\n",
            "cmake                              3.31.6\n",
            "cmdstanpy                          1.2.5\n",
            "colorama                           0.4.6\n",
            "colorcet                           3.1.0\n",
            "colorlover                         0.3.0\n",
            "colour                             0.1.5\n",
            "community                          1.0.0b1\n",
            "confection                         0.1.5\n",
            "cons                               0.4.6\n",
            "contourpy                          1.3.1\n",
            "cramjam                            2.9.1\n",
            "cryptography                       43.0.3\n",
            "cuda-python                        12.6.2.post1\n",
            "cudf-cu12                          25.2.1\n",
            "cudf-polars-cu12                   25.2.2\n",
            "cufflinks                          0.17.3\n",
            "cuml-cu12                          25.2.1\n",
            "cupy-cuda12x                       13.3.0\n",
            "cuvs-cu12                          25.2.1\n",
            "cvxopt                             1.3.2\n",
            "cvxpy                              1.6.3\n",
            "cycler                             0.12.1\n",
            "cyipopt                            1.5.0\n",
            "cymem                              2.0.11\n",
            "Cython                             3.0.12\n",
            "dask                               2024.12.1\n",
            "dask-cuda                          25.2.0\n",
            "dask-cudf-cu12                     25.2.2\n",
            "dask-expr                          1.1.21\n",
            "datascience                        0.17.6\n",
            "datasets                           3.3.2\n",
            "db-dtypes                          1.4.2\n",
            "dbus-python                        1.2.18\n",
            "debugpy                            1.8.0\n",
            "decorator                          4.4.2\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.18\n",
            "diffusers                          0.32.2\n",
            "dill                               0.3.8\n",
            "distributed                        2024.12.1\n",
            "distributed-ucxx-cu12              0.42.0\n",
            "distro                             1.9.0\n",
            "dlib                               19.24.2\n",
            "dm-tree                            0.1.9\n",
            "docker-pycreds                     0.4.0\n",
            "docstring_parser                   0.16\n",
            "docutils                           0.21.2\n",
            "dopamine_rl                        4.1.2\n",
            "duckdb                             1.1.3\n",
            "earthengine-api                    1.5.6\n",
            "easydict                           1.13\n",
            "editdistance                       0.8.1\n",
            "eerepr                             0.1.1\n",
            "einops                             0.8.1\n",
            "en-core-web-sm                     3.7.1\n",
            "entrypoints                        0.4\n",
            "et_xmlfile                         2.0.0\n",
            "etils                              1.12.2\n",
            "etuples                            0.3.9\n",
            "Farama-Notifications               0.0.4\n",
            "fastai                             2.7.18\n",
            "fastcore                           1.7.29\n",
            "fastdownload                       0.0.7\n",
            "fastjsonschema                     2.21.1\n",
            "fastprogress                       1.0.3\n",
            "fastrlock                          0.8.3\n",
            "filelock                           3.17.0\n",
            "firebase-admin                     6.6.0\n",
            "Flask                              3.1.0\n",
            "flatbuffers                        25.2.10\n",
            "flax                               0.10.4\n",
            "folium                             0.19.5\n",
            "fonttools                          4.56.0\n",
            "frozendict                         2.4.6\n",
            "frozenlist                         1.5.0\n",
            "fsspec                             2024.10.0\n",
            "future                             1.0.0\n",
            "gast                               0.6.0\n",
            "gcsfs                              2024.10.0\n",
            "GDAL                               3.6.4\n",
            "gdown                              5.2.0\n",
            "geemap                             0.35.3\n",
            "geocoder                           1.38.1\n",
            "geographiclib                      2.0\n",
            "geopandas                          1.0.1\n",
            "geopy                              2.4.1\n",
            "gin-config                         0.5.0\n",
            "gitdb                              4.0.12\n",
            "GitPython                          3.1.44\n",
            "glob2                              0.7\n",
            "google                             2.0.3\n",
            "google-ai-generativelanguage       0.6.15\n",
            "google-api-core                    2.24.2\n",
            "google-api-python-client           2.160.0\n",
            "google-auth                        2.38.0\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.1\n",
            "google-cloud-aiplatform            1.79.0\n",
            "google-cloud-bigquery              3.29.0\n",
            "google-cloud-bigquery-connection   1.18.1\n",
            "google-cloud-bigquery-storage      2.28.0\n",
            "google-cloud-bigtable              2.29.0\n",
            "google-cloud-core                  2.4.3\n",
            "google-cloud-dataproc              5.18.0\n",
            "google-cloud-datastore             2.20.2\n",
            "google-cloud-firestore             2.20.1\n",
            "google-cloud-functions             1.19.0\n",
            "google-cloud-iam                   2.18.1\n",
            "google-cloud-language              2.16.0\n",
            "google-cloud-pubsub                2.25.0\n",
            "google-cloud-resource-manager      1.14.1\n",
            "google-cloud-spanner               3.52.0\n",
            "google-cloud-storage               2.19.0\n",
            "google-cloud-translate             3.19.0\n",
            "google-colab                       1.0.0\n",
            "google-crc32c                      1.6.0\n",
            "google-genai                       1.4.0\n",
            "google-generativeai                0.8.4\n",
            "google-pasta                       0.2.0\n",
            "google-resumable-media             2.7.2\n",
            "google-spark-connect               0.5.4\n",
            "googleapis-common-protos           1.69.1\n",
            "googledrivedownloader              1.1.0\n",
            "graphviz                           0.20.3\n",
            "greenlet                           3.1.1\n",
            "grpc-google-iam-v1                 0.14.1\n",
            "grpc-interceptor                   0.15.4\n",
            "grpcio                             1.71.0\n",
            "grpcio-status                      1.62.3\n",
            "grpclib                            0.4.7\n",
            "gspread                            6.1.4\n",
            "gspread-dataframe                  4.0.0\n",
            "gym                                0.25.2\n",
            "gym-notices                        0.0.8\n",
            "gymnasium                          1.1.1\n",
            "h11                                0.14.0\n",
            "h2                                 4.2.0\n",
            "h5netcdf                           1.6.1\n",
            "h5py                               3.12.1\n",
            "hdbscan                            0.8.40\n",
            "highspy                            1.9.0\n",
            "holidays                           0.68\n",
            "holoviews                          1.20.1\n",
            "hpack                              4.1.0\n",
            "html5lib                           1.1\n",
            "httpcore                           1.0.7\n",
            "httpimport                         1.4.1\n",
            "httplib2                           0.22.0\n",
            "httpx                              0.28.1\n",
            "huggingface-hub                    0.28.1\n",
            "humanize                           4.11.0\n",
            "hyperframe                         6.1.0\n",
            "hyperopt                           0.2.7\n",
            "ibis-framework                     9.2.0\n",
            "idna                               3.10\n",
            "imageio                            2.37.0\n",
            "imageio-ffmpeg                     0.6.0\n",
            "imagesize                          1.4.1\n",
            "imbalanced-learn                   0.13.0\n",
            "imgaug                             0.4.0\n",
            "immutabledict                      4.2.1\n",
            "importlib_metadata                 8.6.1\n",
            "importlib_resources                6.5.2\n",
            "imutils                            0.5.4\n",
            "inflect                            7.5.0\n",
            "iniconfig                          2.0.0\n",
            "intel-cmplr-lib-ur                 2025.0.5\n",
            "intel-openmp                       2025.0.5\n",
            "ipyevents                          2.0.2\n",
            "ipyfilechooser                     0.6.0\n",
            "ipykernel                          6.17.1\n",
            "ipyleaflet                         0.19.2\n",
            "ipyparallel                        8.8.0\n",
            "ipython                            7.34.0\n",
            "ipython-genutils                   0.2.0\n",
            "ipython-sql                        0.5.0\n",
            "ipytree                            0.2.2\n",
            "ipywidgets                         7.7.1\n",
            "itsdangerous                       2.2.0\n",
            "jax                                0.5.2\n",
            "jax-cuda12-pjrt                    0.5.1\n",
            "jax-cuda12-plugin                  0.5.1\n",
            "jaxlib                             0.5.1\n",
            "jeepney                            0.7.1\n",
            "jellyfish                          1.1.0\n",
            "jieba                              0.42.1\n",
            "Jinja2                             3.1.6\n",
            "jiter                              0.9.0\n",
            "joblib                             1.4.2\n",
            "jsonpatch                          1.33\n",
            "jsonpickle                         4.0.2\n",
            "jsonpointer                        3.0.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2024.10.1\n",
            "jupyter-client                     6.1.12\n",
            "jupyter-console                    6.1.0\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-leaflet                    0.19.2\n",
            "jupyter-server                     1.24.0\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_widgets                 3.0.13\n",
            "kaggle                             1.6.17\n",
            "kagglehub                          0.3.10\n",
            "keras                              3.8.0\n",
            "keras-hub                          0.18.1\n",
            "keras-nlp                          0.18.1\n",
            "keyring                            23.5.0\n",
            "kiwisolver                         1.4.8\n",
            "langchain                          0.3.20\n",
            "langchain-core                     0.3.43\n",
            "langchain-text-splitters           0.3.6\n",
            "langcodes                          3.5.0\n",
            "langsmith                          0.3.13\n",
            "language_data                      1.3.0\n",
            "launchpadlib                       1.10.16\n",
            "lazr.restfulclient                 0.14.4\n",
            "lazr.uri                           1.0.6\n",
            "lazy_loader                        0.4\n",
            "libclang                           18.1.1\n",
            "libcudf-cu12                       25.2.1\n",
            "libcugraph-cu12                    25.2.0\n",
            "libcuml-cu12                       25.2.1\n",
            "libcuvs-cu12                       25.2.1\n",
            "libkvikio-cu12                     25.2.1\n",
            "libraft-cu12                       25.2.0\n",
            "librosa                            0.10.2.post1\n",
            "libucx-cu12                        1.18.0\n",
            "libucxx-cu12                       0.42.0\n",
            "lightgbm                           4.5.0\n",
            "linkify-it-py                      2.0.3\n",
            "llvmlite                           0.43.0\n",
            "locket                             1.0.0\n",
            "logical-unification                0.4.6\n",
            "lxml                               5.3.1\n",
            "marisa-trie                        1.2.1\n",
            "Markdown                           3.7\n",
            "markdown-it-py                     3.0.0\n",
            "MarkupSafe                         3.0.2\n",
            "matplotlib                         3.10.0\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.2\n",
            "mdit-py-plugins                    0.4.2\n",
            "mdurl                              0.1.2\n",
            "miniKanren                         1.0.3\n",
            "missingno                          0.5.2\n",
            "mistune                            3.1.2\n",
            "mizani                             0.13.1\n",
            "mkl                                2025.0.1\n",
            "ml-dtypes                          0.4.1\n",
            "mlxtend                            0.23.4\n",
            "more-itertools                     10.6.0\n",
            "moviepy                            1.0.3\n",
            "mpmath                             1.3.0\n",
            "msgpack                            1.1.0\n",
            "multidict                          6.1.0\n",
            "multipledispatch                   1.0.0\n",
            "multiprocess                       0.70.16\n",
            "multitasking                       0.0.11\n",
            "murmurhash                         1.0.12\n",
            "music21                            9.3.0\n",
            "namex                              0.0.8\n",
            "narwhals                           1.30.0\n",
            "natsort                            8.4.0\n",
            "nbclassic                          1.2.0\n",
            "nbclient                           0.10.2\n",
            "nbconvert                          7.16.6\n",
            "nbformat                           5.10.4\n",
            "ndindex                            1.9.2\n",
            "nest-asyncio                       1.6.0\n",
            "networkx                           3.4.2\n",
            "nibabel                            5.3.2\n",
            "nltk                               3.9.1\n",
            "notebook                           6.5.5\n",
            "notebook_shim                      0.2.4\n",
            "numba                              0.60.0\n",
            "numba-cuda                         0.2.0\n",
            "numexpr                            2.10.2\n",
            "numpy                              1.26.4\n",
            "nvidia-cublas-cu12                 12.4.5.8\n",
            "nvidia-cuda-cupti-cu12             12.4.127\n",
            "nvidia-cuda-nvcc-cu12              12.5.82\n",
            "nvidia-cuda-nvrtc-cu12             12.4.127\n",
            "nvidia-cuda-runtime-cu12           12.4.127\n",
            "nvidia-cudnn-cu12                  9.1.0.70\n",
            "nvidia-cufft-cu12                  11.2.1.3\n",
            "nvidia-curand-cu12                 10.3.5.147\n",
            "nvidia-cusolver-cu12               11.6.1.9\n",
            "nvidia-cusparse-cu12               12.3.1.170\n",
            "nvidia-ml-py                       12.570.86\n",
            "nvidia-nccl-cu12                   2.21.5\n",
            "nvidia-nvcomp-cu12                 4.2.0.11\n",
            "nvidia-nvjitlink-cu12              12.4.127\n",
            "nvidia-nvtx-cu12                   12.4.127\n",
            "nvtx                               0.2.11\n",
            "nx-cugraph-cu12                    25.2.0\n",
            "oauth2client                       4.1.3\n",
            "oauthlib                           3.2.2\n",
            "omegaconf                          2.3.0\n",
            "openai                             1.61.1\n",
            "opencv-contrib-python              4.11.0.86\n",
            "opencv-python                      4.11.0.86\n",
            "opencv-python-headless             4.11.0.86\n",
            "openpyxl                           3.1.5\n",
            "opentelemetry-api                  1.16.0\n",
            "opentelemetry-sdk                  1.16.0\n",
            "opentelemetry-semantic-conventions 0.37b0\n",
            "opt_einsum                         3.4.0\n",
            "optax                              0.2.4\n",
            "optree                             0.14.1\n",
            "orbax-checkpoint                   0.11.8\n",
            "orjson                             3.10.15\n",
            "osqp                               0.6.7.post3\n",
            "packaging                          24.2\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.28.0\n",
            "pandas-stubs                       2.2.2.240909\n",
            "pandocfilters                      1.5.1\n",
            "panel                              1.6.1\n",
            "param                              2.2.0\n",
            "parso                              0.8.4\n",
            "parsy                              2.1\n",
            "partd                              1.4.2\n",
            "pathlib                            1.0.1\n",
            "patsy                              1.0.1\n",
            "peewee                             3.17.9\n",
            "peft                               0.3.0.dev0\n",
            "pexpect                            4.9.0\n",
            "pickleshare                        0.7.5\n",
            "pillow                             11.1.0\n",
            "pip                                24.1.2\n",
            "platformdirs                       4.3.6\n",
            "plotly                             5.24.1\n",
            "plotnine                           0.14.5\n",
            "pluggy                             1.5.0\n",
            "ply                                3.11\n",
            "polars                             1.21.0\n",
            "pooch                              1.8.2\n",
            "portalocker                        3.1.1\n",
            "portpicker                         1.5.2\n",
            "preshed                            3.0.9\n",
            "prettytable                        3.15.1\n",
            "proglog                            0.1.10\n",
            "progressbar2                       4.5.0\n",
            "prometheus_client                  0.21.1\n",
            "promise                            2.3\n",
            "prompt_toolkit                     3.0.50\n",
            "propcache                          0.3.0\n",
            "prophet                            1.1.6\n",
            "proto-plus                         1.26.1\n",
            "protobuf                           4.25.6\n",
            "psutil                             5.9.5\n",
            "psycopg2                           2.9.10\n",
            "ptyprocess                         0.7.0\n",
            "py-cpuinfo                         9.0.0\n",
            "py4j                               0.10.9.7\n",
            "pyarrow                            18.1.0\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.1\n",
            "pycocotools                        2.0.8\n",
            "pycountry                          24.6.1\n",
            "pycparser                          2.22\n",
            "pydantic                           2.10.6\n",
            "pydantic_core                      2.27.2\n",
            "pydata-google-auth                 1.9.1\n",
            "pydot                              3.0.4\n",
            "pydotplus                          2.0.2\n",
            "PyDrive                            1.3.1\n",
            "PyDrive2                           1.21.3\n",
            "pyerfa                             2.0.1.5\n",
            "pygame                             2.6.1\n",
            "pygit2                             1.17.0\n",
            "Pygments                           2.18.0\n",
            "PyGObject                          3.42.1\n",
            "PyJWT                              2.10.1\n",
            "pylibcudf-cu12                     25.2.1\n",
            "pylibcugraph-cu12                  25.2.0\n",
            "pylibraft-cu12                     25.2.0\n",
            "pymc                               5.20.1\n",
            "pymystem3                          0.2.0\n",
            "pynndescent                        0.5.13\n",
            "pynvjitlink-cu12                   0.5.2\n",
            "pynvml                             12.0.0\n",
            "pyogrio                            0.10.0\n",
            "Pyomo                              6.8.2\n",
            "PyOpenGL                           3.1.9\n",
            "pyOpenSSL                          24.2.1\n",
            "pyparsing                          3.2.1\n",
            "pyperclip                          1.9.0\n",
            "pyproj                             3.7.1\n",
            "pyshp                              2.3.1\n",
            "PySocks                            1.7.1\n",
            "pyspark                            3.5.5\n",
            "pytensor                           2.27.1\n",
            "pytest                             8.3.5\n",
            "python-apt                         0.0.0\n",
            "python-box                         7.3.2\n",
            "python-dateutil                    2.8.2\n",
            "python-louvain                     0.16\n",
            "python-slugify                     8.0.4\n",
            "python-snappy                      0.7.3\n",
            "python-utils                       3.9.1\n",
            "pytz                               2025.1\n",
            "pyviz_comms                        3.0.4\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              24.0.1\n",
            "qdldl                              0.1.7.post5\n",
            "raft-dask-cu12                     25.2.0\n",
            "rapids-dask-dependency             25.2.0\n",
            "ratelim                            0.1.6\n",
            "referencing                        0.36.2\n",
            "regex                              2024.11.6\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  2.0.0\n",
            "requests-toolbelt                  1.0.0\n",
            "requirements-parser                0.9.0\n",
            "rich                               13.9.4\n",
            "rmm-cu12                           25.2.0\n",
            "rouge_score                        0.1.2\n",
            "rpds-py                            0.23.1\n",
            "rpy2                               3.5.17\n",
            "rsa                                4.9\n",
            "sacrebleu                          2.5.1\n",
            "safetensors                        0.5.3\n",
            "scikit-image                       0.25.2\n",
            "scikit-learn                       1.6.1\n",
            "scipy                              1.14.1\n",
            "scooby                             0.10.0\n",
            "scs                                3.2.7.post2\n",
            "seaborn                            0.13.2\n",
            "SecretStorage                      3.3.1\n",
            "Send2Trash                         1.8.3\n",
            "sentence-transformers              3.4.1\n",
            "sentencepiece                      0.2.0\n",
            "sentry-sdk                         2.22.0\n",
            "setproctitle                       1.3.5\n",
            "setuptools                         75.1.0\n",
            "shap                               0.46.0\n",
            "shapely                            2.0.7\n",
            "shellingham                        1.5.4\n",
            "simple-parsing                     0.1.7\n",
            "simplejson                         3.20.1\n",
            "simsimd                            6.2.1\n",
            "six                                1.17.0\n",
            "sklearn-compat                     0.1.3\n",
            "sklearn-pandas                     2.2.0\n",
            "slicer                             0.0.8\n",
            "smart-open                         7.1.0\n",
            "smmap                              5.0.2\n",
            "sniffio                            1.3.1\n",
            "snowballstemmer                    2.2.0\n",
            "sortedcontainers                   2.4.0\n",
            "soundfile                          0.13.1\n",
            "soupsieve                          2.6\n",
            "soxr                               0.5.0.post1\n",
            "spacy                              3.7.5\n",
            "spacy-legacy                       3.0.12\n",
            "spacy-loggers                      1.0.5\n",
            "spanner-graph-notebook             1.1.3\n",
            "Sphinx                             8.1.3\n",
            "sphinxcontrib-applehelp            2.0.0\n",
            "sphinxcontrib-devhelp              2.0.0\n",
            "sphinxcontrib-htmlhelp             2.1.0\n",
            "sphinxcontrib-jsmath               1.0.1\n",
            "sphinxcontrib-qthelp               2.0.0\n",
            "sphinxcontrib-serializinghtml      2.0.0\n",
            "SQLAlchemy                         2.0.38\n",
            "sqlglot                            25.6.1\n",
            "sqlitedict                         2.1.0\n",
            "sqlparse                           0.5.3\n",
            "srsly                              2.5.1\n",
            "stanio                             0.5.1\n",
            "statsmodels                        0.14.4\n",
            "stringzilla                        3.12.3\n",
            "sympy                              1.13.1\n",
            "tables                             3.10.2\n",
            "tabulate                           0.9.0\n",
            "tbb                                2022.0.0\n",
            "tblib                              3.0.0\n",
            "tcmlib                             1.2.0\n",
            "tenacity                           9.0.0\n",
            "tensorboard                        2.18.0\n",
            "tensorboard-data-server            0.7.2\n",
            "tensorflow                         2.18.0\n",
            "tensorflow-datasets                4.9.7\n",
            "tensorflow-hub                     0.16.1\n",
            "tensorflow-io-gcs-filesystem       0.37.1\n",
            "tensorflow-metadata                1.16.1\n",
            "tensorflow-probability             0.25.0\n",
            "tensorflow-text                    2.18.1\n",
            "tensorstore                        0.1.72\n",
            "termcolor                          2.5.0\n",
            "terminado                          0.18.1\n",
            "text-unidecode                     1.3\n",
            "textblob                           0.19.0\n",
            "tf_keras                           2.18.0\n",
            "tf-slim                            1.1.0\n",
            "thinc                              8.2.5\n",
            "threadpoolctl                      3.5.0\n",
            "tifffile                           2025.2.18\n",
            "timm                               1.0.15\n",
            "tinycss2                           1.4.0\n",
            "tokenizers                         0.21.0\n",
            "toml                               0.10.2\n",
            "toolz                              0.12.1\n",
            "torch                              2.5.1+cu124\n",
            "torchaudio                         2.5.1+cu124\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.20.1+cu124\n",
            "tornado                            6.4.2\n",
            "tqdm                               4.67.1\n",
            "traitlets                          5.7.1\n",
            "traittypes                         0.2.1\n",
            "transformers                       4.50.0.dev0\n",
            "treelite                           4.4.1\n",
            "treescope                          0.1.9\n",
            "triton                             3.1.0\n",
            "tweepy                             4.15.0\n",
            "typeguard                          4.4.2\n",
            "typer                              0.15.2\n",
            "types-pytz                         2025.1.0.20250204\n",
            "types-setuptools                   75.8.2.20250305\n",
            "typing_extensions                  4.12.2\n",
            "tzdata                             2025.1\n",
            "tzlocal                            5.3.1\n",
            "uc-micro-py                        1.0.3\n",
            "ucx-py-cu12                        0.42.0\n",
            "ucxx-cu12                          0.42.0\n",
            "umap-learn                         0.5.7\n",
            "umf                                0.9.1\n",
            "uritemplate                        4.1.1\n",
            "urllib3                            2.3.0\n",
            "vega-datasets                      0.9.0\n",
            "wadllib                            1.3.6\n",
            "wandb                              0.19.8\n",
            "wasabi                             1.1.3\n",
            "wcwidth                            0.2.13\n",
            "weasel                             0.4.1\n",
            "webcolors                          24.11.1\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "websockets                         14.2\n",
            "Werkzeug                           3.1.3\n",
            "wheel                              0.45.1\n",
            "widgetsnbextension                 3.6.10\n",
            "wordcloud                          1.9.4\n",
            "wrapt                              1.17.2\n",
            "xarray                             2025.1.2\n",
            "xarray-einstats                    0.8.0\n",
            "xgboost                            2.1.4\n",
            "xlrd                               2.0.1\n",
            "xxhash                             3.5.0\n",
            "xyzservices                        2025.1.0\n",
            "yarl                               1.18.3\n",
            "yellowbrick                        1.5\n",
            "yfinance                           0.2.54\n",
            "zict                               3.0.0\n",
            "zipp                               3.21.0\n",
            "zstandard                          0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash /content/low_bit_llama/scripts/harness/yi_6b_w2a16g32_harness.sh"
      ],
      "metadata": {
        "id": "0ttECQ1R1Jl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOqn4qp38qeF",
        "outputId": "d8a448f3-b2f1-429a-9a00-624ef31869c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 00:00:08.092503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741910408.113439    9539 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741910408.120793    9539 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741910408.138221    9539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741910408.138249    9539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741910408.138254    9539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741910408.138257    9539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-14 00:00:08.143179: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 7.12 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mstart harness evaluation\u001b[0m\n",
            "\u001b[0mSelected Tasks: ['truthfulqa_mc', 'anli_r1', 'race', 'anli_r3', 'openbookqa', 'arc_challenge', 'piqa', 'winogrande', 'anli_r2', 'arc_easy', 'rte', 'hellaswag', 'wic', 'record', 'boolq']\u001b[0m\n",
            "README.md: 100% 9.59k/9.59k [00:00<00:00, 37.2MB/s]\u001b[0m\n",
            "validation-00000-of-00001.parquet: 100% 271k/271k [00:00<00:00, 9.00MB/s]\u001b[0m\n",
            "Generating validation split: 100% 817/817 [00:00<00:00, 11297.28 examples/s]\u001b[0m\n",
            "README.md: 100% 7.98k/7.98k [00:00<00:00, 31.1MB/s]\u001b[0m\n",
            "train_r1-00000-of-00001.parquet: 100% 3.14M/3.14M [00:00<00:00, 95.2MB/s]\u001b[0m\n",
            "dev_r1-00000-of-00001.parquet: 100% 351k/351k [00:00<00:00, 287MB/s]\u001b[0m\n",
            "test_r1-00000-of-00001.parquet: 100% 353k/353k [00:00<00:00, 318MB/s]\u001b[0m\n",
            "train_r2-00000-of-00001.parquet: 100% 6.53M/6.53M [00:00<00:00, 7.56MB/s]\u001b[0m\n",
            "dev_r2-00000-of-00001.parquet: 100% 351k/351k [00:00<00:00, 59.2MB/s]\u001b[0m\n",
            "test_r2-00000-of-00001.parquet: 100% 362k/362k [00:00<00:00, 62.7MB/s]\u001b[0m\n",
            "train_r3-00000-of-00001.parquet: 100% 14.3M/14.3M [00:00<00:00, 33.2MB/s]\u001b[0m\n",
            "dev_r3-00000-of-00001.parquet: 100% 434k/434k [00:00<00:00, 11.3MB/s]\u001b[0m\n",
            "test_r3-00000-of-00001.parquet: 100% 435k/435k [00:00<00:00, 17.9MB/s]\u001b[0m\n",
            "Generating train_r1 split: 100% 16946/16946 [00:00<00:00, 518539.12 examples/s]\u001b[0m\n",
            "Generating dev_r1 split: 100% 1000/1000 [00:00<00:00, 239962.47 examples/s]\u001b[0m\n",
            "Generating test_r1 split: 100% 1000/1000 [00:00<00:00, 248330.61 examples/s]\u001b[0m\n",
            "Generating train_r2 split: 100% 45460/45460 [00:00<00:00, 723641.64 examples/s]\u001b[0m\n",
            "Generating dev_r2 split: 100% 1000/1000 [00:00<00:00, 238828.38 examples/s]\u001b[0m\n",
            "Generating test_r2 split: 100% 1000/1000 [00:00<00:00, 241816.32 examples/s]\u001b[0m\n",
            "Generating train_r3 split: 100% 100459/100459 [00:00<00:00, 731516.30 examples/s]\u001b[0m\n",
            "Generating dev_r3 split: 100% 1200/1200 [00:00<00:00, 233807.07 examples/s]\u001b[0m\n",
            "Generating test_r3 split: 100% 1200/1200 [00:00<00:00, 123896.34 examples/s]\u001b[0m\n",
            "README.md: 100% 11.0k/11.0k [00:00<00:00, 51.4MB/s]\u001b[0m\n",
            "test-00000-of-00001.parquet: 100% 1.68M/1.68M [00:00<00:00, 29.3MB/s]\u001b[0m\n",
            "train-00000-of-00001.parquet: 100% 30.4M/30.4M [00:00<00:00, 115MB/s]\u001b[0m\n",
            "validation-00000-of-00001.parquet: 100% 1.66M/1.66M [00:00<00:00, 127MB/s]\u001b[0m\n",
            "Generating test split: 100% 3498/3498 [00:00<00:00, 100896.59 examples/s]\u001b[0m\n",
            "Generating train split: 100% 62445/62445 [00:00<00:00, 97473.53 examples/s]\u001b[0m\n",
            "Generating validation split: 100% 3451/3451 [00:00<00:00, 98587.00 examples/s]\u001b[0m\n",
            "README.md: 100% 9.06k/9.06k [00:00<00:00, 38.1MB/s]\u001b[0m\n",
            "train-00000-of-00001.parquet: 100% 496k/496k [00:00<00:00, 287MB/s]\u001b[0m\n",
            "validation-00000-of-00001.parquet: 100% 58.2k/58.2k [00:00<00:00, 158MB/s]\u001b[0m\n",
            "test-00000-of-00001.parquet: 100% 55.5k/55.5k [00:00<00:00, 126MB/s]\u001b[0m\n",
            "Generating train split: 100% 4957/4957 [00:00<00:00, 600518.89 examples/s]\u001b[0m\n",
            "Generating validation split: 100% 500/500 [00:00<00:00, 136657.89 examples/s]\u001b[0m\n",
            "Generating test split: 100% 500/500 [00:00<00:00, 190390.56 examples/s]\u001b[0m\n",
            "train-00000-of-00001.parquet: 100% 190k/190k [00:00<00:00, 8.28MB/s]\u001b[0m\n",
            "test-00000-of-00001.parquet: 100% 204k/204k [00:00<00:00, 51.0MB/s]\u001b[0m\n",
            "validation-00000-of-00001.parquet: 100% 55.7k/55.7k [00:00<00:00, 164MB/s]\u001b[0m\n",
            "Generating train split: 100% 1119/1119 [00:00<00:00, 238184.53 examples/s]\u001b[0m\n",
            "Generating test split: 100% 1172/1172 [00:00<00:00, 273293.17 examples/s]\u001b[0m\n",
            "Generating validation split: 100% 299/299 [00:00<00:00, 121733.34 examples/s]\u001b[0m\n",
            "README.md: 100% 8.41k/8.41k [00:00<00:00, 39.9MB/s]\u001b[0m\n",
            "piqa.py: 100% 5.36k/5.36k [00:00<00:00, 27.1MB/s]\u001b[0m\n",
            "\u001b[0mThe repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] \u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 55, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mt_results = evaluator.simple_evaluate(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/utils.py\", line 160, in _wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/evaluator.py\", line 66, in simple_evaluate\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_dict = lm_eval.tasks.get_task_dict(task_names)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 342, in get_task_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name_dict = {\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 343, in <dictcomp>\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name: get_task(task_name)()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 412, in __init__\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.download(data_dir, cache_dir, download_mode)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 441, in download\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.dataset = datasets.load_dataset(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2129, in load_dataset\n",
            "\u001b[0m\u001b[0m    \u001b[0mbuilder_instance = load_dataset_builder(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1849, in load_dataset_builder\n",
            "\u001b[0m\u001b[0m    \u001b[0mdataset_module = dataset_module_factory(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1731, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise e1 from None\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1681, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0m).get_module()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1331, in get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mtrust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise ValueError(\u001b[0m\n",
            "\u001b[0m\u001b[0mValueError\u001b[0m: \u001b[0mThe repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "question = \"Who is Einstein?\"\n",
        "generator = pipeline(\"text-generation\", model=\"GreenBitAI/yi-6b-w4a16g32\", torch_dtype=torch.float16, device_map=\"auto\")\n",
        "output = generator([{\"role\": \"user\", \"content\": question}], max_new_tokens=12, return_full_text=False)[0]\n",
        "print(output[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898,
          "referenced_widgets": [
            "fc03e98a407d48318bc5ec0e1cf5e6bc",
            "754081607a03497aa0c3d9ef9c81f4d0",
            "d1a513a61c2d4f168fd3b6237729653c",
            "0066f4ff31f84323be82ffcda2d4bfa3",
            "3abba4a469004a61a6c92237869672d9",
            "33fccfcf095b435e981692d144958fa3",
            "19dae95fde484c23a0a69cd8d51861fb",
            "a667e3880ddc41069437a448f48b4442",
            "aa18803627c343988641f4fbd2c6369a",
            "6915fc9b597c444187ed946277f100ec",
            "0512b923eb824d6bab4d500cd49b33dc",
            "0888e48296234b91a246dce7d46aebf5",
            "39f6290e51724e4cad56f41aec51cbe5",
            "26a9d2af5a1f4292b60beaa70dbf91ac",
            "ca7fe9ef63754b5bb47d42652c55569e",
            "675349ec358d46139e362c3593351fec",
            "e6ebd9a6d86a4f66a6e475192152f9ea",
            "e397b55e0b5748d8b45d307f30b1389b",
            "53d360c6185940beab39193dd221603d",
            "50003a057322494991ec187521a32b40",
            "378973a7274c483db81b908d64c9a180",
            "8cf966dee5ac467985ef1c2a4a01caf4",
            "83f556fc80944bc5a6f4b78d647e3ae1",
            "b2a715f6da4344ee952e3413c0955738",
            "c7e7f065478c488fb1def2902a7a82db",
            "05815fd2725e4427abf8afda12b5de26",
            "c5f5f94c1a6f433c82614811596218d1",
            "c31a80d9b4984f53bf77ec210971c349",
            "09d6018fd5de4ec990ee56a4bdbec5ca",
            "50b36142028a48ff8a3e422db7123af6",
            "c941c1b379624037b6eddfb5b74d1eb9",
            "85216b6a8b3445a7916fd19ec0f7f73d",
            "3b2fd9a23b254679ae7f68790e6bde3f",
            "0b1109cca2694ea1a0f940ba0d6fd15b",
            "2aa74b14252148a9a2cfdc50cbbe6c6a",
            "1ef3bbc40d3b4032a05d9ec9f3433c1c",
            "7ff3a55d8d834a618cee8039e4eb633e",
            "3c5f37b0c4a9419eb049130def0d1999",
            "be6f61bdb40744bf8c613dc5ca45f445",
            "642b29f7a477410f980bb92da9f8fe3c",
            "a32e6f7033054029a96afd6858dc8783",
            "97516306277848a5b584c30557f458ea",
            "83f12e1076524f95a79a1a9951994f66",
            "d4896203e2ca4933877779c3ff059a7c",
            "b70f1ef0b8874f90bf2454c985fc58d0",
            "473a533cc9a242bea8d3effde9b3352c",
            "f93abe8039264faaa8dac0e0039d4827",
            "f75a50051ab64aed9c32dd07ece53a95",
            "8e704ce0a82a41a9a9310d74a6b63fac",
            "48cfef7ad62a440b92becae1a38a5180",
            "a7943bbfbbef4520935e9652a3285e42",
            "a7494d083d7840b998dd0882914e1a86",
            "6d8b890e4fea407592d6a6947bb6e5a2",
            "028b508b46df4221b363d1a396ef29be",
            "28afd464d6b3401e988b2e4573069492",
            "4feb2080a3b04dc997c7ad8b8b68181a",
            "d7080442979a49e99698ec7d210b4b3a",
            "c36e3db4c217450ab878b7da95ca4c3b",
            "eb59e9483c824677895c3a7d5eeb3fd9",
            "5a43c1baa16a4da8b38e71f30d348aab",
            "ae1e648cca0947aead3c84e2f50d1b27",
            "df5a5c19a1e54d15bfd171609578da69",
            "eb32232bb050483a8d212150b361936b",
            "0d8642a23fcb48cfa4d1de9566cd0d63",
            "c6204b4f98834edfa5ad7ade0fec9353",
            "933d627d4d364b6eb2f4d7df46f02d7a"
          ]
        },
        "id": "sf3nZDE582Gt",
        "outputId": "db342b4d-9fda-488d-af81-c7fce2c92d5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc03e98a407d48318bc5ec0e1cf5e6bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.04G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0888e48296234b91a246dce7d46aebf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at GreenBitAI/yi-6b-w4a16g32 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.g_idx', 'model.layers.0.mlp.down_proj.qscales_scales', 'model.layers.0.mlp.down_proj.qscales_zeros', 'model.layers.0.mlp.down_proj.qstatistic', 'model.layers.0.mlp.down_proj.qweight', 'model.layers.0.mlp.down_proj.qzeros_scales', 'model.layers.0.mlp.down_proj.qzeros_zeros', 'model.layers.0.mlp.gate_proj.g_idx', 'model.layers.0.mlp.gate_proj.qscales_scales', 'model.layers.0.mlp.gate_proj.qscales_zeros', 'model.layers.0.mlp.gate_proj.qstatistic', 'model.layers.0.mlp.gate_proj.qweight', 'model.layers.0.mlp.gate_proj.qzeros_scales', 'model.layers.0.mlp.gate_proj.qzeros_zeros', 'model.layers.0.mlp.up_proj.g_idx', 'model.layers.0.mlp.up_proj.qscales_scales', 'model.layers.0.mlp.up_proj.qscales_zeros', 'model.layers.0.mlp.up_proj.qstatistic', 'model.layers.0.mlp.up_proj.qweight', 'model.layers.0.mlp.up_proj.qzeros_scales', 'model.layers.0.mlp.up_proj.qzeros_zeros', 'model.layers.0.self_attn.k_proj.g_idx', 'model.layers.0.self_attn.k_proj.qscales_scales', 'model.layers.0.self_attn.k_proj.qscales_zeros', 'model.layers.0.self_attn.k_proj.qstatistic', 'model.layers.0.self_attn.k_proj.qweight', 'model.layers.0.self_attn.k_proj.qzeros_scales', 'model.layers.0.self_attn.k_proj.qzeros_zeros', 'model.layers.0.self_attn.o_proj.g_idx', 'model.layers.0.self_attn.o_proj.qscales_scales', 'model.layers.0.self_attn.o_proj.qscales_zeros', 'model.layers.0.self_attn.o_proj.qstatistic', 'model.layers.0.self_attn.o_proj.qweight', 'model.layers.0.self_attn.o_proj.qzeros_scales', 'model.layers.0.self_attn.o_proj.qzeros_zeros', 'model.layers.0.self_attn.q_proj.g_idx', 'model.layers.0.self_attn.q_proj.qscales_scales', 'model.layers.0.self_attn.q_proj.qscales_zeros', 'model.layers.0.self_attn.q_proj.qstatistic', 'model.layers.0.self_attn.q_proj.qweight', 'model.layers.0.self_attn.q_proj.qzeros_scales', 'model.layers.0.self_attn.q_proj.qzeros_zeros', 'model.layers.0.self_attn.v_proj.g_idx', 'model.layers.0.self_attn.v_proj.qscales_scales', 'model.layers.0.self_attn.v_proj.qscales_zeros', 'model.layers.0.self_attn.v_proj.qstatistic', 'model.layers.0.self_attn.v_proj.qweight', 'model.layers.0.self_attn.v_proj.qzeros_scales', 'model.layers.0.self_attn.v_proj.qzeros_zeros', 'model.layers.1.mlp.down_proj.g_idx', 'model.layers.1.mlp.down_proj.qscales_scales', 'model.layers.1.mlp.down_proj.qscales_zeros', 'model.layers.1.mlp.down_proj.qstatistic', 'model.layers.1.mlp.down_proj.qweight', 'model.layers.1.mlp.down_proj.qzeros_scales', 'model.layers.1.mlp.down_proj.qzeros_zeros', 'model.layers.1.mlp.gate_proj.g_idx', 'model.layers.1.mlp.gate_proj.qscales_scales', 'model.layers.1.mlp.gate_proj.qscales_zeros', 'model.layers.1.mlp.gate_proj.qstatistic', 'model.layers.1.mlp.gate_proj.qweight', 'model.layers.1.mlp.gate_proj.qzeros_scales', 'model.layers.1.mlp.gate_proj.qzeros_zeros', 'model.layers.1.mlp.up_proj.g_idx', 'model.layers.1.mlp.up_proj.qscales_scales', 'model.layers.1.mlp.up_proj.qscales_zeros', 'model.layers.1.mlp.up_proj.qstatistic', 'model.layers.1.mlp.up_proj.qweight', 'model.layers.1.mlp.up_proj.qzeros_scales', 'model.layers.1.mlp.up_proj.qzeros_zeros', 'model.layers.1.self_attn.k_proj.g_idx', 'model.layers.1.self_attn.k_proj.qscales_scales', 'model.layers.1.self_attn.k_proj.qscales_zeros', 'model.layers.1.self_attn.k_proj.qstatistic', 'model.layers.1.self_attn.k_proj.qweight', 'model.layers.1.self_attn.k_proj.qzeros_scales', 'model.layers.1.self_attn.k_proj.qzeros_zeros', 'model.layers.1.self_attn.o_proj.g_idx', 'model.layers.1.self_attn.o_proj.qscales_scales', 'model.layers.1.self_attn.o_proj.qscales_zeros', 'model.layers.1.self_attn.o_proj.qstatistic', 'model.layers.1.self_attn.o_proj.qweight', 'model.layers.1.self_attn.o_proj.qzeros_scales', 'model.layers.1.self_attn.o_proj.qzeros_zeros', 'model.layers.1.self_attn.q_proj.g_idx', 'model.layers.1.self_attn.q_proj.qscales_scales', 'model.layers.1.self_attn.q_proj.qscales_zeros', 'model.layers.1.self_attn.q_proj.qstatistic', 'model.layers.1.self_attn.q_proj.qweight', 'model.layers.1.self_attn.q_proj.qzeros_scales', 'model.layers.1.self_attn.q_proj.qzeros_zeros', 'model.layers.1.self_attn.v_proj.g_idx', 'model.layers.1.self_attn.v_proj.qscales_scales', 'model.layers.1.self_attn.v_proj.qscales_zeros', 'model.layers.1.self_attn.v_proj.qstatistic', 'model.layers.1.self_attn.v_proj.qweight', 'model.layers.1.self_attn.v_proj.qzeros_scales', 'model.layers.1.self_attn.v_proj.qzeros_zeros', 'model.layers.10.mlp.down_proj.g_idx', 'model.layers.10.mlp.down_proj.qscales_scales', 'model.layers.10.mlp.down_proj.qscales_zeros', 'model.layers.10.mlp.down_proj.qstatistic', 'model.layers.10.mlp.down_proj.qweight', 'model.layers.10.mlp.down_proj.qzeros_scales', 'model.layers.10.mlp.down_proj.qzeros_zeros', 'model.layers.10.mlp.gate_proj.g_idx', 'model.layers.10.mlp.gate_proj.qscales_scales', 'model.layers.10.mlp.gate_proj.qscales_zeros', 'model.layers.10.mlp.gate_proj.qstatistic', 'model.layers.10.mlp.gate_proj.qweight', 'model.layers.10.mlp.gate_proj.qzeros_scales', 'model.layers.10.mlp.gate_proj.qzeros_zeros', 'model.layers.10.mlp.up_proj.g_idx', 'model.layers.10.mlp.up_proj.qscales_scales', 'model.layers.10.mlp.up_proj.qscales_zeros', 'model.layers.10.mlp.up_proj.qstatistic', 'model.layers.10.mlp.up_proj.qweight', 'model.layers.10.mlp.up_proj.qzeros_scales', 'model.layers.10.mlp.up_proj.qzeros_zeros', 'model.layers.10.self_attn.k_proj.g_idx', 'model.layers.10.self_attn.k_proj.qscales_scales', 'model.layers.10.self_attn.k_proj.qscales_zeros', 'model.layers.10.self_attn.k_proj.qstatistic', 'model.layers.10.self_attn.k_proj.qweight', 'model.layers.10.self_attn.k_proj.qzeros_scales', 'model.layers.10.self_attn.k_proj.qzeros_zeros', 'model.layers.10.self_attn.o_proj.g_idx', 'model.layers.10.self_attn.o_proj.qscales_scales', 'model.layers.10.self_attn.o_proj.qscales_zeros', 'model.layers.10.self_attn.o_proj.qstatistic', 'model.layers.10.self_attn.o_proj.qweight', 'model.layers.10.self_attn.o_proj.qzeros_scales', 'model.layers.10.self_attn.o_proj.qzeros_zeros', 'model.layers.10.self_attn.q_proj.g_idx', 'model.layers.10.self_attn.q_proj.qscales_scales', 'model.layers.10.self_attn.q_proj.qscales_zeros', 'model.layers.10.self_attn.q_proj.qstatistic', 'model.layers.10.self_attn.q_proj.qweight', 'model.layers.10.self_attn.q_proj.qzeros_scales', 'model.layers.10.self_attn.q_proj.qzeros_zeros', 'model.layers.10.self_attn.v_proj.g_idx', 'model.layers.10.self_attn.v_proj.qscales_scales', 'model.layers.10.self_attn.v_proj.qscales_zeros', 'model.layers.10.self_attn.v_proj.qstatistic', 'model.layers.10.self_attn.v_proj.qweight', 'model.layers.10.self_attn.v_proj.qzeros_scales', 'model.layers.10.self_attn.v_proj.qzeros_zeros', 'model.layers.11.mlp.down_proj.g_idx', 'model.layers.11.mlp.down_proj.qscales_scales', 'model.layers.11.mlp.down_proj.qscales_zeros', 'model.layers.11.mlp.down_proj.qstatistic', 'model.layers.11.mlp.down_proj.qweight', 'model.layers.11.mlp.down_proj.qzeros_scales', 'model.layers.11.mlp.down_proj.qzeros_zeros', 'model.layers.11.mlp.gate_proj.g_idx', 'model.layers.11.mlp.gate_proj.qscales_scales', 'model.layers.11.mlp.gate_proj.qscales_zeros', 'model.layers.11.mlp.gate_proj.qstatistic', 'model.layers.11.mlp.gate_proj.qweight', 'model.layers.11.mlp.gate_proj.qzeros_scales', 'model.layers.11.mlp.gate_proj.qzeros_zeros', 'model.layers.11.mlp.up_proj.g_idx', 'model.layers.11.mlp.up_proj.qscales_scales', 'model.layers.11.mlp.up_proj.qscales_zeros', 'model.layers.11.mlp.up_proj.qstatistic', 'model.layers.11.mlp.up_proj.qweight', 'model.layers.11.mlp.up_proj.qzeros_scales', 'model.layers.11.mlp.up_proj.qzeros_zeros', 'model.layers.11.self_attn.k_proj.g_idx', 'model.layers.11.self_attn.k_proj.qscales_scales', 'model.layers.11.self_attn.k_proj.qscales_zeros', 'model.layers.11.self_attn.k_proj.qstatistic', 'model.layers.11.self_attn.k_proj.qweight', 'model.layers.11.self_attn.k_proj.qzeros_scales', 'model.layers.11.self_attn.k_proj.qzeros_zeros', 'model.layers.11.self_attn.o_proj.g_idx', 'model.layers.11.self_attn.o_proj.qscales_scales', 'model.layers.11.self_attn.o_proj.qscales_zeros', 'model.layers.11.self_attn.o_proj.qstatistic', 'model.layers.11.self_attn.o_proj.qweight', 'model.layers.11.self_attn.o_proj.qzeros_scales', 'model.layers.11.self_attn.o_proj.qzeros_zeros', 'model.layers.11.self_attn.q_proj.g_idx', 'model.layers.11.self_attn.q_proj.qscales_scales', 'model.layers.11.self_attn.q_proj.qscales_zeros', 'model.layers.11.self_attn.q_proj.qstatistic', 'model.layers.11.self_attn.q_proj.qweight', 'model.layers.11.self_attn.q_proj.qzeros_scales', 'model.layers.11.self_attn.q_proj.qzeros_zeros', 'model.layers.11.self_attn.v_proj.g_idx', 'model.layers.11.self_attn.v_proj.qscales_scales', 'model.layers.11.self_attn.v_proj.qscales_zeros', 'model.layers.11.self_attn.v_proj.qstatistic', 'model.layers.11.self_attn.v_proj.qweight', 'model.layers.11.self_attn.v_proj.qzeros_scales', 'model.layers.11.self_attn.v_proj.qzeros_zeros', 'model.layers.12.mlp.down_proj.g_idx', 'model.layers.12.mlp.down_proj.qscales_scales', 'model.layers.12.mlp.down_proj.qscales_zeros', 'model.layers.12.mlp.down_proj.qstatistic', 'model.layers.12.mlp.down_proj.qweight', 'model.layers.12.mlp.down_proj.qzeros_scales', 'model.layers.12.mlp.down_proj.qzeros_zeros', 'model.layers.12.mlp.gate_proj.g_idx', 'model.layers.12.mlp.gate_proj.qscales_scales', 'model.layers.12.mlp.gate_proj.qscales_zeros', 'model.layers.12.mlp.gate_proj.qstatistic', 'model.layers.12.mlp.gate_proj.qweight', 'model.layers.12.mlp.gate_proj.qzeros_scales', 'model.layers.12.mlp.gate_proj.qzeros_zeros', 'model.layers.12.mlp.up_proj.g_idx', 'model.layers.12.mlp.up_proj.qscales_scales', 'model.layers.12.mlp.up_proj.qscales_zeros', 'model.layers.12.mlp.up_proj.qstatistic', 'model.layers.12.mlp.up_proj.qweight', 'model.layers.12.mlp.up_proj.qzeros_scales', 'model.layers.12.mlp.up_proj.qzeros_zeros', 'model.layers.12.self_attn.k_proj.g_idx', 'model.layers.12.self_attn.k_proj.qscales_scales', 'model.layers.12.self_attn.k_proj.qscales_zeros', 'model.layers.12.self_attn.k_proj.qstatistic', 'model.layers.12.self_attn.k_proj.qweight', 'model.layers.12.self_attn.k_proj.qzeros_scales', 'model.layers.12.self_attn.k_proj.qzeros_zeros', 'model.layers.12.self_attn.o_proj.g_idx', 'model.layers.12.self_attn.o_proj.qscales_scales', 'model.layers.12.self_attn.o_proj.qscales_zeros', 'model.layers.12.self_attn.o_proj.qstatistic', 'model.layers.12.self_attn.o_proj.qweight', 'model.layers.12.self_attn.o_proj.qzeros_scales', 'model.layers.12.self_attn.o_proj.qzeros_zeros', 'model.layers.12.self_attn.q_proj.g_idx', 'model.layers.12.self_attn.q_proj.qscales_scales', 'model.layers.12.self_attn.q_proj.qscales_zeros', 'model.layers.12.self_attn.q_proj.qstatistic', 'model.layers.12.self_attn.q_proj.qweight', 'model.layers.12.self_attn.q_proj.qzeros_scales', 'model.layers.12.self_attn.q_proj.qzeros_zeros', 'model.layers.12.self_attn.v_proj.g_idx', 'model.layers.12.self_attn.v_proj.qscales_scales', 'model.layers.12.self_attn.v_proj.qscales_zeros', 'model.layers.12.self_attn.v_proj.qstatistic', 'model.layers.12.self_attn.v_proj.qweight', 'model.layers.12.self_attn.v_proj.qzeros_scales', 'model.layers.12.self_attn.v_proj.qzeros_zeros', 'model.layers.13.mlp.down_proj.g_idx', 'model.layers.13.mlp.down_proj.qscales_scales', 'model.layers.13.mlp.down_proj.qscales_zeros', 'model.layers.13.mlp.down_proj.qstatistic', 'model.layers.13.mlp.down_proj.qweight', 'model.layers.13.mlp.down_proj.qzeros_scales', 'model.layers.13.mlp.down_proj.qzeros_zeros', 'model.layers.13.mlp.gate_proj.g_idx', 'model.layers.13.mlp.gate_proj.qscales_scales', 'model.layers.13.mlp.gate_proj.qscales_zeros', 'model.layers.13.mlp.gate_proj.qstatistic', 'model.layers.13.mlp.gate_proj.qweight', 'model.layers.13.mlp.gate_proj.qzeros_scales', 'model.layers.13.mlp.gate_proj.qzeros_zeros', 'model.layers.13.mlp.up_proj.g_idx', 'model.layers.13.mlp.up_proj.qscales_scales', 'model.layers.13.mlp.up_proj.qscales_zeros', 'model.layers.13.mlp.up_proj.qstatistic', 'model.layers.13.mlp.up_proj.qweight', 'model.layers.13.mlp.up_proj.qzeros_scales', 'model.layers.13.mlp.up_proj.qzeros_zeros', 'model.layers.13.self_attn.k_proj.g_idx', 'model.layers.13.self_attn.k_proj.qscales_scales', 'model.layers.13.self_attn.k_proj.qscales_zeros', 'model.layers.13.self_attn.k_proj.qstatistic', 'model.layers.13.self_attn.k_proj.qweight', 'model.layers.13.self_attn.k_proj.qzeros_scales', 'model.layers.13.self_attn.k_proj.qzeros_zeros', 'model.layers.13.self_attn.o_proj.g_idx', 'model.layers.13.self_attn.o_proj.qscales_scales', 'model.layers.13.self_attn.o_proj.qscales_zeros', 'model.layers.13.self_attn.o_proj.qstatistic', 'model.layers.13.self_attn.o_proj.qweight', 'model.layers.13.self_attn.o_proj.qzeros_scales', 'model.layers.13.self_attn.o_proj.qzeros_zeros', 'model.layers.13.self_attn.q_proj.g_idx', 'model.layers.13.self_attn.q_proj.qscales_scales', 'model.layers.13.self_attn.q_proj.qscales_zeros', 'model.layers.13.self_attn.q_proj.qstatistic', 'model.layers.13.self_attn.q_proj.qweight', 'model.layers.13.self_attn.q_proj.qzeros_scales', 'model.layers.13.self_attn.q_proj.qzeros_zeros', 'model.layers.13.self_attn.v_proj.g_idx', 'model.layers.13.self_attn.v_proj.qscales_scales', 'model.layers.13.self_attn.v_proj.qscales_zeros', 'model.layers.13.self_attn.v_proj.qstatistic', 'model.layers.13.self_attn.v_proj.qweight', 'model.layers.13.self_attn.v_proj.qzeros_scales', 'model.layers.13.self_attn.v_proj.qzeros_zeros', 'model.layers.14.mlp.down_proj.g_idx', 'model.layers.14.mlp.down_proj.qscales_scales', 'model.layers.14.mlp.down_proj.qscales_zeros', 'model.layers.14.mlp.down_proj.qstatistic', 'model.layers.14.mlp.down_proj.qweight', 'model.layers.14.mlp.down_proj.qzeros_scales', 'model.layers.14.mlp.down_proj.qzeros_zeros', 'model.layers.14.mlp.gate_proj.g_idx', 'model.layers.14.mlp.gate_proj.qscales_scales', 'model.layers.14.mlp.gate_proj.qscales_zeros', 'model.layers.14.mlp.gate_proj.qstatistic', 'model.layers.14.mlp.gate_proj.qweight', 'model.layers.14.mlp.gate_proj.qzeros_scales', 'model.layers.14.mlp.gate_proj.qzeros_zeros', 'model.layers.14.mlp.up_proj.g_idx', 'model.layers.14.mlp.up_proj.qscales_scales', 'model.layers.14.mlp.up_proj.qscales_zeros', 'model.layers.14.mlp.up_proj.qstatistic', 'model.layers.14.mlp.up_proj.qweight', 'model.layers.14.mlp.up_proj.qzeros_scales', 'model.layers.14.mlp.up_proj.qzeros_zeros', 'model.layers.14.self_attn.k_proj.g_idx', 'model.layers.14.self_attn.k_proj.qscales_scales', 'model.layers.14.self_attn.k_proj.qscales_zeros', 'model.layers.14.self_attn.k_proj.qstatistic', 'model.layers.14.self_attn.k_proj.qweight', 'model.layers.14.self_attn.k_proj.qzeros_scales', 'model.layers.14.self_attn.k_proj.qzeros_zeros', 'model.layers.14.self_attn.o_proj.g_idx', 'model.layers.14.self_attn.o_proj.qscales_scales', 'model.layers.14.self_attn.o_proj.qscales_zeros', 'model.layers.14.self_attn.o_proj.qstatistic', 'model.layers.14.self_attn.o_proj.qweight', 'model.layers.14.self_attn.o_proj.qzeros_scales', 'model.layers.14.self_attn.o_proj.qzeros_zeros', 'model.layers.14.self_attn.q_proj.g_idx', 'model.layers.14.self_attn.q_proj.qscales_scales', 'model.layers.14.self_attn.q_proj.qscales_zeros', 'model.layers.14.self_attn.q_proj.qstatistic', 'model.layers.14.self_attn.q_proj.qweight', 'model.layers.14.self_attn.q_proj.qzeros_scales', 'model.layers.14.self_attn.q_proj.qzeros_zeros', 'model.layers.14.self_attn.v_proj.g_idx', 'model.layers.14.self_attn.v_proj.qscales_scales', 'model.layers.14.self_attn.v_proj.qscales_zeros', 'model.layers.14.self_attn.v_proj.qstatistic', 'model.layers.14.self_attn.v_proj.qweight', 'model.layers.14.self_attn.v_proj.qzeros_scales', 'model.layers.14.self_attn.v_proj.qzeros_zeros', 'model.layers.15.mlp.down_proj.g_idx', 'model.layers.15.mlp.down_proj.qscales_scales', 'model.layers.15.mlp.down_proj.qscales_zeros', 'model.layers.15.mlp.down_proj.qstatistic', 'model.layers.15.mlp.down_proj.qweight', 'model.layers.15.mlp.down_proj.qzeros_scales', 'model.layers.15.mlp.down_proj.qzeros_zeros', 'model.layers.15.mlp.gate_proj.g_idx', 'model.layers.15.mlp.gate_proj.qscales_scales', 'model.layers.15.mlp.gate_proj.qscales_zeros', 'model.layers.15.mlp.gate_proj.qstatistic', 'model.layers.15.mlp.gate_proj.qweight', 'model.layers.15.mlp.gate_proj.qzeros_scales', 'model.layers.15.mlp.gate_proj.qzeros_zeros', 'model.layers.15.mlp.up_proj.g_idx', 'model.layers.15.mlp.up_proj.qscales_scales', 'model.layers.15.mlp.up_proj.qscales_zeros', 'model.layers.15.mlp.up_proj.qstatistic', 'model.layers.15.mlp.up_proj.qweight', 'model.layers.15.mlp.up_proj.qzeros_scales', 'model.layers.15.mlp.up_proj.qzeros_zeros', 'model.layers.15.self_attn.k_proj.g_idx', 'model.layers.15.self_attn.k_proj.qscales_scales', 'model.layers.15.self_attn.k_proj.qscales_zeros', 'model.layers.15.self_attn.k_proj.qstatistic', 'model.layers.15.self_attn.k_proj.qweight', 'model.layers.15.self_attn.k_proj.qzeros_scales', 'model.layers.15.self_attn.k_proj.qzeros_zeros', 'model.layers.15.self_attn.o_proj.g_idx', 'model.layers.15.self_attn.o_proj.qscales_scales', 'model.layers.15.self_attn.o_proj.qscales_zeros', 'model.layers.15.self_attn.o_proj.qstatistic', 'model.layers.15.self_attn.o_proj.qweight', 'model.layers.15.self_attn.o_proj.qzeros_scales', 'model.layers.15.self_attn.o_proj.qzeros_zeros', 'model.layers.15.self_attn.q_proj.g_idx', 'model.layers.15.self_attn.q_proj.qscales_scales', 'model.layers.15.self_attn.q_proj.qscales_zeros', 'model.layers.15.self_attn.q_proj.qstatistic', 'model.layers.15.self_attn.q_proj.qweight', 'model.layers.15.self_attn.q_proj.qzeros_scales', 'model.layers.15.self_attn.q_proj.qzeros_zeros', 'model.layers.15.self_attn.v_proj.g_idx', 'model.layers.15.self_attn.v_proj.qscales_scales', 'model.layers.15.self_attn.v_proj.qscales_zeros', 'model.layers.15.self_attn.v_proj.qstatistic', 'model.layers.15.self_attn.v_proj.qweight', 'model.layers.15.self_attn.v_proj.qzeros_scales', 'model.layers.15.self_attn.v_proj.qzeros_zeros', 'model.layers.16.mlp.down_proj.g_idx', 'model.layers.16.mlp.down_proj.qscales_scales', 'model.layers.16.mlp.down_proj.qscales_zeros', 'model.layers.16.mlp.down_proj.qstatistic', 'model.layers.16.mlp.down_proj.qweight', 'model.layers.16.mlp.down_proj.qzeros_scales', 'model.layers.16.mlp.down_proj.qzeros_zeros', 'model.layers.16.mlp.gate_proj.g_idx', 'model.layers.16.mlp.gate_proj.qscales_scales', 'model.layers.16.mlp.gate_proj.qscales_zeros', 'model.layers.16.mlp.gate_proj.qstatistic', 'model.layers.16.mlp.gate_proj.qweight', 'model.layers.16.mlp.gate_proj.qzeros_scales', 'model.layers.16.mlp.gate_proj.qzeros_zeros', 'model.layers.16.mlp.up_proj.g_idx', 'model.layers.16.mlp.up_proj.qscales_scales', 'model.layers.16.mlp.up_proj.qscales_zeros', 'model.layers.16.mlp.up_proj.qstatistic', 'model.layers.16.mlp.up_proj.qweight', 'model.layers.16.mlp.up_proj.qzeros_scales', 'model.layers.16.mlp.up_proj.qzeros_zeros', 'model.layers.16.self_attn.k_proj.g_idx', 'model.layers.16.self_attn.k_proj.qscales_scales', 'model.layers.16.self_attn.k_proj.qscales_zeros', 'model.layers.16.self_attn.k_proj.qstatistic', 'model.layers.16.self_attn.k_proj.qweight', 'model.layers.16.self_attn.k_proj.qzeros_scales', 'model.layers.16.self_attn.k_proj.qzeros_zeros', 'model.layers.16.self_attn.o_proj.g_idx', 'model.layers.16.self_attn.o_proj.qscales_scales', 'model.layers.16.self_attn.o_proj.qscales_zeros', 'model.layers.16.self_attn.o_proj.qstatistic', 'model.layers.16.self_attn.o_proj.qweight', 'model.layers.16.self_attn.o_proj.qzeros_scales', 'model.layers.16.self_attn.o_proj.qzeros_zeros', 'model.layers.16.self_attn.q_proj.g_idx', 'model.layers.16.self_attn.q_proj.qscales_scales', 'model.layers.16.self_attn.q_proj.qscales_zeros', 'model.layers.16.self_attn.q_proj.qstatistic', 'model.layers.16.self_attn.q_proj.qweight', 'model.layers.16.self_attn.q_proj.qzeros_scales', 'model.layers.16.self_attn.q_proj.qzeros_zeros', 'model.layers.16.self_attn.v_proj.g_idx', 'model.layers.16.self_attn.v_proj.qscales_scales', 'model.layers.16.self_attn.v_proj.qscales_zeros', 'model.layers.16.self_attn.v_proj.qstatistic', 'model.layers.16.self_attn.v_proj.qweight', 'model.layers.16.self_attn.v_proj.qzeros_scales', 'model.layers.16.self_attn.v_proj.qzeros_zeros', 'model.layers.17.mlp.down_proj.g_idx', 'model.layers.17.mlp.down_proj.qscales_scales', 'model.layers.17.mlp.down_proj.qscales_zeros', 'model.layers.17.mlp.down_proj.qstatistic', 'model.layers.17.mlp.down_proj.qweight', 'model.layers.17.mlp.down_proj.qzeros_scales', 'model.layers.17.mlp.down_proj.qzeros_zeros', 'model.layers.17.mlp.gate_proj.g_idx', 'model.layers.17.mlp.gate_proj.qscales_scales', 'model.layers.17.mlp.gate_proj.qscales_zeros', 'model.layers.17.mlp.gate_proj.qstatistic', 'model.layers.17.mlp.gate_proj.qweight', 'model.layers.17.mlp.gate_proj.qzeros_scales', 'model.layers.17.mlp.gate_proj.qzeros_zeros', 'model.layers.17.mlp.up_proj.g_idx', 'model.layers.17.mlp.up_proj.qscales_scales', 'model.layers.17.mlp.up_proj.qscales_zeros', 'model.layers.17.mlp.up_proj.qstatistic', 'model.layers.17.mlp.up_proj.qweight', 'model.layers.17.mlp.up_proj.qzeros_scales', 'model.layers.17.mlp.up_proj.qzeros_zeros', 'model.layers.17.self_attn.k_proj.g_idx', 'model.layers.17.self_attn.k_proj.qscales_scales', 'model.layers.17.self_attn.k_proj.qscales_zeros', 'model.layers.17.self_attn.k_proj.qstatistic', 'model.layers.17.self_attn.k_proj.qweight', 'model.layers.17.self_attn.k_proj.qzeros_scales', 'model.layers.17.self_attn.k_proj.qzeros_zeros', 'model.layers.17.self_attn.o_proj.g_idx', 'model.layers.17.self_attn.o_proj.qscales_scales', 'model.layers.17.self_attn.o_proj.qscales_zeros', 'model.layers.17.self_attn.o_proj.qstatistic', 'model.layers.17.self_attn.o_proj.qweight', 'model.layers.17.self_attn.o_proj.qzeros_scales', 'model.layers.17.self_attn.o_proj.qzeros_zeros', 'model.layers.17.self_attn.q_proj.g_idx', 'model.layers.17.self_attn.q_proj.qscales_scales', 'model.layers.17.self_attn.q_proj.qscales_zeros', 'model.layers.17.self_attn.q_proj.qstatistic', 'model.layers.17.self_attn.q_proj.qweight', 'model.layers.17.self_attn.q_proj.qzeros_scales', 'model.layers.17.self_attn.q_proj.qzeros_zeros', 'model.layers.17.self_attn.v_proj.g_idx', 'model.layers.17.self_attn.v_proj.qscales_scales', 'model.layers.17.self_attn.v_proj.qscales_zeros', 'model.layers.17.self_attn.v_proj.qstatistic', 'model.layers.17.self_attn.v_proj.qweight', 'model.layers.17.self_attn.v_proj.qzeros_scales', 'model.layers.17.self_attn.v_proj.qzeros_zeros', 'model.layers.18.mlp.down_proj.g_idx', 'model.layers.18.mlp.down_proj.qscales_scales', 'model.layers.18.mlp.down_proj.qscales_zeros', 'model.layers.18.mlp.down_proj.qstatistic', 'model.layers.18.mlp.down_proj.qweight', 'model.layers.18.mlp.down_proj.qzeros_scales', 'model.layers.18.mlp.down_proj.qzeros_zeros', 'model.layers.18.mlp.gate_proj.g_idx', 'model.layers.18.mlp.gate_proj.qscales_scales', 'model.layers.18.mlp.gate_proj.qscales_zeros', 'model.layers.18.mlp.gate_proj.qstatistic', 'model.layers.18.mlp.gate_proj.qweight', 'model.layers.18.mlp.gate_proj.qzeros_scales', 'model.layers.18.mlp.gate_proj.qzeros_zeros', 'model.layers.18.mlp.up_proj.g_idx', 'model.layers.18.mlp.up_proj.qscales_scales', 'model.layers.18.mlp.up_proj.qscales_zeros', 'model.layers.18.mlp.up_proj.qstatistic', 'model.layers.18.mlp.up_proj.qweight', 'model.layers.18.mlp.up_proj.qzeros_scales', 'model.layers.18.mlp.up_proj.qzeros_zeros', 'model.layers.18.self_attn.k_proj.g_idx', 'model.layers.18.self_attn.k_proj.qscales_scales', 'model.layers.18.self_attn.k_proj.qscales_zeros', 'model.layers.18.self_attn.k_proj.qstatistic', 'model.layers.18.self_attn.k_proj.qweight', 'model.layers.18.self_attn.k_proj.qzeros_scales', 'model.layers.18.self_attn.k_proj.qzeros_zeros', 'model.layers.18.self_attn.o_proj.g_idx', 'model.layers.18.self_attn.o_proj.qscales_scales', 'model.layers.18.self_attn.o_proj.qscales_zeros', 'model.layers.18.self_attn.o_proj.qstatistic', 'model.layers.18.self_attn.o_proj.qweight', 'model.layers.18.self_attn.o_proj.qzeros_scales', 'model.layers.18.self_attn.o_proj.qzeros_zeros', 'model.layers.18.self_attn.q_proj.g_idx', 'model.layers.18.self_attn.q_proj.qscales_scales', 'model.layers.18.self_attn.q_proj.qscales_zeros', 'model.layers.18.self_attn.q_proj.qstatistic', 'model.layers.18.self_attn.q_proj.qweight', 'model.layers.18.self_attn.q_proj.qzeros_scales', 'model.layers.18.self_attn.q_proj.qzeros_zeros', 'model.layers.18.self_attn.v_proj.g_idx', 'model.layers.18.self_attn.v_proj.qscales_scales', 'model.layers.18.self_attn.v_proj.qscales_zeros', 'model.layers.18.self_attn.v_proj.qstatistic', 'model.layers.18.self_attn.v_proj.qweight', 'model.layers.18.self_attn.v_proj.qzeros_scales', 'model.layers.18.self_attn.v_proj.qzeros_zeros', 'model.layers.19.mlp.down_proj.g_idx', 'model.layers.19.mlp.down_proj.qscales_scales', 'model.layers.19.mlp.down_proj.qscales_zeros', 'model.layers.19.mlp.down_proj.qstatistic', 'model.layers.19.mlp.down_proj.qweight', 'model.layers.19.mlp.down_proj.qzeros_scales', 'model.layers.19.mlp.down_proj.qzeros_zeros', 'model.layers.19.mlp.gate_proj.g_idx', 'model.layers.19.mlp.gate_proj.qscales_scales', 'model.layers.19.mlp.gate_proj.qscales_zeros', 'model.layers.19.mlp.gate_proj.qstatistic', 'model.layers.19.mlp.gate_proj.qweight', 'model.layers.19.mlp.gate_proj.qzeros_scales', 'model.layers.19.mlp.gate_proj.qzeros_zeros', 'model.layers.19.mlp.up_proj.g_idx', 'model.layers.19.mlp.up_proj.qscales_scales', 'model.layers.19.mlp.up_proj.qscales_zeros', 'model.layers.19.mlp.up_proj.qstatistic', 'model.layers.19.mlp.up_proj.qweight', 'model.layers.19.mlp.up_proj.qzeros_scales', 'model.layers.19.mlp.up_proj.qzeros_zeros', 'model.layers.19.self_attn.k_proj.g_idx', 'model.layers.19.self_attn.k_proj.qscales_scales', 'model.layers.19.self_attn.k_proj.qscales_zeros', 'model.layers.19.self_attn.k_proj.qstatistic', 'model.layers.19.self_attn.k_proj.qweight', 'model.layers.19.self_attn.k_proj.qzeros_scales', 'model.layers.19.self_attn.k_proj.qzeros_zeros', 'model.layers.19.self_attn.o_proj.g_idx', 'model.layers.19.self_attn.o_proj.qscales_scales', 'model.layers.19.self_attn.o_proj.qscales_zeros', 'model.layers.19.self_attn.o_proj.qstatistic', 'model.layers.19.self_attn.o_proj.qweight', 'model.layers.19.self_attn.o_proj.qzeros_scales', 'model.layers.19.self_attn.o_proj.qzeros_zeros', 'model.layers.19.self_attn.q_proj.g_idx', 'model.layers.19.self_attn.q_proj.qscales_scales', 'model.layers.19.self_attn.q_proj.qscales_zeros', 'model.layers.19.self_attn.q_proj.qstatistic', 'model.layers.19.self_attn.q_proj.qweight', 'model.layers.19.self_attn.q_proj.qzeros_scales', 'model.layers.19.self_attn.q_proj.qzeros_zeros', 'model.layers.19.self_attn.v_proj.g_idx', 'model.layers.19.self_attn.v_proj.qscales_scales', 'model.layers.19.self_attn.v_proj.qscales_zeros', 'model.layers.19.self_attn.v_proj.qstatistic', 'model.layers.19.self_attn.v_proj.qweight', 'model.layers.19.self_attn.v_proj.qzeros_scales', 'model.layers.19.self_attn.v_proj.qzeros_zeros', 'model.layers.2.mlp.down_proj.g_idx', 'model.layers.2.mlp.down_proj.qscales_scales', 'model.layers.2.mlp.down_proj.qscales_zeros', 'model.layers.2.mlp.down_proj.qstatistic', 'model.layers.2.mlp.down_proj.qweight', 'model.layers.2.mlp.down_proj.qzeros_scales', 'model.layers.2.mlp.down_proj.qzeros_zeros', 'model.layers.2.mlp.gate_proj.g_idx', 'model.layers.2.mlp.gate_proj.qscales_scales', 'model.layers.2.mlp.gate_proj.qscales_zeros', 'model.layers.2.mlp.gate_proj.qstatistic', 'model.layers.2.mlp.gate_proj.qweight', 'model.layers.2.mlp.gate_proj.qzeros_scales', 'model.layers.2.mlp.gate_proj.qzeros_zeros', 'model.layers.2.mlp.up_proj.g_idx', 'model.layers.2.mlp.up_proj.qscales_scales', 'model.layers.2.mlp.up_proj.qscales_zeros', 'model.layers.2.mlp.up_proj.qstatistic', 'model.layers.2.mlp.up_proj.qweight', 'model.layers.2.mlp.up_proj.qzeros_scales', 'model.layers.2.mlp.up_proj.qzeros_zeros', 'model.layers.2.self_attn.k_proj.g_idx', 'model.layers.2.self_attn.k_proj.qscales_scales', 'model.layers.2.self_attn.k_proj.qscales_zeros', 'model.layers.2.self_attn.k_proj.qstatistic', 'model.layers.2.self_attn.k_proj.qweight', 'model.layers.2.self_attn.k_proj.qzeros_scales', 'model.layers.2.self_attn.k_proj.qzeros_zeros', 'model.layers.2.self_attn.o_proj.g_idx', 'model.layers.2.self_attn.o_proj.qscales_scales', 'model.layers.2.self_attn.o_proj.qscales_zeros', 'model.layers.2.self_attn.o_proj.qstatistic', 'model.layers.2.self_attn.o_proj.qweight', 'model.layers.2.self_attn.o_proj.qzeros_scales', 'model.layers.2.self_attn.o_proj.qzeros_zeros', 'model.layers.2.self_attn.q_proj.g_idx', 'model.layers.2.self_attn.q_proj.qscales_scales', 'model.layers.2.self_attn.q_proj.qscales_zeros', 'model.layers.2.self_attn.q_proj.qstatistic', 'model.layers.2.self_attn.q_proj.qweight', 'model.layers.2.self_attn.q_proj.qzeros_scales', 'model.layers.2.self_attn.q_proj.qzeros_zeros', 'model.layers.2.self_attn.v_proj.g_idx', 'model.layers.2.self_attn.v_proj.qscales_scales', 'model.layers.2.self_attn.v_proj.qscales_zeros', 'model.layers.2.self_attn.v_proj.qstatistic', 'model.layers.2.self_attn.v_proj.qweight', 'model.layers.2.self_attn.v_proj.qzeros_scales', 'model.layers.2.self_attn.v_proj.qzeros_zeros', 'model.layers.20.mlp.down_proj.g_idx', 'model.layers.20.mlp.down_proj.qscales_scales', 'model.layers.20.mlp.down_proj.qscales_zeros', 'model.layers.20.mlp.down_proj.qstatistic', 'model.layers.20.mlp.down_proj.qweight', 'model.layers.20.mlp.down_proj.qzeros_scales', 'model.layers.20.mlp.down_proj.qzeros_zeros', 'model.layers.20.mlp.gate_proj.g_idx', 'model.layers.20.mlp.gate_proj.qscales_scales', 'model.layers.20.mlp.gate_proj.qscales_zeros', 'model.layers.20.mlp.gate_proj.qstatistic', 'model.layers.20.mlp.gate_proj.qweight', 'model.layers.20.mlp.gate_proj.qzeros_scales', 'model.layers.20.mlp.gate_proj.qzeros_zeros', 'model.layers.20.mlp.up_proj.g_idx', 'model.layers.20.mlp.up_proj.qscales_scales', 'model.layers.20.mlp.up_proj.qscales_zeros', 'model.layers.20.mlp.up_proj.qstatistic', 'model.layers.20.mlp.up_proj.qweight', 'model.layers.20.mlp.up_proj.qzeros_scales', 'model.layers.20.mlp.up_proj.qzeros_zeros', 'model.layers.20.self_attn.k_proj.g_idx', 'model.layers.20.self_attn.k_proj.qscales_scales', 'model.layers.20.self_attn.k_proj.qscales_zeros', 'model.layers.20.self_attn.k_proj.qstatistic', 'model.layers.20.self_attn.k_proj.qweight', 'model.layers.20.self_attn.k_proj.qzeros_scales', 'model.layers.20.self_attn.k_proj.qzeros_zeros', 'model.layers.20.self_attn.o_proj.g_idx', 'model.layers.20.self_attn.o_proj.qscales_scales', 'model.layers.20.self_attn.o_proj.qscales_zeros', 'model.layers.20.self_attn.o_proj.qstatistic', 'model.layers.20.self_attn.o_proj.qweight', 'model.layers.20.self_attn.o_proj.qzeros_scales', 'model.layers.20.self_attn.o_proj.qzeros_zeros', 'model.layers.20.self_attn.q_proj.g_idx', 'model.layers.20.self_attn.q_proj.qscales_scales', 'model.layers.20.self_attn.q_proj.qscales_zeros', 'model.layers.20.self_attn.q_proj.qstatistic', 'model.layers.20.self_attn.q_proj.qweight', 'model.layers.20.self_attn.q_proj.qzeros_scales', 'model.layers.20.self_attn.q_proj.qzeros_zeros', 'model.layers.20.self_attn.v_proj.g_idx', 'model.layers.20.self_attn.v_proj.qscales_scales', 'model.layers.20.self_attn.v_proj.qscales_zeros', 'model.layers.20.self_attn.v_proj.qstatistic', 'model.layers.20.self_attn.v_proj.qweight', 'model.layers.20.self_attn.v_proj.qzeros_scales', 'model.layers.20.self_attn.v_proj.qzeros_zeros', 'model.layers.21.mlp.down_proj.g_idx', 'model.layers.21.mlp.down_proj.qscales_scales', 'model.layers.21.mlp.down_proj.qscales_zeros', 'model.layers.21.mlp.down_proj.qstatistic', 'model.layers.21.mlp.down_proj.qweight', 'model.layers.21.mlp.down_proj.qzeros_scales', 'model.layers.21.mlp.down_proj.qzeros_zeros', 'model.layers.21.mlp.gate_proj.g_idx', 'model.layers.21.mlp.gate_proj.qscales_scales', 'model.layers.21.mlp.gate_proj.qscales_zeros', 'model.layers.21.mlp.gate_proj.qstatistic', 'model.layers.21.mlp.gate_proj.qweight', 'model.layers.21.mlp.gate_proj.qzeros_scales', 'model.layers.21.mlp.gate_proj.qzeros_zeros', 'model.layers.21.mlp.up_proj.g_idx', 'model.layers.21.mlp.up_proj.qscales_scales', 'model.layers.21.mlp.up_proj.qscales_zeros', 'model.layers.21.mlp.up_proj.qstatistic', 'model.layers.21.mlp.up_proj.qweight', 'model.layers.21.mlp.up_proj.qzeros_scales', 'model.layers.21.mlp.up_proj.qzeros_zeros', 'model.layers.21.self_attn.k_proj.g_idx', 'model.layers.21.self_attn.k_proj.qscales_scales', 'model.layers.21.self_attn.k_proj.qscales_zeros', 'model.layers.21.self_attn.k_proj.qstatistic', 'model.layers.21.self_attn.k_proj.qweight', 'model.layers.21.self_attn.k_proj.qzeros_scales', 'model.layers.21.self_attn.k_proj.qzeros_zeros', 'model.layers.21.self_attn.o_proj.g_idx', 'model.layers.21.self_attn.o_proj.qscales_scales', 'model.layers.21.self_attn.o_proj.qscales_zeros', 'model.layers.21.self_attn.o_proj.qstatistic', 'model.layers.21.self_attn.o_proj.qweight', 'model.layers.21.self_attn.o_proj.qzeros_scales', 'model.layers.21.self_attn.o_proj.qzeros_zeros', 'model.layers.21.self_attn.q_proj.g_idx', 'model.layers.21.self_attn.q_proj.qscales_scales', 'model.layers.21.self_attn.q_proj.qscales_zeros', 'model.layers.21.self_attn.q_proj.qstatistic', 'model.layers.21.self_attn.q_proj.qweight', 'model.layers.21.self_attn.q_proj.qzeros_scales', 'model.layers.21.self_attn.q_proj.qzeros_zeros', 'model.layers.21.self_attn.v_proj.g_idx', 'model.layers.21.self_attn.v_proj.qscales_scales', 'model.layers.21.self_attn.v_proj.qscales_zeros', 'model.layers.21.self_attn.v_proj.qstatistic', 'model.layers.21.self_attn.v_proj.qweight', 'model.layers.21.self_attn.v_proj.qzeros_scales', 'model.layers.21.self_attn.v_proj.qzeros_zeros', 'model.layers.22.mlp.down_proj.g_idx', 'model.layers.22.mlp.down_proj.qscales_scales', 'model.layers.22.mlp.down_proj.qscales_zeros', 'model.layers.22.mlp.down_proj.qstatistic', 'model.layers.22.mlp.down_proj.qweight', 'model.layers.22.mlp.down_proj.qzeros_scales', 'model.layers.22.mlp.down_proj.qzeros_zeros', 'model.layers.22.mlp.gate_proj.g_idx', 'model.layers.22.mlp.gate_proj.qscales_scales', 'model.layers.22.mlp.gate_proj.qscales_zeros', 'model.layers.22.mlp.gate_proj.qstatistic', 'model.layers.22.mlp.gate_proj.qweight', 'model.layers.22.mlp.gate_proj.qzeros_scales', 'model.layers.22.mlp.gate_proj.qzeros_zeros', 'model.layers.22.mlp.up_proj.g_idx', 'model.layers.22.mlp.up_proj.qscales_scales', 'model.layers.22.mlp.up_proj.qscales_zeros', 'model.layers.22.mlp.up_proj.qstatistic', 'model.layers.22.mlp.up_proj.qweight', 'model.layers.22.mlp.up_proj.qzeros_scales', 'model.layers.22.mlp.up_proj.qzeros_zeros', 'model.layers.22.self_attn.k_proj.g_idx', 'model.layers.22.self_attn.k_proj.qscales_scales', 'model.layers.22.self_attn.k_proj.qscales_zeros', 'model.layers.22.self_attn.k_proj.qstatistic', 'model.layers.22.self_attn.k_proj.qweight', 'model.layers.22.self_attn.k_proj.qzeros_scales', 'model.layers.22.self_attn.k_proj.qzeros_zeros', 'model.layers.22.self_attn.o_proj.g_idx', 'model.layers.22.self_attn.o_proj.qscales_scales', 'model.layers.22.self_attn.o_proj.qscales_zeros', 'model.layers.22.self_attn.o_proj.qstatistic', 'model.layers.22.self_attn.o_proj.qweight', 'model.layers.22.self_attn.o_proj.qzeros_scales', 'model.layers.22.self_attn.o_proj.qzeros_zeros', 'model.layers.22.self_attn.q_proj.g_idx', 'model.layers.22.self_attn.q_proj.qscales_scales', 'model.layers.22.self_attn.q_proj.qscales_zeros', 'model.layers.22.self_attn.q_proj.qstatistic', 'model.layers.22.self_attn.q_proj.qweight', 'model.layers.22.self_attn.q_proj.qzeros_scales', 'model.layers.22.self_attn.q_proj.qzeros_zeros', 'model.layers.22.self_attn.v_proj.g_idx', 'model.layers.22.self_attn.v_proj.qscales_scales', 'model.layers.22.self_attn.v_proj.qscales_zeros', 'model.layers.22.self_attn.v_proj.qstatistic', 'model.layers.22.self_attn.v_proj.qweight', 'model.layers.22.self_attn.v_proj.qzeros_scales', 'model.layers.22.self_attn.v_proj.qzeros_zeros', 'model.layers.23.mlp.down_proj.g_idx', 'model.layers.23.mlp.down_proj.qscales_scales', 'model.layers.23.mlp.down_proj.qscales_zeros', 'model.layers.23.mlp.down_proj.qstatistic', 'model.layers.23.mlp.down_proj.qweight', 'model.layers.23.mlp.down_proj.qzeros_scales', 'model.layers.23.mlp.down_proj.qzeros_zeros', 'model.layers.23.mlp.gate_proj.g_idx', 'model.layers.23.mlp.gate_proj.qscales_scales', 'model.layers.23.mlp.gate_proj.qscales_zeros', 'model.layers.23.mlp.gate_proj.qstatistic', 'model.layers.23.mlp.gate_proj.qweight', 'model.layers.23.mlp.gate_proj.qzeros_scales', 'model.layers.23.mlp.gate_proj.qzeros_zeros', 'model.layers.23.mlp.up_proj.g_idx', 'model.layers.23.mlp.up_proj.qscales_scales', 'model.layers.23.mlp.up_proj.qscales_zeros', 'model.layers.23.mlp.up_proj.qstatistic', 'model.layers.23.mlp.up_proj.qweight', 'model.layers.23.mlp.up_proj.qzeros_scales', 'model.layers.23.mlp.up_proj.qzeros_zeros', 'model.layers.23.self_attn.k_proj.g_idx', 'model.layers.23.self_attn.k_proj.qscales_scales', 'model.layers.23.self_attn.k_proj.qscales_zeros', 'model.layers.23.self_attn.k_proj.qstatistic', 'model.layers.23.self_attn.k_proj.qweight', 'model.layers.23.self_attn.k_proj.qzeros_scales', 'model.layers.23.self_attn.k_proj.qzeros_zeros', 'model.layers.23.self_attn.o_proj.g_idx', 'model.layers.23.self_attn.o_proj.qscales_scales', 'model.layers.23.self_attn.o_proj.qscales_zeros', 'model.layers.23.self_attn.o_proj.qstatistic', 'model.layers.23.self_attn.o_proj.qweight', 'model.layers.23.self_attn.o_proj.qzeros_scales', 'model.layers.23.self_attn.o_proj.qzeros_zeros', 'model.layers.23.self_attn.q_proj.g_idx', 'model.layers.23.self_attn.q_proj.qscales_scales', 'model.layers.23.self_attn.q_proj.qscales_zeros', 'model.layers.23.self_attn.q_proj.qstatistic', 'model.layers.23.self_attn.q_proj.qweight', 'model.layers.23.self_attn.q_proj.qzeros_scales', 'model.layers.23.self_attn.q_proj.qzeros_zeros', 'model.layers.23.self_attn.v_proj.g_idx', 'model.layers.23.self_attn.v_proj.qscales_scales', 'model.layers.23.self_attn.v_proj.qscales_zeros', 'model.layers.23.self_attn.v_proj.qstatistic', 'model.layers.23.self_attn.v_proj.qweight', 'model.layers.23.self_attn.v_proj.qzeros_scales', 'model.layers.23.self_attn.v_proj.qzeros_zeros', 'model.layers.24.mlp.down_proj.g_idx', 'model.layers.24.mlp.down_proj.qscales_scales', 'model.layers.24.mlp.down_proj.qscales_zeros', 'model.layers.24.mlp.down_proj.qstatistic', 'model.layers.24.mlp.down_proj.qweight', 'model.layers.24.mlp.down_proj.qzeros_scales', 'model.layers.24.mlp.down_proj.qzeros_zeros', 'model.layers.24.mlp.gate_proj.g_idx', 'model.layers.24.mlp.gate_proj.qscales_scales', 'model.layers.24.mlp.gate_proj.qscales_zeros', 'model.layers.24.mlp.gate_proj.qstatistic', 'model.layers.24.mlp.gate_proj.qweight', 'model.layers.24.mlp.gate_proj.qzeros_scales', 'model.layers.24.mlp.gate_proj.qzeros_zeros', 'model.layers.24.mlp.up_proj.g_idx', 'model.layers.24.mlp.up_proj.qscales_scales', 'model.layers.24.mlp.up_proj.qscales_zeros', 'model.layers.24.mlp.up_proj.qstatistic', 'model.layers.24.mlp.up_proj.qweight', 'model.layers.24.mlp.up_proj.qzeros_scales', 'model.layers.24.mlp.up_proj.qzeros_zeros', 'model.layers.24.self_attn.k_proj.g_idx', 'model.layers.24.self_attn.k_proj.qscales_scales', 'model.layers.24.self_attn.k_proj.qscales_zeros', 'model.layers.24.self_attn.k_proj.qstatistic', 'model.layers.24.self_attn.k_proj.qweight', 'model.layers.24.self_attn.k_proj.qzeros_scales', 'model.layers.24.self_attn.k_proj.qzeros_zeros', 'model.layers.24.self_attn.o_proj.g_idx', 'model.layers.24.self_attn.o_proj.qscales_scales', 'model.layers.24.self_attn.o_proj.qscales_zeros', 'model.layers.24.self_attn.o_proj.qstatistic', 'model.layers.24.self_attn.o_proj.qweight', 'model.layers.24.self_attn.o_proj.qzeros_scales', 'model.layers.24.self_attn.o_proj.qzeros_zeros', 'model.layers.24.self_attn.q_proj.g_idx', 'model.layers.24.self_attn.q_proj.qscales_scales', 'model.layers.24.self_attn.q_proj.qscales_zeros', 'model.layers.24.self_attn.q_proj.qstatistic', 'model.layers.24.self_attn.q_proj.qweight', 'model.layers.24.self_attn.q_proj.qzeros_scales', 'model.layers.24.self_attn.q_proj.qzeros_zeros', 'model.layers.24.self_attn.v_proj.g_idx', 'model.layers.24.self_attn.v_proj.qscales_scales', 'model.layers.24.self_attn.v_proj.qscales_zeros', 'model.layers.24.self_attn.v_proj.qstatistic', 'model.layers.24.self_attn.v_proj.qweight', 'model.layers.24.self_attn.v_proj.qzeros_scales', 'model.layers.24.self_attn.v_proj.qzeros_zeros', 'model.layers.25.mlp.down_proj.g_idx', 'model.layers.25.mlp.down_proj.qscales_scales', 'model.layers.25.mlp.down_proj.qscales_zeros', 'model.layers.25.mlp.down_proj.qstatistic', 'model.layers.25.mlp.down_proj.qweight', 'model.layers.25.mlp.down_proj.qzeros_scales', 'model.layers.25.mlp.down_proj.qzeros_zeros', 'model.layers.25.mlp.gate_proj.g_idx', 'model.layers.25.mlp.gate_proj.qscales_scales', 'model.layers.25.mlp.gate_proj.qscales_zeros', 'model.layers.25.mlp.gate_proj.qstatistic', 'model.layers.25.mlp.gate_proj.qweight', 'model.layers.25.mlp.gate_proj.qzeros_scales', 'model.layers.25.mlp.gate_proj.qzeros_zeros', 'model.layers.25.mlp.up_proj.g_idx', 'model.layers.25.mlp.up_proj.qscales_scales', 'model.layers.25.mlp.up_proj.qscales_zeros', 'model.layers.25.mlp.up_proj.qstatistic', 'model.layers.25.mlp.up_proj.qweight', 'model.layers.25.mlp.up_proj.qzeros_scales', 'model.layers.25.mlp.up_proj.qzeros_zeros', 'model.layers.25.self_attn.k_proj.g_idx', 'model.layers.25.self_attn.k_proj.qscales_scales', 'model.layers.25.self_attn.k_proj.qscales_zeros', 'model.layers.25.self_attn.k_proj.qstatistic', 'model.layers.25.self_attn.k_proj.qweight', 'model.layers.25.self_attn.k_proj.qzeros_scales', 'model.layers.25.self_attn.k_proj.qzeros_zeros', 'model.layers.25.self_attn.o_proj.g_idx', 'model.layers.25.self_attn.o_proj.qscales_scales', 'model.layers.25.self_attn.o_proj.qscales_zeros', 'model.layers.25.self_attn.o_proj.qstatistic', 'model.layers.25.self_attn.o_proj.qweight', 'model.layers.25.self_attn.o_proj.qzeros_scales', 'model.layers.25.self_attn.o_proj.qzeros_zeros', 'model.layers.25.self_attn.q_proj.g_idx', 'model.layers.25.self_attn.q_proj.qscales_scales', 'model.layers.25.self_attn.q_proj.qscales_zeros', 'model.layers.25.self_attn.q_proj.qstatistic', 'model.layers.25.self_attn.q_proj.qweight', 'model.layers.25.self_attn.q_proj.qzeros_scales', 'model.layers.25.self_attn.q_proj.qzeros_zeros', 'model.layers.25.self_attn.v_proj.g_idx', 'model.layers.25.self_attn.v_proj.qscales_scales', 'model.layers.25.self_attn.v_proj.qscales_zeros', 'model.layers.25.self_attn.v_proj.qstatistic', 'model.layers.25.self_attn.v_proj.qweight', 'model.layers.25.self_attn.v_proj.qzeros_scales', 'model.layers.25.self_attn.v_proj.qzeros_zeros', 'model.layers.26.mlp.down_proj.g_idx', 'model.layers.26.mlp.down_proj.qscales_scales', 'model.layers.26.mlp.down_proj.qscales_zeros', 'model.layers.26.mlp.down_proj.qstatistic', 'model.layers.26.mlp.down_proj.qweight', 'model.layers.26.mlp.down_proj.qzeros_scales', 'model.layers.26.mlp.down_proj.qzeros_zeros', 'model.layers.26.mlp.gate_proj.g_idx', 'model.layers.26.mlp.gate_proj.qscales_scales', 'model.layers.26.mlp.gate_proj.qscales_zeros', 'model.layers.26.mlp.gate_proj.qstatistic', 'model.layers.26.mlp.gate_proj.qweight', 'model.layers.26.mlp.gate_proj.qzeros_scales', 'model.layers.26.mlp.gate_proj.qzeros_zeros', 'model.layers.26.mlp.up_proj.g_idx', 'model.layers.26.mlp.up_proj.qscales_scales', 'model.layers.26.mlp.up_proj.qscales_zeros', 'model.layers.26.mlp.up_proj.qstatistic', 'model.layers.26.mlp.up_proj.qweight', 'model.layers.26.mlp.up_proj.qzeros_scales', 'model.layers.26.mlp.up_proj.qzeros_zeros', 'model.layers.26.self_attn.k_proj.g_idx', 'model.layers.26.self_attn.k_proj.qscales_scales', 'model.layers.26.self_attn.k_proj.qscales_zeros', 'model.layers.26.self_attn.k_proj.qstatistic', 'model.layers.26.self_attn.k_proj.qweight', 'model.layers.26.self_attn.k_proj.qzeros_scales', 'model.layers.26.self_attn.k_proj.qzeros_zeros', 'model.layers.26.self_attn.o_proj.g_idx', 'model.layers.26.self_attn.o_proj.qscales_scales', 'model.layers.26.self_attn.o_proj.qscales_zeros', 'model.layers.26.self_attn.o_proj.qstatistic', 'model.layers.26.self_attn.o_proj.qweight', 'model.layers.26.self_attn.o_proj.qzeros_scales', 'model.layers.26.self_attn.o_proj.qzeros_zeros', 'model.layers.26.self_attn.q_proj.g_idx', 'model.layers.26.self_attn.q_proj.qscales_scales', 'model.layers.26.self_attn.q_proj.qscales_zeros', 'model.layers.26.self_attn.q_proj.qstatistic', 'model.layers.26.self_attn.q_proj.qweight', 'model.layers.26.self_attn.q_proj.qzeros_scales', 'model.layers.26.self_attn.q_proj.qzeros_zeros', 'model.layers.26.self_attn.v_proj.g_idx', 'model.layers.26.self_attn.v_proj.qscales_scales', 'model.layers.26.self_attn.v_proj.qscales_zeros', 'model.layers.26.self_attn.v_proj.qstatistic', 'model.layers.26.self_attn.v_proj.qweight', 'model.layers.26.self_attn.v_proj.qzeros_scales', 'model.layers.26.self_attn.v_proj.qzeros_zeros', 'model.layers.27.mlp.down_proj.g_idx', 'model.layers.27.mlp.down_proj.qscales_scales', 'model.layers.27.mlp.down_proj.qscales_zeros', 'model.layers.27.mlp.down_proj.qstatistic', 'model.layers.27.mlp.down_proj.qweight', 'model.layers.27.mlp.down_proj.qzeros_scales', 'model.layers.27.mlp.down_proj.qzeros_zeros', 'model.layers.27.mlp.gate_proj.g_idx', 'model.layers.27.mlp.gate_proj.qscales_scales', 'model.layers.27.mlp.gate_proj.qscales_zeros', 'model.layers.27.mlp.gate_proj.qstatistic', 'model.layers.27.mlp.gate_proj.qweight', 'model.layers.27.mlp.gate_proj.qzeros_scales', 'model.layers.27.mlp.gate_proj.qzeros_zeros', 'model.layers.27.mlp.up_proj.g_idx', 'model.layers.27.mlp.up_proj.qscales_scales', 'model.layers.27.mlp.up_proj.qscales_zeros', 'model.layers.27.mlp.up_proj.qstatistic', 'model.layers.27.mlp.up_proj.qweight', 'model.layers.27.mlp.up_proj.qzeros_scales', 'model.layers.27.mlp.up_proj.qzeros_zeros', 'model.layers.27.self_attn.k_proj.g_idx', 'model.layers.27.self_attn.k_proj.qscales_scales', 'model.layers.27.self_attn.k_proj.qscales_zeros', 'model.layers.27.self_attn.k_proj.qstatistic', 'model.layers.27.self_attn.k_proj.qweight', 'model.layers.27.self_attn.k_proj.qzeros_scales', 'model.layers.27.self_attn.k_proj.qzeros_zeros', 'model.layers.27.self_attn.o_proj.g_idx', 'model.layers.27.self_attn.o_proj.qscales_scales', 'model.layers.27.self_attn.o_proj.qscales_zeros', 'model.layers.27.self_attn.o_proj.qstatistic', 'model.layers.27.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qzeros_scales', 'model.layers.27.self_attn.o_proj.qzeros_zeros', 'model.layers.27.self_attn.q_proj.g_idx', 'model.layers.27.self_attn.q_proj.qscales_scales', 'model.layers.27.self_attn.q_proj.qscales_zeros', 'model.layers.27.self_attn.q_proj.qstatistic', 'model.layers.27.self_attn.q_proj.qweight', 'model.layers.27.self_attn.q_proj.qzeros_scales', 'model.layers.27.self_attn.q_proj.qzeros_zeros', 'model.layers.27.self_attn.v_proj.g_idx', 'model.layers.27.self_attn.v_proj.qscales_scales', 'model.layers.27.self_attn.v_proj.qscales_zeros', 'model.layers.27.self_attn.v_proj.qstatistic', 'model.layers.27.self_attn.v_proj.qweight', 'model.layers.27.self_attn.v_proj.qzeros_scales', 'model.layers.27.self_attn.v_proj.qzeros_zeros', 'model.layers.28.mlp.down_proj.g_idx', 'model.layers.28.mlp.down_proj.qscales_scales', 'model.layers.28.mlp.down_proj.qscales_zeros', 'model.layers.28.mlp.down_proj.qstatistic', 'model.layers.28.mlp.down_proj.qweight', 'model.layers.28.mlp.down_proj.qzeros_scales', 'model.layers.28.mlp.down_proj.qzeros_zeros', 'model.layers.28.mlp.gate_proj.g_idx', 'model.layers.28.mlp.gate_proj.qscales_scales', 'model.layers.28.mlp.gate_proj.qscales_zeros', 'model.layers.28.mlp.gate_proj.qstatistic', 'model.layers.28.mlp.gate_proj.qweight', 'model.layers.28.mlp.gate_proj.qzeros_scales', 'model.layers.28.mlp.gate_proj.qzeros_zeros', 'model.layers.28.mlp.up_proj.g_idx', 'model.layers.28.mlp.up_proj.qscales_scales', 'model.layers.28.mlp.up_proj.qscales_zeros', 'model.layers.28.mlp.up_proj.qstatistic', 'model.layers.28.mlp.up_proj.qweight', 'model.layers.28.mlp.up_proj.qzeros_scales', 'model.layers.28.mlp.up_proj.qzeros_zeros', 'model.layers.28.self_attn.k_proj.g_idx', 'model.layers.28.self_attn.k_proj.qscales_scales', 'model.layers.28.self_attn.k_proj.qscales_zeros', 'model.layers.28.self_attn.k_proj.qstatistic', 'model.layers.28.self_attn.k_proj.qweight', 'model.layers.28.self_attn.k_proj.qzeros_scales', 'model.layers.28.self_attn.k_proj.qzeros_zeros', 'model.layers.28.self_attn.o_proj.g_idx', 'model.layers.28.self_attn.o_proj.qscales_scales', 'model.layers.28.self_attn.o_proj.qscales_zeros', 'model.layers.28.self_attn.o_proj.qstatistic', 'model.layers.28.self_attn.o_proj.qweight', 'model.layers.28.self_attn.o_proj.qzeros_scales', 'model.layers.28.self_attn.o_proj.qzeros_zeros', 'model.layers.28.self_attn.q_proj.g_idx', 'model.layers.28.self_attn.q_proj.qscales_scales', 'model.layers.28.self_attn.q_proj.qscales_zeros', 'model.layers.28.self_attn.q_proj.qstatistic', 'model.layers.28.self_attn.q_proj.qweight', 'model.layers.28.self_attn.q_proj.qzeros_scales', 'model.layers.28.self_attn.q_proj.qzeros_zeros', 'model.layers.28.self_attn.v_proj.g_idx', 'model.layers.28.self_attn.v_proj.qscales_scales', 'model.layers.28.self_attn.v_proj.qscales_zeros', 'model.layers.28.self_attn.v_proj.qstatistic', 'model.layers.28.self_attn.v_proj.qweight', 'model.layers.28.self_attn.v_proj.qzeros_scales', 'model.layers.28.self_attn.v_proj.qzeros_zeros', 'model.layers.29.mlp.down_proj.g_idx', 'model.layers.29.mlp.down_proj.qscales_scales', 'model.layers.29.mlp.down_proj.qscales_zeros', 'model.layers.29.mlp.down_proj.qstatistic', 'model.layers.29.mlp.down_proj.qweight', 'model.layers.29.mlp.down_proj.qzeros_scales', 'model.layers.29.mlp.down_proj.qzeros_zeros', 'model.layers.29.mlp.gate_proj.g_idx', 'model.layers.29.mlp.gate_proj.qscales_scales', 'model.layers.29.mlp.gate_proj.qscales_zeros', 'model.layers.29.mlp.gate_proj.qstatistic', 'model.layers.29.mlp.gate_proj.qweight', 'model.layers.29.mlp.gate_proj.qzeros_scales', 'model.layers.29.mlp.gate_proj.qzeros_zeros', 'model.layers.29.mlp.up_proj.g_idx', 'model.layers.29.mlp.up_proj.qscales_scales', 'model.layers.29.mlp.up_proj.qscales_zeros', 'model.layers.29.mlp.up_proj.qstatistic', 'model.layers.29.mlp.up_proj.qweight', 'model.layers.29.mlp.up_proj.qzeros_scales', 'model.layers.29.mlp.up_proj.qzeros_zeros', 'model.layers.29.self_attn.k_proj.g_idx', 'model.layers.29.self_attn.k_proj.qscales_scales', 'model.layers.29.self_attn.k_proj.qscales_zeros', 'model.layers.29.self_attn.k_proj.qstatistic', 'model.layers.29.self_attn.k_proj.qweight', 'model.layers.29.self_attn.k_proj.qzeros_scales', 'model.layers.29.self_attn.k_proj.qzeros_zeros', 'model.layers.29.self_attn.o_proj.g_idx', 'model.layers.29.self_attn.o_proj.qscales_scales', 'model.layers.29.self_attn.o_proj.qscales_zeros', 'model.layers.29.self_attn.o_proj.qstatistic', 'model.layers.29.self_attn.o_proj.qweight', 'model.layers.29.self_attn.o_proj.qzeros_scales', 'model.layers.29.self_attn.o_proj.qzeros_zeros', 'model.layers.29.self_attn.q_proj.g_idx', 'model.layers.29.self_attn.q_proj.qscales_scales', 'model.layers.29.self_attn.q_proj.qscales_zeros', 'model.layers.29.self_attn.q_proj.qstatistic', 'model.layers.29.self_attn.q_proj.qweight', 'model.layers.29.self_attn.q_proj.qzeros_scales', 'model.layers.29.self_attn.q_proj.qzeros_zeros', 'model.layers.29.self_attn.v_proj.g_idx', 'model.layers.29.self_attn.v_proj.qscales_scales', 'model.layers.29.self_attn.v_proj.qscales_zeros', 'model.layers.29.self_attn.v_proj.qstatistic', 'model.layers.29.self_attn.v_proj.qweight', 'model.layers.29.self_attn.v_proj.qzeros_scales', 'model.layers.29.self_attn.v_proj.qzeros_zeros', 'model.layers.3.mlp.down_proj.g_idx', 'model.layers.3.mlp.down_proj.qscales_scales', 'model.layers.3.mlp.down_proj.qscales_zeros', 'model.layers.3.mlp.down_proj.qstatistic', 'model.layers.3.mlp.down_proj.qweight', 'model.layers.3.mlp.down_proj.qzeros_scales', 'model.layers.3.mlp.down_proj.qzeros_zeros', 'model.layers.3.mlp.gate_proj.g_idx', 'model.layers.3.mlp.gate_proj.qscales_scales', 'model.layers.3.mlp.gate_proj.qscales_zeros', 'model.layers.3.mlp.gate_proj.qstatistic', 'model.layers.3.mlp.gate_proj.qweight', 'model.layers.3.mlp.gate_proj.qzeros_scales', 'model.layers.3.mlp.gate_proj.qzeros_zeros', 'model.layers.3.mlp.up_proj.g_idx', 'model.layers.3.mlp.up_proj.qscales_scales', 'model.layers.3.mlp.up_proj.qscales_zeros', 'model.layers.3.mlp.up_proj.qstatistic', 'model.layers.3.mlp.up_proj.qweight', 'model.layers.3.mlp.up_proj.qzeros_scales', 'model.layers.3.mlp.up_proj.qzeros_zeros', 'model.layers.3.self_attn.k_proj.g_idx', 'model.layers.3.self_attn.k_proj.qscales_scales', 'model.layers.3.self_attn.k_proj.qscales_zeros', 'model.layers.3.self_attn.k_proj.qstatistic', 'model.layers.3.self_attn.k_proj.qweight', 'model.layers.3.self_attn.k_proj.qzeros_scales', 'model.layers.3.self_attn.k_proj.qzeros_zeros', 'model.layers.3.self_attn.o_proj.g_idx', 'model.layers.3.self_attn.o_proj.qscales_scales', 'model.layers.3.self_attn.o_proj.qscales_zeros', 'model.layers.3.self_attn.o_proj.qstatistic', 'model.layers.3.self_attn.o_proj.qweight', 'model.layers.3.self_attn.o_proj.qzeros_scales', 'model.layers.3.self_attn.o_proj.qzeros_zeros', 'model.layers.3.self_attn.q_proj.g_idx', 'model.layers.3.self_attn.q_proj.qscales_scales', 'model.layers.3.self_attn.q_proj.qscales_zeros', 'model.layers.3.self_attn.q_proj.qstatistic', 'model.layers.3.self_attn.q_proj.qweight', 'model.layers.3.self_attn.q_proj.qzeros_scales', 'model.layers.3.self_attn.q_proj.qzeros_zeros', 'model.layers.3.self_attn.v_proj.g_idx', 'model.layers.3.self_attn.v_proj.qscales_scales', 'model.layers.3.self_attn.v_proj.qscales_zeros', 'model.layers.3.self_attn.v_proj.qstatistic', 'model.layers.3.self_attn.v_proj.qweight', 'model.layers.3.self_attn.v_proj.qzeros_scales', 'model.layers.3.self_attn.v_proj.qzeros_zeros', 'model.layers.30.mlp.down_proj.g_idx', 'model.layers.30.mlp.down_proj.qscales_scales', 'model.layers.30.mlp.down_proj.qscales_zeros', 'model.layers.30.mlp.down_proj.qstatistic', 'model.layers.30.mlp.down_proj.qweight', 'model.layers.30.mlp.down_proj.qzeros_scales', 'model.layers.30.mlp.down_proj.qzeros_zeros', 'model.layers.30.mlp.gate_proj.g_idx', 'model.layers.30.mlp.gate_proj.qscales_scales', 'model.layers.30.mlp.gate_proj.qscales_zeros', 'model.layers.30.mlp.gate_proj.qstatistic', 'model.layers.30.mlp.gate_proj.qweight', 'model.layers.30.mlp.gate_proj.qzeros_scales', 'model.layers.30.mlp.gate_proj.qzeros_zeros', 'model.layers.30.mlp.up_proj.g_idx', 'model.layers.30.mlp.up_proj.qscales_scales', 'model.layers.30.mlp.up_proj.qscales_zeros', 'model.layers.30.mlp.up_proj.qstatistic', 'model.layers.30.mlp.up_proj.qweight', 'model.layers.30.mlp.up_proj.qzeros_scales', 'model.layers.30.mlp.up_proj.qzeros_zeros', 'model.layers.30.self_attn.k_proj.g_idx', 'model.layers.30.self_attn.k_proj.qscales_scales', 'model.layers.30.self_attn.k_proj.qscales_zeros', 'model.layers.30.self_attn.k_proj.qstatistic', 'model.layers.30.self_attn.k_proj.qweight', 'model.layers.30.self_attn.k_proj.qzeros_scales', 'model.layers.30.self_attn.k_proj.qzeros_zeros', 'model.layers.30.self_attn.o_proj.g_idx', 'model.layers.30.self_attn.o_proj.qscales_scales', 'model.layers.30.self_attn.o_proj.qscales_zeros', 'model.layers.30.self_attn.o_proj.qstatistic', 'model.layers.30.self_attn.o_proj.qweight', 'model.layers.30.self_attn.o_proj.qzeros_scales', 'model.layers.30.self_attn.o_proj.qzeros_zeros', 'model.layers.30.self_attn.q_proj.g_idx', 'model.layers.30.self_attn.q_proj.qscales_scales', 'model.layers.30.self_attn.q_proj.qscales_zeros', 'model.layers.30.self_attn.q_proj.qstatistic', 'model.layers.30.self_attn.q_proj.qweight', 'model.layers.30.self_attn.q_proj.qzeros_scales', 'model.layers.30.self_attn.q_proj.qzeros_zeros', 'model.layers.30.self_attn.v_proj.g_idx', 'model.layers.30.self_attn.v_proj.qscales_scales', 'model.layers.30.self_attn.v_proj.qscales_zeros', 'model.layers.30.self_attn.v_proj.qstatistic', 'model.layers.30.self_attn.v_proj.qweight', 'model.layers.30.self_attn.v_proj.qzeros_scales', 'model.layers.30.self_attn.v_proj.qzeros_zeros', 'model.layers.31.mlp.down_proj.g_idx', 'model.layers.31.mlp.down_proj.qscales_scales', 'model.layers.31.mlp.down_proj.qscales_zeros', 'model.layers.31.mlp.down_proj.qstatistic', 'model.layers.31.mlp.down_proj.qweight', 'model.layers.31.mlp.down_proj.qzeros_scales', 'model.layers.31.mlp.down_proj.qzeros_zeros', 'model.layers.31.mlp.gate_proj.g_idx', 'model.layers.31.mlp.gate_proj.qscales_scales', 'model.layers.31.mlp.gate_proj.qscales_zeros', 'model.layers.31.mlp.gate_proj.qstatistic', 'model.layers.31.mlp.gate_proj.qweight', 'model.layers.31.mlp.gate_proj.qzeros_scales', 'model.layers.31.mlp.gate_proj.qzeros_zeros', 'model.layers.31.mlp.up_proj.g_idx', 'model.layers.31.mlp.up_proj.qscales_scales', 'model.layers.31.mlp.up_proj.qscales_zeros', 'model.layers.31.mlp.up_proj.qstatistic', 'model.layers.31.mlp.up_proj.qweight', 'model.layers.31.mlp.up_proj.qzeros_scales', 'model.layers.31.mlp.up_proj.qzeros_zeros', 'model.layers.31.self_attn.k_proj.g_idx', 'model.layers.31.self_attn.k_proj.qscales_scales', 'model.layers.31.self_attn.k_proj.qscales_zeros', 'model.layers.31.self_attn.k_proj.qstatistic', 'model.layers.31.self_attn.k_proj.qweight', 'model.layers.31.self_attn.k_proj.qzeros_scales', 'model.layers.31.self_attn.k_proj.qzeros_zeros', 'model.layers.31.self_attn.o_proj.g_idx', 'model.layers.31.self_attn.o_proj.qscales_scales', 'model.layers.31.self_attn.o_proj.qscales_zeros', 'model.layers.31.self_attn.o_proj.qstatistic', 'model.layers.31.self_attn.o_proj.qweight', 'model.layers.31.self_attn.o_proj.qzeros_scales', 'model.layers.31.self_attn.o_proj.qzeros_zeros', 'model.layers.31.self_attn.q_proj.g_idx', 'model.layers.31.self_attn.q_proj.qscales_scales', 'model.layers.31.self_attn.q_proj.qscales_zeros', 'model.layers.31.self_attn.q_proj.qstatistic', 'model.layers.31.self_attn.q_proj.qweight', 'model.layers.31.self_attn.q_proj.qzeros_scales', 'model.layers.31.self_attn.q_proj.qzeros_zeros', 'model.layers.31.self_attn.v_proj.g_idx', 'model.layers.31.self_attn.v_proj.qscales_scales', 'model.layers.31.self_attn.v_proj.qscales_zeros', 'model.layers.31.self_attn.v_proj.qstatistic', 'model.layers.31.self_attn.v_proj.qweight', 'model.layers.31.self_attn.v_proj.qzeros_scales', 'model.layers.31.self_attn.v_proj.qzeros_zeros', 'model.layers.4.mlp.down_proj.g_idx', 'model.layers.4.mlp.down_proj.qscales_scales', 'model.layers.4.mlp.down_proj.qscales_zeros', 'model.layers.4.mlp.down_proj.qstatistic', 'model.layers.4.mlp.down_proj.qweight', 'model.layers.4.mlp.down_proj.qzeros_scales', 'model.layers.4.mlp.down_proj.qzeros_zeros', 'model.layers.4.mlp.gate_proj.g_idx', 'model.layers.4.mlp.gate_proj.qscales_scales', 'model.layers.4.mlp.gate_proj.qscales_zeros', 'model.layers.4.mlp.gate_proj.qstatistic', 'model.layers.4.mlp.gate_proj.qweight', 'model.layers.4.mlp.gate_proj.qzeros_scales', 'model.layers.4.mlp.gate_proj.qzeros_zeros', 'model.layers.4.mlp.up_proj.g_idx', 'model.layers.4.mlp.up_proj.qscales_scales', 'model.layers.4.mlp.up_proj.qscales_zeros', 'model.layers.4.mlp.up_proj.qstatistic', 'model.layers.4.mlp.up_proj.qweight', 'model.layers.4.mlp.up_proj.qzeros_scales', 'model.layers.4.mlp.up_proj.qzeros_zeros', 'model.layers.4.self_attn.k_proj.g_idx', 'model.layers.4.self_attn.k_proj.qscales_scales', 'model.layers.4.self_attn.k_proj.qscales_zeros', 'model.layers.4.self_attn.k_proj.qstatistic', 'model.layers.4.self_attn.k_proj.qweight', 'model.layers.4.self_attn.k_proj.qzeros_scales', 'model.layers.4.self_attn.k_proj.qzeros_zeros', 'model.layers.4.self_attn.o_proj.g_idx', 'model.layers.4.self_attn.o_proj.qscales_scales', 'model.layers.4.self_attn.o_proj.qscales_zeros', 'model.layers.4.self_attn.o_proj.qstatistic', 'model.layers.4.self_attn.o_proj.qweight', 'model.layers.4.self_attn.o_proj.qzeros_scales', 'model.layers.4.self_attn.o_proj.qzeros_zeros', 'model.layers.4.self_attn.q_proj.g_idx', 'model.layers.4.self_attn.q_proj.qscales_scales', 'model.layers.4.self_attn.q_proj.qscales_zeros', 'model.layers.4.self_attn.q_proj.qstatistic', 'model.layers.4.self_attn.q_proj.qweight', 'model.layers.4.self_attn.q_proj.qzeros_scales', 'model.layers.4.self_attn.q_proj.qzeros_zeros', 'model.layers.4.self_attn.v_proj.g_idx', 'model.layers.4.self_attn.v_proj.qscales_scales', 'model.layers.4.self_attn.v_proj.qscales_zeros', 'model.layers.4.self_attn.v_proj.qstatistic', 'model.layers.4.self_attn.v_proj.qweight', 'model.layers.4.self_attn.v_proj.qzeros_scales', 'model.layers.4.self_attn.v_proj.qzeros_zeros', 'model.layers.5.mlp.down_proj.g_idx', 'model.layers.5.mlp.down_proj.qscales_scales', 'model.layers.5.mlp.down_proj.qscales_zeros', 'model.layers.5.mlp.down_proj.qstatistic', 'model.layers.5.mlp.down_proj.qweight', 'model.layers.5.mlp.down_proj.qzeros_scales', 'model.layers.5.mlp.down_proj.qzeros_zeros', 'model.layers.5.mlp.gate_proj.g_idx', 'model.layers.5.mlp.gate_proj.qscales_scales', 'model.layers.5.mlp.gate_proj.qscales_zeros', 'model.layers.5.mlp.gate_proj.qstatistic', 'model.layers.5.mlp.gate_proj.qweight', 'model.layers.5.mlp.gate_proj.qzeros_scales', 'model.layers.5.mlp.gate_proj.qzeros_zeros', 'model.layers.5.mlp.up_proj.g_idx', 'model.layers.5.mlp.up_proj.qscales_scales', 'model.layers.5.mlp.up_proj.qscales_zeros', 'model.layers.5.mlp.up_proj.qstatistic', 'model.layers.5.mlp.up_proj.qweight', 'model.layers.5.mlp.up_proj.qzeros_scales', 'model.layers.5.mlp.up_proj.qzeros_zeros', 'model.layers.5.self_attn.k_proj.g_idx', 'model.layers.5.self_attn.k_proj.qscales_scales', 'model.layers.5.self_attn.k_proj.qscales_zeros', 'model.layers.5.self_attn.k_proj.qstatistic', 'model.layers.5.self_attn.k_proj.qweight', 'model.layers.5.self_attn.k_proj.qzeros_scales', 'model.layers.5.self_attn.k_proj.qzeros_zeros', 'model.layers.5.self_attn.o_proj.g_idx', 'model.layers.5.self_attn.o_proj.qscales_scales', 'model.layers.5.self_attn.o_proj.qscales_zeros', 'model.layers.5.self_attn.o_proj.qstatistic', 'model.layers.5.self_attn.o_proj.qweight', 'model.layers.5.self_attn.o_proj.qzeros_scales', 'model.layers.5.self_attn.o_proj.qzeros_zeros', 'model.layers.5.self_attn.q_proj.g_idx', 'model.layers.5.self_attn.q_proj.qscales_scales', 'model.layers.5.self_attn.q_proj.qscales_zeros', 'model.layers.5.self_attn.q_proj.qstatistic', 'model.layers.5.self_attn.q_proj.qweight', 'model.layers.5.self_attn.q_proj.qzeros_scales', 'model.layers.5.self_attn.q_proj.qzeros_zeros', 'model.layers.5.self_attn.v_proj.g_idx', 'model.layers.5.self_attn.v_proj.qscales_scales', 'model.layers.5.self_attn.v_proj.qscales_zeros', 'model.layers.5.self_attn.v_proj.qstatistic', 'model.layers.5.self_attn.v_proj.qweight', 'model.layers.5.self_attn.v_proj.qzeros_scales', 'model.layers.5.self_attn.v_proj.qzeros_zeros', 'model.layers.6.mlp.down_proj.g_idx', 'model.layers.6.mlp.down_proj.qscales_scales', 'model.layers.6.mlp.down_proj.qscales_zeros', 'model.layers.6.mlp.down_proj.qstatistic', 'model.layers.6.mlp.down_proj.qweight', 'model.layers.6.mlp.down_proj.qzeros_scales', 'model.layers.6.mlp.down_proj.qzeros_zeros', 'model.layers.6.mlp.gate_proj.g_idx', 'model.layers.6.mlp.gate_proj.qscales_scales', 'model.layers.6.mlp.gate_proj.qscales_zeros', 'model.layers.6.mlp.gate_proj.qstatistic', 'model.layers.6.mlp.gate_proj.qweight', 'model.layers.6.mlp.gate_proj.qzeros_scales', 'model.layers.6.mlp.gate_proj.qzeros_zeros', 'model.layers.6.mlp.up_proj.g_idx', 'model.layers.6.mlp.up_proj.qscales_scales', 'model.layers.6.mlp.up_proj.qscales_zeros', 'model.layers.6.mlp.up_proj.qstatistic', 'model.layers.6.mlp.up_proj.qweight', 'model.layers.6.mlp.up_proj.qzeros_scales', 'model.layers.6.mlp.up_proj.qzeros_zeros', 'model.layers.6.self_attn.k_proj.g_idx', 'model.layers.6.self_attn.k_proj.qscales_scales', 'model.layers.6.self_attn.k_proj.qscales_zeros', 'model.layers.6.self_attn.k_proj.qstatistic', 'model.layers.6.self_attn.k_proj.qweight', 'model.layers.6.self_attn.k_proj.qzeros_scales', 'model.layers.6.self_attn.k_proj.qzeros_zeros', 'model.layers.6.self_attn.o_proj.g_idx', 'model.layers.6.self_attn.o_proj.qscales_scales', 'model.layers.6.self_attn.o_proj.qscales_zeros', 'model.layers.6.self_attn.o_proj.qstatistic', 'model.layers.6.self_attn.o_proj.qweight', 'model.layers.6.self_attn.o_proj.qzeros_scales', 'model.layers.6.self_attn.o_proj.qzeros_zeros', 'model.layers.6.self_attn.q_proj.g_idx', 'model.layers.6.self_attn.q_proj.qscales_scales', 'model.layers.6.self_attn.q_proj.qscales_zeros', 'model.layers.6.self_attn.q_proj.qstatistic', 'model.layers.6.self_attn.q_proj.qweight', 'model.layers.6.self_attn.q_proj.qzeros_scales', 'model.layers.6.self_attn.q_proj.qzeros_zeros', 'model.layers.6.self_attn.v_proj.g_idx', 'model.layers.6.self_attn.v_proj.qscales_scales', 'model.layers.6.self_attn.v_proj.qscales_zeros', 'model.layers.6.self_attn.v_proj.qstatistic', 'model.layers.6.self_attn.v_proj.qweight', 'model.layers.6.self_attn.v_proj.qzeros_scales', 'model.layers.6.self_attn.v_proj.qzeros_zeros', 'model.layers.7.mlp.down_proj.g_idx', 'model.layers.7.mlp.down_proj.qscales_scales', 'model.layers.7.mlp.down_proj.qscales_zeros', 'model.layers.7.mlp.down_proj.qstatistic', 'model.layers.7.mlp.down_proj.qweight', 'model.layers.7.mlp.down_proj.qzeros_scales', 'model.layers.7.mlp.down_proj.qzeros_zeros', 'model.layers.7.mlp.gate_proj.g_idx', 'model.layers.7.mlp.gate_proj.qscales_scales', 'model.layers.7.mlp.gate_proj.qscales_zeros', 'model.layers.7.mlp.gate_proj.qstatistic', 'model.layers.7.mlp.gate_proj.qweight', 'model.layers.7.mlp.gate_proj.qzeros_scales', 'model.layers.7.mlp.gate_proj.qzeros_zeros', 'model.layers.7.mlp.up_proj.g_idx', 'model.layers.7.mlp.up_proj.qscales_scales', 'model.layers.7.mlp.up_proj.qscales_zeros', 'model.layers.7.mlp.up_proj.qstatistic', 'model.layers.7.mlp.up_proj.qweight', 'model.layers.7.mlp.up_proj.qzeros_scales', 'model.layers.7.mlp.up_proj.qzeros_zeros', 'model.layers.7.self_attn.k_proj.g_idx', 'model.layers.7.self_attn.k_proj.qscales_scales', 'model.layers.7.self_attn.k_proj.qscales_zeros', 'model.layers.7.self_attn.k_proj.qstatistic', 'model.layers.7.self_attn.k_proj.qweight', 'model.layers.7.self_attn.k_proj.qzeros_scales', 'model.layers.7.self_attn.k_proj.qzeros_zeros', 'model.layers.7.self_attn.o_proj.g_idx', 'model.layers.7.self_attn.o_proj.qscales_scales', 'model.layers.7.self_attn.o_proj.qscales_zeros', 'model.layers.7.self_attn.o_proj.qstatistic', 'model.layers.7.self_attn.o_proj.qweight', 'model.layers.7.self_attn.o_proj.qzeros_scales', 'model.layers.7.self_attn.o_proj.qzeros_zeros', 'model.layers.7.self_attn.q_proj.g_idx', 'model.layers.7.self_attn.q_proj.qscales_scales', 'model.layers.7.self_attn.q_proj.qscales_zeros', 'model.layers.7.self_attn.q_proj.qstatistic', 'model.layers.7.self_attn.q_proj.qweight', 'model.layers.7.self_attn.q_proj.qzeros_scales', 'model.layers.7.self_attn.q_proj.qzeros_zeros', 'model.layers.7.self_attn.v_proj.g_idx', 'model.layers.7.self_attn.v_proj.qscales_scales', 'model.layers.7.self_attn.v_proj.qscales_zeros', 'model.layers.7.self_attn.v_proj.qstatistic', 'model.layers.7.self_attn.v_proj.qweight', 'model.layers.7.self_attn.v_proj.qzeros_scales', 'model.layers.7.self_attn.v_proj.qzeros_zeros', 'model.layers.8.mlp.down_proj.g_idx', 'model.layers.8.mlp.down_proj.qscales_scales', 'model.layers.8.mlp.down_proj.qscales_zeros', 'model.layers.8.mlp.down_proj.qstatistic', 'model.layers.8.mlp.down_proj.qweight', 'model.layers.8.mlp.down_proj.qzeros_scales', 'model.layers.8.mlp.down_proj.qzeros_zeros', 'model.layers.8.mlp.gate_proj.g_idx', 'model.layers.8.mlp.gate_proj.qscales_scales', 'model.layers.8.mlp.gate_proj.qscales_zeros', 'model.layers.8.mlp.gate_proj.qstatistic', 'model.layers.8.mlp.gate_proj.qweight', 'model.layers.8.mlp.gate_proj.qzeros_scales', 'model.layers.8.mlp.gate_proj.qzeros_zeros', 'model.layers.8.mlp.up_proj.g_idx', 'model.layers.8.mlp.up_proj.qscales_scales', 'model.layers.8.mlp.up_proj.qscales_zeros', 'model.layers.8.mlp.up_proj.qstatistic', 'model.layers.8.mlp.up_proj.qweight', 'model.layers.8.mlp.up_proj.qzeros_scales', 'model.layers.8.mlp.up_proj.qzeros_zeros', 'model.layers.8.self_attn.k_proj.g_idx', 'model.layers.8.self_attn.k_proj.qscales_scales', 'model.layers.8.self_attn.k_proj.qscales_zeros', 'model.layers.8.self_attn.k_proj.qstatistic', 'model.layers.8.self_attn.k_proj.qweight', 'model.layers.8.self_attn.k_proj.qzeros_scales', 'model.layers.8.self_attn.k_proj.qzeros_zeros', 'model.layers.8.self_attn.o_proj.g_idx', 'model.layers.8.self_attn.o_proj.qscales_scales', 'model.layers.8.self_attn.o_proj.qscales_zeros', 'model.layers.8.self_attn.o_proj.qstatistic', 'model.layers.8.self_attn.o_proj.qweight', 'model.layers.8.self_attn.o_proj.qzeros_scales', 'model.layers.8.self_attn.o_proj.qzeros_zeros', 'model.layers.8.self_attn.q_proj.g_idx', 'model.layers.8.self_attn.q_proj.qscales_scales', 'model.layers.8.self_attn.q_proj.qscales_zeros', 'model.layers.8.self_attn.q_proj.qstatistic', 'model.layers.8.self_attn.q_proj.qweight', 'model.layers.8.self_attn.q_proj.qzeros_scales', 'model.layers.8.self_attn.q_proj.qzeros_zeros', 'model.layers.8.self_attn.v_proj.g_idx', 'model.layers.8.self_attn.v_proj.qscales_scales', 'model.layers.8.self_attn.v_proj.qscales_zeros', 'model.layers.8.self_attn.v_proj.qstatistic', 'model.layers.8.self_attn.v_proj.qweight', 'model.layers.8.self_attn.v_proj.qzeros_scales', 'model.layers.8.self_attn.v_proj.qzeros_zeros', 'model.layers.9.mlp.down_proj.g_idx', 'model.layers.9.mlp.down_proj.qscales_scales', 'model.layers.9.mlp.down_proj.qscales_zeros', 'model.layers.9.mlp.down_proj.qstatistic', 'model.layers.9.mlp.down_proj.qweight', 'model.layers.9.mlp.down_proj.qzeros_scales', 'model.layers.9.mlp.down_proj.qzeros_zeros', 'model.layers.9.mlp.gate_proj.g_idx', 'model.layers.9.mlp.gate_proj.qscales_scales', 'model.layers.9.mlp.gate_proj.qscales_zeros', 'model.layers.9.mlp.gate_proj.qstatistic', 'model.layers.9.mlp.gate_proj.qweight', 'model.layers.9.mlp.gate_proj.qzeros_scales', 'model.layers.9.mlp.gate_proj.qzeros_zeros', 'model.layers.9.mlp.up_proj.g_idx', 'model.layers.9.mlp.up_proj.qscales_scales', 'model.layers.9.mlp.up_proj.qscales_zeros', 'model.layers.9.mlp.up_proj.qstatistic', 'model.layers.9.mlp.up_proj.qweight', 'model.layers.9.mlp.up_proj.qzeros_scales', 'model.layers.9.mlp.up_proj.qzeros_zeros', 'model.layers.9.self_attn.k_proj.g_idx', 'model.layers.9.self_attn.k_proj.qscales_scales', 'model.layers.9.self_attn.k_proj.qscales_zeros', 'model.layers.9.self_attn.k_proj.qstatistic', 'model.layers.9.self_attn.k_proj.qweight', 'model.layers.9.self_attn.k_proj.qzeros_scales', 'model.layers.9.self_attn.k_proj.qzeros_zeros', 'model.layers.9.self_attn.o_proj.g_idx', 'model.layers.9.self_attn.o_proj.qscales_scales', 'model.layers.9.self_attn.o_proj.qscales_zeros', 'model.layers.9.self_attn.o_proj.qstatistic', 'model.layers.9.self_attn.o_proj.qweight', 'model.layers.9.self_attn.o_proj.qzeros_scales', 'model.layers.9.self_attn.o_proj.qzeros_zeros', 'model.layers.9.self_attn.q_proj.g_idx', 'model.layers.9.self_attn.q_proj.qscales_scales', 'model.layers.9.self_attn.q_proj.qscales_zeros', 'model.layers.9.self_attn.q_proj.qstatistic', 'model.layers.9.self_attn.q_proj.qweight', 'model.layers.9.self_attn.q_proj.qzeros_scales', 'model.layers.9.self_attn.q_proj.qzeros_zeros', 'model.layers.9.self_attn.v_proj.g_idx', 'model.layers.9.self_attn.v_proj.qscales_scales', 'model.layers.9.self_attn.v_proj.qscales_zeros', 'model.layers.9.self_attn.v_proj.qstatistic', 'model.layers.9.self_attn.v_proj.qweight', 'model.layers.9.self_attn.v_proj.qzeros_scales', 'model.layers.9.self_attn.v_proj.qzeros_zeros']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83f556fc80944bc5a6f4b78d647e3ae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b1109cca2694ea1a0f940ba0d6fd15b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b70f1ef0b8874f90bf2454c985fc58d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4feb2080a3b04dc997c7ad8b8b68181a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f33c0b29465>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who is Einstein?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GreenBitAI/yi-6b-w4a16g32\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;31m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0mchats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 🐈 🐈 🐈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, prompt_text, prefix, handle_long_generation, add_special_tokens, truncation, padding, max_length, continue_final_message, **generate_kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_final_message\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcontinue_final_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             inputs = self.tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0madd_generation_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcontinue_final_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m         \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_assistant_tokens_mask\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\{\\%-?\\s*generation\\s*-?\\%\\}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_chat_template\u001b[0;34m(self, chat_template, tools)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1823\u001b[0m                     \u001b[0;34m\"Cannot use chat template functions because tokenizer.chat_template is not set and no template \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;34m\"argument was passed! For information about writing templates and setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bwKkeEy-kmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"GreenBitAI/yi-6b-w4a16g32\", cache_dir=\"/content/low_bit_llama/cache/models--GreenBitAI--yi-6b-w4a16g32\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gEcemxTd-9jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "19VUY5gP--FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "question = \"من هو أينشتاين؟\"\n",
        "output = generator(question, max_length=50)\n",
        "print(output[0][\"generated_text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Ry-mMfkw---V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26x9F5a-AO1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IVO21ebAOy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D4aH948fAOwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Yba2bHAAOtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2qBHZesAOpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Assuming you want to use a float16 model and let Transformers automatically handle device placement\n",
        "generator = pipeline(\"chat\", model=\"GreenBitAI/yi-6b-w4a16g32\", torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "question = \"Who is Einstein?\"\n",
        "\n",
        "# Provide the prompt as a chat message:\n",
        "chat_input = [{\"role\": \"user\", \"content\": question}]\n",
        "\n",
        "output = generator(chat_input, max_new_tokens=12)  # Remove return_full_text=False if not needed\n",
        "\n",
        "print(output[0][\"generated_text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "1AJPltOYAPfv",
        "outputId": "90275efd-ab39-412f-b953-c30d07363a3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Unknown task chat, available tasks are ['audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-15fee6147db1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming you want to use a float16 model and let Transformers automatically handle device placement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GreenBitAI/yi-6b-w4a16g32\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who is Einstein?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[1;32m    894\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mnormalized_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mpipeline_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPIPELINE_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m   1451\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid translation task {task}, use 'translation_XX_to_YY' format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m         raise KeyError(\n\u001b[0m\u001b[1;32m   1454\u001b[0m             \u001b[0;34mf\"Unknown task {task}, available tasks are {self.get_supported_tasks() + ['translation_XX_to_YY']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m         )\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Unknown task chat, available tasks are ['audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\""
          ]
        }
      ]
    },
    {
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"GreenBitAI/yi-6b-w4a16g32\", torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "question = \"Who is Einstein?\"\n",
        "\n",
        "# Simulate a conversation with a prompt:\n",
        "prompt = f\"User: {question}\\nAssistant:\"\n",
        "\n",
        "output = generator(prompt, max_new_tokens=12)[0]  # Remove return_full_text=False if not needed\n",
        "\n",
        "print(output[\"generated_text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7TxyrXQAWu3",
        "outputId": "1a725e4e-6cc9-4abe-fbdb-e51c12edba35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at GreenBitAI/yi-6b-w4a16g32 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.g_idx', 'model.layers.0.mlp.down_proj.qscales_scales', 'model.layers.0.mlp.down_proj.qscales_zeros', 'model.layers.0.mlp.down_proj.qstatistic', 'model.layers.0.mlp.down_proj.qweight', 'model.layers.0.mlp.down_proj.qzeros_scales', 'model.layers.0.mlp.down_proj.qzeros_zeros', 'model.layers.0.mlp.gate_proj.g_idx', 'model.layers.0.mlp.gate_proj.qscales_scales', 'model.layers.0.mlp.gate_proj.qscales_zeros', 'model.layers.0.mlp.gate_proj.qstatistic', 'model.layers.0.mlp.gate_proj.qweight', 'model.layers.0.mlp.gate_proj.qzeros_scales', 'model.layers.0.mlp.gate_proj.qzeros_zeros', 'model.layers.0.mlp.up_proj.g_idx', 'model.layers.0.mlp.up_proj.qscales_scales', 'model.layers.0.mlp.up_proj.qscales_zeros', 'model.layers.0.mlp.up_proj.qstatistic', 'model.layers.0.mlp.up_proj.qweight', 'model.layers.0.mlp.up_proj.qzeros_scales', 'model.layers.0.mlp.up_proj.qzeros_zeros', 'model.layers.0.self_attn.k_proj.g_idx', 'model.layers.0.self_attn.k_proj.qscales_scales', 'model.layers.0.self_attn.k_proj.qscales_zeros', 'model.layers.0.self_attn.k_proj.qstatistic', 'model.layers.0.self_attn.k_proj.qweight', 'model.layers.0.self_attn.k_proj.qzeros_scales', 'model.layers.0.self_attn.k_proj.qzeros_zeros', 'model.layers.0.self_attn.o_proj.g_idx', 'model.layers.0.self_attn.o_proj.qscales_scales', 'model.layers.0.self_attn.o_proj.qscales_zeros', 'model.layers.0.self_attn.o_proj.qstatistic', 'model.layers.0.self_attn.o_proj.qweight', 'model.layers.0.self_attn.o_proj.qzeros_scales', 'model.layers.0.self_attn.o_proj.qzeros_zeros', 'model.layers.0.self_attn.q_proj.g_idx', 'model.layers.0.self_attn.q_proj.qscales_scales', 'model.layers.0.self_attn.q_proj.qscales_zeros', 'model.layers.0.self_attn.q_proj.qstatistic', 'model.layers.0.self_attn.q_proj.qweight', 'model.layers.0.self_attn.q_proj.qzeros_scales', 'model.layers.0.self_attn.q_proj.qzeros_zeros', 'model.layers.0.self_attn.v_proj.g_idx', 'model.layers.0.self_attn.v_proj.qscales_scales', 'model.layers.0.self_attn.v_proj.qscales_zeros', 'model.layers.0.self_attn.v_proj.qstatistic', 'model.layers.0.self_attn.v_proj.qweight', 'model.layers.0.self_attn.v_proj.qzeros_scales', 'model.layers.0.self_attn.v_proj.qzeros_zeros', 'model.layers.1.mlp.down_proj.g_idx', 'model.layers.1.mlp.down_proj.qscales_scales', 'model.layers.1.mlp.down_proj.qscales_zeros', 'model.layers.1.mlp.down_proj.qstatistic', 'model.layers.1.mlp.down_proj.qweight', 'model.layers.1.mlp.down_proj.qzeros_scales', 'model.layers.1.mlp.down_proj.qzeros_zeros', 'model.layers.1.mlp.gate_proj.g_idx', 'model.layers.1.mlp.gate_proj.qscales_scales', 'model.layers.1.mlp.gate_proj.qscales_zeros', 'model.layers.1.mlp.gate_proj.qstatistic', 'model.layers.1.mlp.gate_proj.qweight', 'model.layers.1.mlp.gate_proj.qzeros_scales', 'model.layers.1.mlp.gate_proj.qzeros_zeros', 'model.layers.1.mlp.up_proj.g_idx', 'model.layers.1.mlp.up_proj.qscales_scales', 'model.layers.1.mlp.up_proj.qscales_zeros', 'model.layers.1.mlp.up_proj.qstatistic', 'model.layers.1.mlp.up_proj.qweight', 'model.layers.1.mlp.up_proj.qzeros_scales', 'model.layers.1.mlp.up_proj.qzeros_zeros', 'model.layers.1.self_attn.k_proj.g_idx', 'model.layers.1.self_attn.k_proj.qscales_scales', 'model.layers.1.self_attn.k_proj.qscales_zeros', 'model.layers.1.self_attn.k_proj.qstatistic', 'model.layers.1.self_attn.k_proj.qweight', 'model.layers.1.self_attn.k_proj.qzeros_scales', 'model.layers.1.self_attn.k_proj.qzeros_zeros', 'model.layers.1.self_attn.o_proj.g_idx', 'model.layers.1.self_attn.o_proj.qscales_scales', 'model.layers.1.self_attn.o_proj.qscales_zeros', 'model.layers.1.self_attn.o_proj.qstatistic', 'model.layers.1.self_attn.o_proj.qweight', 'model.layers.1.self_attn.o_proj.qzeros_scales', 'model.layers.1.self_attn.o_proj.qzeros_zeros', 'model.layers.1.self_attn.q_proj.g_idx', 'model.layers.1.self_attn.q_proj.qscales_scales', 'model.layers.1.self_attn.q_proj.qscales_zeros', 'model.layers.1.self_attn.q_proj.qstatistic', 'model.layers.1.self_attn.q_proj.qweight', 'model.layers.1.self_attn.q_proj.qzeros_scales', 'model.layers.1.self_attn.q_proj.qzeros_zeros', 'model.layers.1.self_attn.v_proj.g_idx', 'model.layers.1.self_attn.v_proj.qscales_scales', 'model.layers.1.self_attn.v_proj.qscales_zeros', 'model.layers.1.self_attn.v_proj.qstatistic', 'model.layers.1.self_attn.v_proj.qweight', 'model.layers.1.self_attn.v_proj.qzeros_scales', 'model.layers.1.self_attn.v_proj.qzeros_zeros', 'model.layers.10.mlp.down_proj.g_idx', 'model.layers.10.mlp.down_proj.qscales_scales', 'model.layers.10.mlp.down_proj.qscales_zeros', 'model.layers.10.mlp.down_proj.qstatistic', 'model.layers.10.mlp.down_proj.qweight', 'model.layers.10.mlp.down_proj.qzeros_scales', 'model.layers.10.mlp.down_proj.qzeros_zeros', 'model.layers.10.mlp.gate_proj.g_idx', 'model.layers.10.mlp.gate_proj.qscales_scales', 'model.layers.10.mlp.gate_proj.qscales_zeros', 'model.layers.10.mlp.gate_proj.qstatistic', 'model.layers.10.mlp.gate_proj.qweight', 'model.layers.10.mlp.gate_proj.qzeros_scales', 'model.layers.10.mlp.gate_proj.qzeros_zeros', 'model.layers.10.mlp.up_proj.g_idx', 'model.layers.10.mlp.up_proj.qscales_scales', 'model.layers.10.mlp.up_proj.qscales_zeros', 'model.layers.10.mlp.up_proj.qstatistic', 'model.layers.10.mlp.up_proj.qweight', 'model.layers.10.mlp.up_proj.qzeros_scales', 'model.layers.10.mlp.up_proj.qzeros_zeros', 'model.layers.10.self_attn.k_proj.g_idx', 'model.layers.10.self_attn.k_proj.qscales_scales', 'model.layers.10.self_attn.k_proj.qscales_zeros', 'model.layers.10.self_attn.k_proj.qstatistic', 'model.layers.10.self_attn.k_proj.qweight', 'model.layers.10.self_attn.k_proj.qzeros_scales', 'model.layers.10.self_attn.k_proj.qzeros_zeros', 'model.layers.10.self_attn.o_proj.g_idx', 'model.layers.10.self_attn.o_proj.qscales_scales', 'model.layers.10.self_attn.o_proj.qscales_zeros', 'model.layers.10.self_attn.o_proj.qstatistic', 'model.layers.10.self_attn.o_proj.qweight', 'model.layers.10.self_attn.o_proj.qzeros_scales', 'model.layers.10.self_attn.o_proj.qzeros_zeros', 'model.layers.10.self_attn.q_proj.g_idx', 'model.layers.10.self_attn.q_proj.qscales_scales', 'model.layers.10.self_attn.q_proj.qscales_zeros', 'model.layers.10.self_attn.q_proj.qstatistic', 'model.layers.10.self_attn.q_proj.qweight', 'model.layers.10.self_attn.q_proj.qzeros_scales', 'model.layers.10.self_attn.q_proj.qzeros_zeros', 'model.layers.10.self_attn.v_proj.g_idx', 'model.layers.10.self_attn.v_proj.qscales_scales', 'model.layers.10.self_attn.v_proj.qscales_zeros', 'model.layers.10.self_attn.v_proj.qstatistic', 'model.layers.10.self_attn.v_proj.qweight', 'model.layers.10.self_attn.v_proj.qzeros_scales', 'model.layers.10.self_attn.v_proj.qzeros_zeros', 'model.layers.11.mlp.down_proj.g_idx', 'model.layers.11.mlp.down_proj.qscales_scales', 'model.layers.11.mlp.down_proj.qscales_zeros', 'model.layers.11.mlp.down_proj.qstatistic', 'model.layers.11.mlp.down_proj.qweight', 'model.layers.11.mlp.down_proj.qzeros_scales', 'model.layers.11.mlp.down_proj.qzeros_zeros', 'model.layers.11.mlp.gate_proj.g_idx', 'model.layers.11.mlp.gate_proj.qscales_scales', 'model.layers.11.mlp.gate_proj.qscales_zeros', 'model.layers.11.mlp.gate_proj.qstatistic', 'model.layers.11.mlp.gate_proj.qweight', 'model.layers.11.mlp.gate_proj.qzeros_scales', 'model.layers.11.mlp.gate_proj.qzeros_zeros', 'model.layers.11.mlp.up_proj.g_idx', 'model.layers.11.mlp.up_proj.qscales_scales', 'model.layers.11.mlp.up_proj.qscales_zeros', 'model.layers.11.mlp.up_proj.qstatistic', 'model.layers.11.mlp.up_proj.qweight', 'model.layers.11.mlp.up_proj.qzeros_scales', 'model.layers.11.mlp.up_proj.qzeros_zeros', 'model.layers.11.self_attn.k_proj.g_idx', 'model.layers.11.self_attn.k_proj.qscales_scales', 'model.layers.11.self_attn.k_proj.qscales_zeros', 'model.layers.11.self_attn.k_proj.qstatistic', 'model.layers.11.self_attn.k_proj.qweight', 'model.layers.11.self_attn.k_proj.qzeros_scales', 'model.layers.11.self_attn.k_proj.qzeros_zeros', 'model.layers.11.self_attn.o_proj.g_idx', 'model.layers.11.self_attn.o_proj.qscales_scales', 'model.layers.11.self_attn.o_proj.qscales_zeros', 'model.layers.11.self_attn.o_proj.qstatistic', 'model.layers.11.self_attn.o_proj.qweight', 'model.layers.11.self_attn.o_proj.qzeros_scales', 'model.layers.11.self_attn.o_proj.qzeros_zeros', 'model.layers.11.self_attn.q_proj.g_idx', 'model.layers.11.self_attn.q_proj.qscales_scales', 'model.layers.11.self_attn.q_proj.qscales_zeros', 'model.layers.11.self_attn.q_proj.qstatistic', 'model.layers.11.self_attn.q_proj.qweight', 'model.layers.11.self_attn.q_proj.qzeros_scales', 'model.layers.11.self_attn.q_proj.qzeros_zeros', 'model.layers.11.self_attn.v_proj.g_idx', 'model.layers.11.self_attn.v_proj.qscales_scales', 'model.layers.11.self_attn.v_proj.qscales_zeros', 'model.layers.11.self_attn.v_proj.qstatistic', 'model.layers.11.self_attn.v_proj.qweight', 'model.layers.11.self_attn.v_proj.qzeros_scales', 'model.layers.11.self_attn.v_proj.qzeros_zeros', 'model.layers.12.mlp.down_proj.g_idx', 'model.layers.12.mlp.down_proj.qscales_scales', 'model.layers.12.mlp.down_proj.qscales_zeros', 'model.layers.12.mlp.down_proj.qstatistic', 'model.layers.12.mlp.down_proj.qweight', 'model.layers.12.mlp.down_proj.qzeros_scales', 'model.layers.12.mlp.down_proj.qzeros_zeros', 'model.layers.12.mlp.gate_proj.g_idx', 'model.layers.12.mlp.gate_proj.qscales_scales', 'model.layers.12.mlp.gate_proj.qscales_zeros', 'model.layers.12.mlp.gate_proj.qstatistic', 'model.layers.12.mlp.gate_proj.qweight', 'model.layers.12.mlp.gate_proj.qzeros_scales', 'model.layers.12.mlp.gate_proj.qzeros_zeros', 'model.layers.12.mlp.up_proj.g_idx', 'model.layers.12.mlp.up_proj.qscales_scales', 'model.layers.12.mlp.up_proj.qscales_zeros', 'model.layers.12.mlp.up_proj.qstatistic', 'model.layers.12.mlp.up_proj.qweight', 'model.layers.12.mlp.up_proj.qzeros_scales', 'model.layers.12.mlp.up_proj.qzeros_zeros', 'model.layers.12.self_attn.k_proj.g_idx', 'model.layers.12.self_attn.k_proj.qscales_scales', 'model.layers.12.self_attn.k_proj.qscales_zeros', 'model.layers.12.self_attn.k_proj.qstatistic', 'model.layers.12.self_attn.k_proj.qweight', 'model.layers.12.self_attn.k_proj.qzeros_scales', 'model.layers.12.self_attn.k_proj.qzeros_zeros', 'model.layers.12.self_attn.o_proj.g_idx', 'model.layers.12.self_attn.o_proj.qscales_scales', 'model.layers.12.self_attn.o_proj.qscales_zeros', 'model.layers.12.self_attn.o_proj.qstatistic', 'model.layers.12.self_attn.o_proj.qweight', 'model.layers.12.self_attn.o_proj.qzeros_scales', 'model.layers.12.self_attn.o_proj.qzeros_zeros', 'model.layers.12.self_attn.q_proj.g_idx', 'model.layers.12.self_attn.q_proj.qscales_scales', 'model.layers.12.self_attn.q_proj.qscales_zeros', 'model.layers.12.self_attn.q_proj.qstatistic', 'model.layers.12.self_attn.q_proj.qweight', 'model.layers.12.self_attn.q_proj.qzeros_scales', 'model.layers.12.self_attn.q_proj.qzeros_zeros', 'model.layers.12.self_attn.v_proj.g_idx', 'model.layers.12.self_attn.v_proj.qscales_scales', 'model.layers.12.self_attn.v_proj.qscales_zeros', 'model.layers.12.self_attn.v_proj.qstatistic', 'model.layers.12.self_attn.v_proj.qweight', 'model.layers.12.self_attn.v_proj.qzeros_scales', 'model.layers.12.self_attn.v_proj.qzeros_zeros', 'model.layers.13.mlp.down_proj.g_idx', 'model.layers.13.mlp.down_proj.qscales_scales', 'model.layers.13.mlp.down_proj.qscales_zeros', 'model.layers.13.mlp.down_proj.qstatistic', 'model.layers.13.mlp.down_proj.qweight', 'model.layers.13.mlp.down_proj.qzeros_scales', 'model.layers.13.mlp.down_proj.qzeros_zeros', 'model.layers.13.mlp.gate_proj.g_idx', 'model.layers.13.mlp.gate_proj.qscales_scales', 'model.layers.13.mlp.gate_proj.qscales_zeros', 'model.layers.13.mlp.gate_proj.qstatistic', 'model.layers.13.mlp.gate_proj.qweight', 'model.layers.13.mlp.gate_proj.qzeros_scales', 'model.layers.13.mlp.gate_proj.qzeros_zeros', 'model.layers.13.mlp.up_proj.g_idx', 'model.layers.13.mlp.up_proj.qscales_scales', 'model.layers.13.mlp.up_proj.qscales_zeros', 'model.layers.13.mlp.up_proj.qstatistic', 'model.layers.13.mlp.up_proj.qweight', 'model.layers.13.mlp.up_proj.qzeros_scales', 'model.layers.13.mlp.up_proj.qzeros_zeros', 'model.layers.13.self_attn.k_proj.g_idx', 'model.layers.13.self_attn.k_proj.qscales_scales', 'model.layers.13.self_attn.k_proj.qscales_zeros', 'model.layers.13.self_attn.k_proj.qstatistic', 'model.layers.13.self_attn.k_proj.qweight', 'model.layers.13.self_attn.k_proj.qzeros_scales', 'model.layers.13.self_attn.k_proj.qzeros_zeros', 'model.layers.13.self_attn.o_proj.g_idx', 'model.layers.13.self_attn.o_proj.qscales_scales', 'model.layers.13.self_attn.o_proj.qscales_zeros', 'model.layers.13.self_attn.o_proj.qstatistic', 'model.layers.13.self_attn.o_proj.qweight', 'model.layers.13.self_attn.o_proj.qzeros_scales', 'model.layers.13.self_attn.o_proj.qzeros_zeros', 'model.layers.13.self_attn.q_proj.g_idx', 'model.layers.13.self_attn.q_proj.qscales_scales', 'model.layers.13.self_attn.q_proj.qscales_zeros', 'model.layers.13.self_attn.q_proj.qstatistic', 'model.layers.13.self_attn.q_proj.qweight', 'model.layers.13.self_attn.q_proj.qzeros_scales', 'model.layers.13.self_attn.q_proj.qzeros_zeros', 'model.layers.13.self_attn.v_proj.g_idx', 'model.layers.13.self_attn.v_proj.qscales_scales', 'model.layers.13.self_attn.v_proj.qscales_zeros', 'model.layers.13.self_attn.v_proj.qstatistic', 'model.layers.13.self_attn.v_proj.qweight', 'model.layers.13.self_attn.v_proj.qzeros_scales', 'model.layers.13.self_attn.v_proj.qzeros_zeros', 'model.layers.14.mlp.down_proj.g_idx', 'model.layers.14.mlp.down_proj.qscales_scales', 'model.layers.14.mlp.down_proj.qscales_zeros', 'model.layers.14.mlp.down_proj.qstatistic', 'model.layers.14.mlp.down_proj.qweight', 'model.layers.14.mlp.down_proj.qzeros_scales', 'model.layers.14.mlp.down_proj.qzeros_zeros', 'model.layers.14.mlp.gate_proj.g_idx', 'model.layers.14.mlp.gate_proj.qscales_scales', 'model.layers.14.mlp.gate_proj.qscales_zeros', 'model.layers.14.mlp.gate_proj.qstatistic', 'model.layers.14.mlp.gate_proj.qweight', 'model.layers.14.mlp.gate_proj.qzeros_scales', 'model.layers.14.mlp.gate_proj.qzeros_zeros', 'model.layers.14.mlp.up_proj.g_idx', 'model.layers.14.mlp.up_proj.qscales_scales', 'model.layers.14.mlp.up_proj.qscales_zeros', 'model.layers.14.mlp.up_proj.qstatistic', 'model.layers.14.mlp.up_proj.qweight', 'model.layers.14.mlp.up_proj.qzeros_scales', 'model.layers.14.mlp.up_proj.qzeros_zeros', 'model.layers.14.self_attn.k_proj.g_idx', 'model.layers.14.self_attn.k_proj.qscales_scales', 'model.layers.14.self_attn.k_proj.qscales_zeros', 'model.layers.14.self_attn.k_proj.qstatistic', 'model.layers.14.self_attn.k_proj.qweight', 'model.layers.14.self_attn.k_proj.qzeros_scales', 'model.layers.14.self_attn.k_proj.qzeros_zeros', 'model.layers.14.self_attn.o_proj.g_idx', 'model.layers.14.self_attn.o_proj.qscales_scales', 'model.layers.14.self_attn.o_proj.qscales_zeros', 'model.layers.14.self_attn.o_proj.qstatistic', 'model.layers.14.self_attn.o_proj.qweight', 'model.layers.14.self_attn.o_proj.qzeros_scales', 'model.layers.14.self_attn.o_proj.qzeros_zeros', 'model.layers.14.self_attn.q_proj.g_idx', 'model.layers.14.self_attn.q_proj.qscales_scales', 'model.layers.14.self_attn.q_proj.qscales_zeros', 'model.layers.14.self_attn.q_proj.qstatistic', 'model.layers.14.self_attn.q_proj.qweight', 'model.layers.14.self_attn.q_proj.qzeros_scales', 'model.layers.14.self_attn.q_proj.qzeros_zeros', 'model.layers.14.self_attn.v_proj.g_idx', 'model.layers.14.self_attn.v_proj.qscales_scales', 'model.layers.14.self_attn.v_proj.qscales_zeros', 'model.layers.14.self_attn.v_proj.qstatistic', 'model.layers.14.self_attn.v_proj.qweight', 'model.layers.14.self_attn.v_proj.qzeros_scales', 'model.layers.14.self_attn.v_proj.qzeros_zeros', 'model.layers.15.mlp.down_proj.g_idx', 'model.layers.15.mlp.down_proj.qscales_scales', 'model.layers.15.mlp.down_proj.qscales_zeros', 'model.layers.15.mlp.down_proj.qstatistic', 'model.layers.15.mlp.down_proj.qweight', 'model.layers.15.mlp.down_proj.qzeros_scales', 'model.layers.15.mlp.down_proj.qzeros_zeros', 'model.layers.15.mlp.gate_proj.g_idx', 'model.layers.15.mlp.gate_proj.qscales_scales', 'model.layers.15.mlp.gate_proj.qscales_zeros', 'model.layers.15.mlp.gate_proj.qstatistic', 'model.layers.15.mlp.gate_proj.qweight', 'model.layers.15.mlp.gate_proj.qzeros_scales', 'model.layers.15.mlp.gate_proj.qzeros_zeros', 'model.layers.15.mlp.up_proj.g_idx', 'model.layers.15.mlp.up_proj.qscales_scales', 'model.layers.15.mlp.up_proj.qscales_zeros', 'model.layers.15.mlp.up_proj.qstatistic', 'model.layers.15.mlp.up_proj.qweight', 'model.layers.15.mlp.up_proj.qzeros_scales', 'model.layers.15.mlp.up_proj.qzeros_zeros', 'model.layers.15.self_attn.k_proj.g_idx', 'model.layers.15.self_attn.k_proj.qscales_scales', 'model.layers.15.self_attn.k_proj.qscales_zeros', 'model.layers.15.self_attn.k_proj.qstatistic', 'model.layers.15.self_attn.k_proj.qweight', 'model.layers.15.self_attn.k_proj.qzeros_scales', 'model.layers.15.self_attn.k_proj.qzeros_zeros', 'model.layers.15.self_attn.o_proj.g_idx', 'model.layers.15.self_attn.o_proj.qscales_scales', 'model.layers.15.self_attn.o_proj.qscales_zeros', 'model.layers.15.self_attn.o_proj.qstatistic', 'model.layers.15.self_attn.o_proj.qweight', 'model.layers.15.self_attn.o_proj.qzeros_scales', 'model.layers.15.self_attn.o_proj.qzeros_zeros', 'model.layers.15.self_attn.q_proj.g_idx', 'model.layers.15.self_attn.q_proj.qscales_scales', 'model.layers.15.self_attn.q_proj.qscales_zeros', 'model.layers.15.self_attn.q_proj.qstatistic', 'model.layers.15.self_attn.q_proj.qweight', 'model.layers.15.self_attn.q_proj.qzeros_scales', 'model.layers.15.self_attn.q_proj.qzeros_zeros', 'model.layers.15.self_attn.v_proj.g_idx', 'model.layers.15.self_attn.v_proj.qscales_scales', 'model.layers.15.self_attn.v_proj.qscales_zeros', 'model.layers.15.self_attn.v_proj.qstatistic', 'model.layers.15.self_attn.v_proj.qweight', 'model.layers.15.self_attn.v_proj.qzeros_scales', 'model.layers.15.self_attn.v_proj.qzeros_zeros', 'model.layers.16.mlp.down_proj.g_idx', 'model.layers.16.mlp.down_proj.qscales_scales', 'model.layers.16.mlp.down_proj.qscales_zeros', 'model.layers.16.mlp.down_proj.qstatistic', 'model.layers.16.mlp.down_proj.qweight', 'model.layers.16.mlp.down_proj.qzeros_scales', 'model.layers.16.mlp.down_proj.qzeros_zeros', 'model.layers.16.mlp.gate_proj.g_idx', 'model.layers.16.mlp.gate_proj.qscales_scales', 'model.layers.16.mlp.gate_proj.qscales_zeros', 'model.layers.16.mlp.gate_proj.qstatistic', 'model.layers.16.mlp.gate_proj.qweight', 'model.layers.16.mlp.gate_proj.qzeros_scales', 'model.layers.16.mlp.gate_proj.qzeros_zeros', 'model.layers.16.mlp.up_proj.g_idx', 'model.layers.16.mlp.up_proj.qscales_scales', 'model.layers.16.mlp.up_proj.qscales_zeros', 'model.layers.16.mlp.up_proj.qstatistic', 'model.layers.16.mlp.up_proj.qweight', 'model.layers.16.mlp.up_proj.qzeros_scales', 'model.layers.16.mlp.up_proj.qzeros_zeros', 'model.layers.16.self_attn.k_proj.g_idx', 'model.layers.16.self_attn.k_proj.qscales_scales', 'model.layers.16.self_attn.k_proj.qscales_zeros', 'model.layers.16.self_attn.k_proj.qstatistic', 'model.layers.16.self_attn.k_proj.qweight', 'model.layers.16.self_attn.k_proj.qzeros_scales', 'model.layers.16.self_attn.k_proj.qzeros_zeros', 'model.layers.16.self_attn.o_proj.g_idx', 'model.layers.16.self_attn.o_proj.qscales_scales', 'model.layers.16.self_attn.o_proj.qscales_zeros', 'model.layers.16.self_attn.o_proj.qstatistic', 'model.layers.16.self_attn.o_proj.qweight', 'model.layers.16.self_attn.o_proj.qzeros_scales', 'model.layers.16.self_attn.o_proj.qzeros_zeros', 'model.layers.16.self_attn.q_proj.g_idx', 'model.layers.16.self_attn.q_proj.qscales_scales', 'model.layers.16.self_attn.q_proj.qscales_zeros', 'model.layers.16.self_attn.q_proj.qstatistic', 'model.layers.16.self_attn.q_proj.qweight', 'model.layers.16.self_attn.q_proj.qzeros_scales', 'model.layers.16.self_attn.q_proj.qzeros_zeros', 'model.layers.16.self_attn.v_proj.g_idx', 'model.layers.16.self_attn.v_proj.qscales_scales', 'model.layers.16.self_attn.v_proj.qscales_zeros', 'model.layers.16.self_attn.v_proj.qstatistic', 'model.layers.16.self_attn.v_proj.qweight', 'model.layers.16.self_attn.v_proj.qzeros_scales', 'model.layers.16.self_attn.v_proj.qzeros_zeros', 'model.layers.17.mlp.down_proj.g_idx', 'model.layers.17.mlp.down_proj.qscales_scales', 'model.layers.17.mlp.down_proj.qscales_zeros', 'model.layers.17.mlp.down_proj.qstatistic', 'model.layers.17.mlp.down_proj.qweight', 'model.layers.17.mlp.down_proj.qzeros_scales', 'model.layers.17.mlp.down_proj.qzeros_zeros', 'model.layers.17.mlp.gate_proj.g_idx', 'model.layers.17.mlp.gate_proj.qscales_scales', 'model.layers.17.mlp.gate_proj.qscales_zeros', 'model.layers.17.mlp.gate_proj.qstatistic', 'model.layers.17.mlp.gate_proj.qweight', 'model.layers.17.mlp.gate_proj.qzeros_scales', 'model.layers.17.mlp.gate_proj.qzeros_zeros', 'model.layers.17.mlp.up_proj.g_idx', 'model.layers.17.mlp.up_proj.qscales_scales', 'model.layers.17.mlp.up_proj.qscales_zeros', 'model.layers.17.mlp.up_proj.qstatistic', 'model.layers.17.mlp.up_proj.qweight', 'model.layers.17.mlp.up_proj.qzeros_scales', 'model.layers.17.mlp.up_proj.qzeros_zeros', 'model.layers.17.self_attn.k_proj.g_idx', 'model.layers.17.self_attn.k_proj.qscales_scales', 'model.layers.17.self_attn.k_proj.qscales_zeros', 'model.layers.17.self_attn.k_proj.qstatistic', 'model.layers.17.self_attn.k_proj.qweight', 'model.layers.17.self_attn.k_proj.qzeros_scales', 'model.layers.17.self_attn.k_proj.qzeros_zeros', 'model.layers.17.self_attn.o_proj.g_idx', 'model.layers.17.self_attn.o_proj.qscales_scales', 'model.layers.17.self_attn.o_proj.qscales_zeros', 'model.layers.17.self_attn.o_proj.qstatistic', 'model.layers.17.self_attn.o_proj.qweight', 'model.layers.17.self_attn.o_proj.qzeros_scales', 'model.layers.17.self_attn.o_proj.qzeros_zeros', 'model.layers.17.self_attn.q_proj.g_idx', 'model.layers.17.self_attn.q_proj.qscales_scales', 'model.layers.17.self_attn.q_proj.qscales_zeros', 'model.layers.17.self_attn.q_proj.qstatistic', 'model.layers.17.self_attn.q_proj.qweight', 'model.layers.17.self_attn.q_proj.qzeros_scales', 'model.layers.17.self_attn.q_proj.qzeros_zeros', 'model.layers.17.self_attn.v_proj.g_idx', 'model.layers.17.self_attn.v_proj.qscales_scales', 'model.layers.17.self_attn.v_proj.qscales_zeros', 'model.layers.17.self_attn.v_proj.qstatistic', 'model.layers.17.self_attn.v_proj.qweight', 'model.layers.17.self_attn.v_proj.qzeros_scales', 'model.layers.17.self_attn.v_proj.qzeros_zeros', 'model.layers.18.mlp.down_proj.g_idx', 'model.layers.18.mlp.down_proj.qscales_scales', 'model.layers.18.mlp.down_proj.qscales_zeros', 'model.layers.18.mlp.down_proj.qstatistic', 'model.layers.18.mlp.down_proj.qweight', 'model.layers.18.mlp.down_proj.qzeros_scales', 'model.layers.18.mlp.down_proj.qzeros_zeros', 'model.layers.18.mlp.gate_proj.g_idx', 'model.layers.18.mlp.gate_proj.qscales_scales', 'model.layers.18.mlp.gate_proj.qscales_zeros', 'model.layers.18.mlp.gate_proj.qstatistic', 'model.layers.18.mlp.gate_proj.qweight', 'model.layers.18.mlp.gate_proj.qzeros_scales', 'model.layers.18.mlp.gate_proj.qzeros_zeros', 'model.layers.18.mlp.up_proj.g_idx', 'model.layers.18.mlp.up_proj.qscales_scales', 'model.layers.18.mlp.up_proj.qscales_zeros', 'model.layers.18.mlp.up_proj.qstatistic', 'model.layers.18.mlp.up_proj.qweight', 'model.layers.18.mlp.up_proj.qzeros_scales', 'model.layers.18.mlp.up_proj.qzeros_zeros', 'model.layers.18.self_attn.k_proj.g_idx', 'model.layers.18.self_attn.k_proj.qscales_scales', 'model.layers.18.self_attn.k_proj.qscales_zeros', 'model.layers.18.self_attn.k_proj.qstatistic', 'model.layers.18.self_attn.k_proj.qweight', 'model.layers.18.self_attn.k_proj.qzeros_scales', 'model.layers.18.self_attn.k_proj.qzeros_zeros', 'model.layers.18.self_attn.o_proj.g_idx', 'model.layers.18.self_attn.o_proj.qscales_scales', 'model.layers.18.self_attn.o_proj.qscales_zeros', 'model.layers.18.self_attn.o_proj.qstatistic', 'model.layers.18.self_attn.o_proj.qweight', 'model.layers.18.self_attn.o_proj.qzeros_scales', 'model.layers.18.self_attn.o_proj.qzeros_zeros', 'model.layers.18.self_attn.q_proj.g_idx', 'model.layers.18.self_attn.q_proj.qscales_scales', 'model.layers.18.self_attn.q_proj.qscales_zeros', 'model.layers.18.self_attn.q_proj.qstatistic', 'model.layers.18.self_attn.q_proj.qweight', 'model.layers.18.self_attn.q_proj.qzeros_scales', 'model.layers.18.self_attn.q_proj.qzeros_zeros', 'model.layers.18.self_attn.v_proj.g_idx', 'model.layers.18.self_attn.v_proj.qscales_scales', 'model.layers.18.self_attn.v_proj.qscales_zeros', 'model.layers.18.self_attn.v_proj.qstatistic', 'model.layers.18.self_attn.v_proj.qweight', 'model.layers.18.self_attn.v_proj.qzeros_scales', 'model.layers.18.self_attn.v_proj.qzeros_zeros', 'model.layers.19.mlp.down_proj.g_idx', 'model.layers.19.mlp.down_proj.qscales_scales', 'model.layers.19.mlp.down_proj.qscales_zeros', 'model.layers.19.mlp.down_proj.qstatistic', 'model.layers.19.mlp.down_proj.qweight', 'model.layers.19.mlp.down_proj.qzeros_scales', 'model.layers.19.mlp.down_proj.qzeros_zeros', 'model.layers.19.mlp.gate_proj.g_idx', 'model.layers.19.mlp.gate_proj.qscales_scales', 'model.layers.19.mlp.gate_proj.qscales_zeros', 'model.layers.19.mlp.gate_proj.qstatistic', 'model.layers.19.mlp.gate_proj.qweight', 'model.layers.19.mlp.gate_proj.qzeros_scales', 'model.layers.19.mlp.gate_proj.qzeros_zeros', 'model.layers.19.mlp.up_proj.g_idx', 'model.layers.19.mlp.up_proj.qscales_scales', 'model.layers.19.mlp.up_proj.qscales_zeros', 'model.layers.19.mlp.up_proj.qstatistic', 'model.layers.19.mlp.up_proj.qweight', 'model.layers.19.mlp.up_proj.qzeros_scales', 'model.layers.19.mlp.up_proj.qzeros_zeros', 'model.layers.19.self_attn.k_proj.g_idx', 'model.layers.19.self_attn.k_proj.qscales_scales', 'model.layers.19.self_attn.k_proj.qscales_zeros', 'model.layers.19.self_attn.k_proj.qstatistic', 'model.layers.19.self_attn.k_proj.qweight', 'model.layers.19.self_attn.k_proj.qzeros_scales', 'model.layers.19.self_attn.k_proj.qzeros_zeros', 'model.layers.19.self_attn.o_proj.g_idx', 'model.layers.19.self_attn.o_proj.qscales_scales', 'model.layers.19.self_attn.o_proj.qscales_zeros', 'model.layers.19.self_attn.o_proj.qstatistic', 'model.layers.19.self_attn.o_proj.qweight', 'model.layers.19.self_attn.o_proj.qzeros_scales', 'model.layers.19.self_attn.o_proj.qzeros_zeros', 'model.layers.19.self_attn.q_proj.g_idx', 'model.layers.19.self_attn.q_proj.qscales_scales', 'model.layers.19.self_attn.q_proj.qscales_zeros', 'model.layers.19.self_attn.q_proj.qstatistic', 'model.layers.19.self_attn.q_proj.qweight', 'model.layers.19.self_attn.q_proj.qzeros_scales', 'model.layers.19.self_attn.q_proj.qzeros_zeros', 'model.layers.19.self_attn.v_proj.g_idx', 'model.layers.19.self_attn.v_proj.qscales_scales', 'model.layers.19.self_attn.v_proj.qscales_zeros', 'model.layers.19.self_attn.v_proj.qstatistic', 'model.layers.19.self_attn.v_proj.qweight', 'model.layers.19.self_attn.v_proj.qzeros_scales', 'model.layers.19.self_attn.v_proj.qzeros_zeros', 'model.layers.2.mlp.down_proj.g_idx', 'model.layers.2.mlp.down_proj.qscales_scales', 'model.layers.2.mlp.down_proj.qscales_zeros', 'model.layers.2.mlp.down_proj.qstatistic', 'model.layers.2.mlp.down_proj.qweight', 'model.layers.2.mlp.down_proj.qzeros_scales', 'model.layers.2.mlp.down_proj.qzeros_zeros', 'model.layers.2.mlp.gate_proj.g_idx', 'model.layers.2.mlp.gate_proj.qscales_scales', 'model.layers.2.mlp.gate_proj.qscales_zeros', 'model.layers.2.mlp.gate_proj.qstatistic', 'model.layers.2.mlp.gate_proj.qweight', 'model.layers.2.mlp.gate_proj.qzeros_scales', 'model.layers.2.mlp.gate_proj.qzeros_zeros', 'model.layers.2.mlp.up_proj.g_idx', 'model.layers.2.mlp.up_proj.qscales_scales', 'model.layers.2.mlp.up_proj.qscales_zeros', 'model.layers.2.mlp.up_proj.qstatistic', 'model.layers.2.mlp.up_proj.qweight', 'model.layers.2.mlp.up_proj.qzeros_scales', 'model.layers.2.mlp.up_proj.qzeros_zeros', 'model.layers.2.self_attn.k_proj.g_idx', 'model.layers.2.self_attn.k_proj.qscales_scales', 'model.layers.2.self_attn.k_proj.qscales_zeros', 'model.layers.2.self_attn.k_proj.qstatistic', 'model.layers.2.self_attn.k_proj.qweight', 'model.layers.2.self_attn.k_proj.qzeros_scales', 'model.layers.2.self_attn.k_proj.qzeros_zeros', 'model.layers.2.self_attn.o_proj.g_idx', 'model.layers.2.self_attn.o_proj.qscales_scales', 'model.layers.2.self_attn.o_proj.qscales_zeros', 'model.layers.2.self_attn.o_proj.qstatistic', 'model.layers.2.self_attn.o_proj.qweight', 'model.layers.2.self_attn.o_proj.qzeros_scales', 'model.layers.2.self_attn.o_proj.qzeros_zeros', 'model.layers.2.self_attn.q_proj.g_idx', 'model.layers.2.self_attn.q_proj.qscales_scales', 'model.layers.2.self_attn.q_proj.qscales_zeros', 'model.layers.2.self_attn.q_proj.qstatistic', 'model.layers.2.self_attn.q_proj.qweight', 'model.layers.2.self_attn.q_proj.qzeros_scales', 'model.layers.2.self_attn.q_proj.qzeros_zeros', 'model.layers.2.self_attn.v_proj.g_idx', 'model.layers.2.self_attn.v_proj.qscales_scales', 'model.layers.2.self_attn.v_proj.qscales_zeros', 'model.layers.2.self_attn.v_proj.qstatistic', 'model.layers.2.self_attn.v_proj.qweight', 'model.layers.2.self_attn.v_proj.qzeros_scales', 'model.layers.2.self_attn.v_proj.qzeros_zeros', 'model.layers.20.mlp.down_proj.g_idx', 'model.layers.20.mlp.down_proj.qscales_scales', 'model.layers.20.mlp.down_proj.qscales_zeros', 'model.layers.20.mlp.down_proj.qstatistic', 'model.layers.20.mlp.down_proj.qweight', 'model.layers.20.mlp.down_proj.qzeros_scales', 'model.layers.20.mlp.down_proj.qzeros_zeros', 'model.layers.20.mlp.gate_proj.g_idx', 'model.layers.20.mlp.gate_proj.qscales_scales', 'model.layers.20.mlp.gate_proj.qscales_zeros', 'model.layers.20.mlp.gate_proj.qstatistic', 'model.layers.20.mlp.gate_proj.qweight', 'model.layers.20.mlp.gate_proj.qzeros_scales', 'model.layers.20.mlp.gate_proj.qzeros_zeros', 'model.layers.20.mlp.up_proj.g_idx', 'model.layers.20.mlp.up_proj.qscales_scales', 'model.layers.20.mlp.up_proj.qscales_zeros', 'model.layers.20.mlp.up_proj.qstatistic', 'model.layers.20.mlp.up_proj.qweight', 'model.layers.20.mlp.up_proj.qzeros_scales', 'model.layers.20.mlp.up_proj.qzeros_zeros', 'model.layers.20.self_attn.k_proj.g_idx', 'model.layers.20.self_attn.k_proj.qscales_scales', 'model.layers.20.self_attn.k_proj.qscales_zeros', 'model.layers.20.self_attn.k_proj.qstatistic', 'model.layers.20.self_attn.k_proj.qweight', 'model.layers.20.self_attn.k_proj.qzeros_scales', 'model.layers.20.self_attn.k_proj.qzeros_zeros', 'model.layers.20.self_attn.o_proj.g_idx', 'model.layers.20.self_attn.o_proj.qscales_scales', 'model.layers.20.self_attn.o_proj.qscales_zeros', 'model.layers.20.self_attn.o_proj.qstatistic', 'model.layers.20.self_attn.o_proj.qweight', 'model.layers.20.self_attn.o_proj.qzeros_scales', 'model.layers.20.self_attn.o_proj.qzeros_zeros', 'model.layers.20.self_attn.q_proj.g_idx', 'model.layers.20.self_attn.q_proj.qscales_scales', 'model.layers.20.self_attn.q_proj.qscales_zeros', 'model.layers.20.self_attn.q_proj.qstatistic', 'model.layers.20.self_attn.q_proj.qweight', 'model.layers.20.self_attn.q_proj.qzeros_scales', 'model.layers.20.self_attn.q_proj.qzeros_zeros', 'model.layers.20.self_attn.v_proj.g_idx', 'model.layers.20.self_attn.v_proj.qscales_scales', 'model.layers.20.self_attn.v_proj.qscales_zeros', 'model.layers.20.self_attn.v_proj.qstatistic', 'model.layers.20.self_attn.v_proj.qweight', 'model.layers.20.self_attn.v_proj.qzeros_scales', 'model.layers.20.self_attn.v_proj.qzeros_zeros', 'model.layers.21.mlp.down_proj.g_idx', 'model.layers.21.mlp.down_proj.qscales_scales', 'model.layers.21.mlp.down_proj.qscales_zeros', 'model.layers.21.mlp.down_proj.qstatistic', 'model.layers.21.mlp.down_proj.qweight', 'model.layers.21.mlp.down_proj.qzeros_scales', 'model.layers.21.mlp.down_proj.qzeros_zeros', 'model.layers.21.mlp.gate_proj.g_idx', 'model.layers.21.mlp.gate_proj.qscales_scales', 'model.layers.21.mlp.gate_proj.qscales_zeros', 'model.layers.21.mlp.gate_proj.qstatistic', 'model.layers.21.mlp.gate_proj.qweight', 'model.layers.21.mlp.gate_proj.qzeros_scales', 'model.layers.21.mlp.gate_proj.qzeros_zeros', 'model.layers.21.mlp.up_proj.g_idx', 'model.layers.21.mlp.up_proj.qscales_scales', 'model.layers.21.mlp.up_proj.qscales_zeros', 'model.layers.21.mlp.up_proj.qstatistic', 'model.layers.21.mlp.up_proj.qweight', 'model.layers.21.mlp.up_proj.qzeros_scales', 'model.layers.21.mlp.up_proj.qzeros_zeros', 'model.layers.21.self_attn.k_proj.g_idx', 'model.layers.21.self_attn.k_proj.qscales_scales', 'model.layers.21.self_attn.k_proj.qscales_zeros', 'model.layers.21.self_attn.k_proj.qstatistic', 'model.layers.21.self_attn.k_proj.qweight', 'model.layers.21.self_attn.k_proj.qzeros_scales', 'model.layers.21.self_attn.k_proj.qzeros_zeros', 'model.layers.21.self_attn.o_proj.g_idx', 'model.layers.21.self_attn.o_proj.qscales_scales', 'model.layers.21.self_attn.o_proj.qscales_zeros', 'model.layers.21.self_attn.o_proj.qstatistic', 'model.layers.21.self_attn.o_proj.qweight', 'model.layers.21.self_attn.o_proj.qzeros_scales', 'model.layers.21.self_attn.o_proj.qzeros_zeros', 'model.layers.21.self_attn.q_proj.g_idx', 'model.layers.21.self_attn.q_proj.qscales_scales', 'model.layers.21.self_attn.q_proj.qscales_zeros', 'model.layers.21.self_attn.q_proj.qstatistic', 'model.layers.21.self_attn.q_proj.qweight', 'model.layers.21.self_attn.q_proj.qzeros_scales', 'model.layers.21.self_attn.q_proj.qzeros_zeros', 'model.layers.21.self_attn.v_proj.g_idx', 'model.layers.21.self_attn.v_proj.qscales_scales', 'model.layers.21.self_attn.v_proj.qscales_zeros', 'model.layers.21.self_attn.v_proj.qstatistic', 'model.layers.21.self_attn.v_proj.qweight', 'model.layers.21.self_attn.v_proj.qzeros_scales', 'model.layers.21.self_attn.v_proj.qzeros_zeros', 'model.layers.22.mlp.down_proj.g_idx', 'model.layers.22.mlp.down_proj.qscales_scales', 'model.layers.22.mlp.down_proj.qscales_zeros', 'model.layers.22.mlp.down_proj.qstatistic', 'model.layers.22.mlp.down_proj.qweight', 'model.layers.22.mlp.down_proj.qzeros_scales', 'model.layers.22.mlp.down_proj.qzeros_zeros', 'model.layers.22.mlp.gate_proj.g_idx', 'model.layers.22.mlp.gate_proj.qscales_scales', 'model.layers.22.mlp.gate_proj.qscales_zeros', 'model.layers.22.mlp.gate_proj.qstatistic', 'model.layers.22.mlp.gate_proj.qweight', 'model.layers.22.mlp.gate_proj.qzeros_scales', 'model.layers.22.mlp.gate_proj.qzeros_zeros', 'model.layers.22.mlp.up_proj.g_idx', 'model.layers.22.mlp.up_proj.qscales_scales', 'model.layers.22.mlp.up_proj.qscales_zeros', 'model.layers.22.mlp.up_proj.qstatistic', 'model.layers.22.mlp.up_proj.qweight', 'model.layers.22.mlp.up_proj.qzeros_scales', 'model.layers.22.mlp.up_proj.qzeros_zeros', 'model.layers.22.self_attn.k_proj.g_idx', 'model.layers.22.self_attn.k_proj.qscales_scales', 'model.layers.22.self_attn.k_proj.qscales_zeros', 'model.layers.22.self_attn.k_proj.qstatistic', 'model.layers.22.self_attn.k_proj.qweight', 'model.layers.22.self_attn.k_proj.qzeros_scales', 'model.layers.22.self_attn.k_proj.qzeros_zeros', 'model.layers.22.self_attn.o_proj.g_idx', 'model.layers.22.self_attn.o_proj.qscales_scales', 'model.layers.22.self_attn.o_proj.qscales_zeros', 'model.layers.22.self_attn.o_proj.qstatistic', 'model.layers.22.self_attn.o_proj.qweight', 'model.layers.22.self_attn.o_proj.qzeros_scales', 'model.layers.22.self_attn.o_proj.qzeros_zeros', 'model.layers.22.self_attn.q_proj.g_idx', 'model.layers.22.self_attn.q_proj.qscales_scales', 'model.layers.22.self_attn.q_proj.qscales_zeros', 'model.layers.22.self_attn.q_proj.qstatistic', 'model.layers.22.self_attn.q_proj.qweight', 'model.layers.22.self_attn.q_proj.qzeros_scales', 'model.layers.22.self_attn.q_proj.qzeros_zeros', 'model.layers.22.self_attn.v_proj.g_idx', 'model.layers.22.self_attn.v_proj.qscales_scales', 'model.layers.22.self_attn.v_proj.qscales_zeros', 'model.layers.22.self_attn.v_proj.qstatistic', 'model.layers.22.self_attn.v_proj.qweight', 'model.layers.22.self_attn.v_proj.qzeros_scales', 'model.layers.22.self_attn.v_proj.qzeros_zeros', 'model.layers.23.mlp.down_proj.g_idx', 'model.layers.23.mlp.down_proj.qscales_scales', 'model.layers.23.mlp.down_proj.qscales_zeros', 'model.layers.23.mlp.down_proj.qstatistic', 'model.layers.23.mlp.down_proj.qweight', 'model.layers.23.mlp.down_proj.qzeros_scales', 'model.layers.23.mlp.down_proj.qzeros_zeros', 'model.layers.23.mlp.gate_proj.g_idx', 'model.layers.23.mlp.gate_proj.qscales_scales', 'model.layers.23.mlp.gate_proj.qscales_zeros', 'model.layers.23.mlp.gate_proj.qstatistic', 'model.layers.23.mlp.gate_proj.qweight', 'model.layers.23.mlp.gate_proj.qzeros_scales', 'model.layers.23.mlp.gate_proj.qzeros_zeros', 'model.layers.23.mlp.up_proj.g_idx', 'model.layers.23.mlp.up_proj.qscales_scales', 'model.layers.23.mlp.up_proj.qscales_zeros', 'model.layers.23.mlp.up_proj.qstatistic', 'model.layers.23.mlp.up_proj.qweight', 'model.layers.23.mlp.up_proj.qzeros_scales', 'model.layers.23.mlp.up_proj.qzeros_zeros', 'model.layers.23.self_attn.k_proj.g_idx', 'model.layers.23.self_attn.k_proj.qscales_scales', 'model.layers.23.self_attn.k_proj.qscales_zeros', 'model.layers.23.self_attn.k_proj.qstatistic', 'model.layers.23.self_attn.k_proj.qweight', 'model.layers.23.self_attn.k_proj.qzeros_scales', 'model.layers.23.self_attn.k_proj.qzeros_zeros', 'model.layers.23.self_attn.o_proj.g_idx', 'model.layers.23.self_attn.o_proj.qscales_scales', 'model.layers.23.self_attn.o_proj.qscales_zeros', 'model.layers.23.self_attn.o_proj.qstatistic', 'model.layers.23.self_attn.o_proj.qweight', 'model.layers.23.self_attn.o_proj.qzeros_scales', 'model.layers.23.self_attn.o_proj.qzeros_zeros', 'model.layers.23.self_attn.q_proj.g_idx', 'model.layers.23.self_attn.q_proj.qscales_scales', 'model.layers.23.self_attn.q_proj.qscales_zeros', 'model.layers.23.self_attn.q_proj.qstatistic', 'model.layers.23.self_attn.q_proj.qweight', 'model.layers.23.self_attn.q_proj.qzeros_scales', 'model.layers.23.self_attn.q_proj.qzeros_zeros', 'model.layers.23.self_attn.v_proj.g_idx', 'model.layers.23.self_attn.v_proj.qscales_scales', 'model.layers.23.self_attn.v_proj.qscales_zeros', 'model.layers.23.self_attn.v_proj.qstatistic', 'model.layers.23.self_attn.v_proj.qweight', 'model.layers.23.self_attn.v_proj.qzeros_scales', 'model.layers.23.self_attn.v_proj.qzeros_zeros', 'model.layers.24.mlp.down_proj.g_idx', 'model.layers.24.mlp.down_proj.qscales_scales', 'model.layers.24.mlp.down_proj.qscales_zeros', 'model.layers.24.mlp.down_proj.qstatistic', 'model.layers.24.mlp.down_proj.qweight', 'model.layers.24.mlp.down_proj.qzeros_scales', 'model.layers.24.mlp.down_proj.qzeros_zeros', 'model.layers.24.mlp.gate_proj.g_idx', 'model.layers.24.mlp.gate_proj.qscales_scales', 'model.layers.24.mlp.gate_proj.qscales_zeros', 'model.layers.24.mlp.gate_proj.qstatistic', 'model.layers.24.mlp.gate_proj.qweight', 'model.layers.24.mlp.gate_proj.qzeros_scales', 'model.layers.24.mlp.gate_proj.qzeros_zeros', 'model.layers.24.mlp.up_proj.g_idx', 'model.layers.24.mlp.up_proj.qscales_scales', 'model.layers.24.mlp.up_proj.qscales_zeros', 'model.layers.24.mlp.up_proj.qstatistic', 'model.layers.24.mlp.up_proj.qweight', 'model.layers.24.mlp.up_proj.qzeros_scales', 'model.layers.24.mlp.up_proj.qzeros_zeros', 'model.layers.24.self_attn.k_proj.g_idx', 'model.layers.24.self_attn.k_proj.qscales_scales', 'model.layers.24.self_attn.k_proj.qscales_zeros', 'model.layers.24.self_attn.k_proj.qstatistic', 'model.layers.24.self_attn.k_proj.qweight', 'model.layers.24.self_attn.k_proj.qzeros_scales', 'model.layers.24.self_attn.k_proj.qzeros_zeros', 'model.layers.24.self_attn.o_proj.g_idx', 'model.layers.24.self_attn.o_proj.qscales_scales', 'model.layers.24.self_attn.o_proj.qscales_zeros', 'model.layers.24.self_attn.o_proj.qstatistic', 'model.layers.24.self_attn.o_proj.qweight', 'model.layers.24.self_attn.o_proj.qzeros_scales', 'model.layers.24.self_attn.o_proj.qzeros_zeros', 'model.layers.24.self_attn.q_proj.g_idx', 'model.layers.24.self_attn.q_proj.qscales_scales', 'model.layers.24.self_attn.q_proj.qscales_zeros', 'model.layers.24.self_attn.q_proj.qstatistic', 'model.layers.24.self_attn.q_proj.qweight', 'model.layers.24.self_attn.q_proj.qzeros_scales', 'model.layers.24.self_attn.q_proj.qzeros_zeros', 'model.layers.24.self_attn.v_proj.g_idx', 'model.layers.24.self_attn.v_proj.qscales_scales', 'model.layers.24.self_attn.v_proj.qscales_zeros', 'model.layers.24.self_attn.v_proj.qstatistic', 'model.layers.24.self_attn.v_proj.qweight', 'model.layers.24.self_attn.v_proj.qzeros_scales', 'model.layers.24.self_attn.v_proj.qzeros_zeros', 'model.layers.25.mlp.down_proj.g_idx', 'model.layers.25.mlp.down_proj.qscales_scales', 'model.layers.25.mlp.down_proj.qscales_zeros', 'model.layers.25.mlp.down_proj.qstatistic', 'model.layers.25.mlp.down_proj.qweight', 'model.layers.25.mlp.down_proj.qzeros_scales', 'model.layers.25.mlp.down_proj.qzeros_zeros', 'model.layers.25.mlp.gate_proj.g_idx', 'model.layers.25.mlp.gate_proj.qscales_scales', 'model.layers.25.mlp.gate_proj.qscales_zeros', 'model.layers.25.mlp.gate_proj.qstatistic', 'model.layers.25.mlp.gate_proj.qweight', 'model.layers.25.mlp.gate_proj.qzeros_scales', 'model.layers.25.mlp.gate_proj.qzeros_zeros', 'model.layers.25.mlp.up_proj.g_idx', 'model.layers.25.mlp.up_proj.qscales_scales', 'model.layers.25.mlp.up_proj.qscales_zeros', 'model.layers.25.mlp.up_proj.qstatistic', 'model.layers.25.mlp.up_proj.qweight', 'model.layers.25.mlp.up_proj.qzeros_scales', 'model.layers.25.mlp.up_proj.qzeros_zeros', 'model.layers.25.self_attn.k_proj.g_idx', 'model.layers.25.self_attn.k_proj.qscales_scales', 'model.layers.25.self_attn.k_proj.qscales_zeros', 'model.layers.25.self_attn.k_proj.qstatistic', 'model.layers.25.self_attn.k_proj.qweight', 'model.layers.25.self_attn.k_proj.qzeros_scales', 'model.layers.25.self_attn.k_proj.qzeros_zeros', 'model.layers.25.self_attn.o_proj.g_idx', 'model.layers.25.self_attn.o_proj.qscales_scales', 'model.layers.25.self_attn.o_proj.qscales_zeros', 'model.layers.25.self_attn.o_proj.qstatistic', 'model.layers.25.self_attn.o_proj.qweight', 'model.layers.25.self_attn.o_proj.qzeros_scales', 'model.layers.25.self_attn.o_proj.qzeros_zeros', 'model.layers.25.self_attn.q_proj.g_idx', 'model.layers.25.self_attn.q_proj.qscales_scales', 'model.layers.25.self_attn.q_proj.qscales_zeros', 'model.layers.25.self_attn.q_proj.qstatistic', 'model.layers.25.self_attn.q_proj.qweight', 'model.layers.25.self_attn.q_proj.qzeros_scales', 'model.layers.25.self_attn.q_proj.qzeros_zeros', 'model.layers.25.self_attn.v_proj.g_idx', 'model.layers.25.self_attn.v_proj.qscales_scales', 'model.layers.25.self_attn.v_proj.qscales_zeros', 'model.layers.25.self_attn.v_proj.qstatistic', 'model.layers.25.self_attn.v_proj.qweight', 'model.layers.25.self_attn.v_proj.qzeros_scales', 'model.layers.25.self_attn.v_proj.qzeros_zeros', 'model.layers.26.mlp.down_proj.g_idx', 'model.layers.26.mlp.down_proj.qscales_scales', 'model.layers.26.mlp.down_proj.qscales_zeros', 'model.layers.26.mlp.down_proj.qstatistic', 'model.layers.26.mlp.down_proj.qweight', 'model.layers.26.mlp.down_proj.qzeros_scales', 'model.layers.26.mlp.down_proj.qzeros_zeros', 'model.layers.26.mlp.gate_proj.g_idx', 'model.layers.26.mlp.gate_proj.qscales_scales', 'model.layers.26.mlp.gate_proj.qscales_zeros', 'model.layers.26.mlp.gate_proj.qstatistic', 'model.layers.26.mlp.gate_proj.qweight', 'model.layers.26.mlp.gate_proj.qzeros_scales', 'model.layers.26.mlp.gate_proj.qzeros_zeros', 'model.layers.26.mlp.up_proj.g_idx', 'model.layers.26.mlp.up_proj.qscales_scales', 'model.layers.26.mlp.up_proj.qscales_zeros', 'model.layers.26.mlp.up_proj.qstatistic', 'model.layers.26.mlp.up_proj.qweight', 'model.layers.26.mlp.up_proj.qzeros_scales', 'model.layers.26.mlp.up_proj.qzeros_zeros', 'model.layers.26.self_attn.k_proj.g_idx', 'model.layers.26.self_attn.k_proj.qscales_scales', 'model.layers.26.self_attn.k_proj.qscales_zeros', 'model.layers.26.self_attn.k_proj.qstatistic', 'model.layers.26.self_attn.k_proj.qweight', 'model.layers.26.self_attn.k_proj.qzeros_scales', 'model.layers.26.self_attn.k_proj.qzeros_zeros', 'model.layers.26.self_attn.o_proj.g_idx', 'model.layers.26.self_attn.o_proj.qscales_scales', 'model.layers.26.self_attn.o_proj.qscales_zeros', 'model.layers.26.self_attn.o_proj.qstatistic', 'model.layers.26.self_attn.o_proj.qweight', 'model.layers.26.self_attn.o_proj.qzeros_scales', 'model.layers.26.self_attn.o_proj.qzeros_zeros', 'model.layers.26.self_attn.q_proj.g_idx', 'model.layers.26.self_attn.q_proj.qscales_scales', 'model.layers.26.self_attn.q_proj.qscales_zeros', 'model.layers.26.self_attn.q_proj.qstatistic', 'model.layers.26.self_attn.q_proj.qweight', 'model.layers.26.self_attn.q_proj.qzeros_scales', 'model.layers.26.self_attn.q_proj.qzeros_zeros', 'model.layers.26.self_attn.v_proj.g_idx', 'model.layers.26.self_attn.v_proj.qscales_scales', 'model.layers.26.self_attn.v_proj.qscales_zeros', 'model.layers.26.self_attn.v_proj.qstatistic', 'model.layers.26.self_attn.v_proj.qweight', 'model.layers.26.self_attn.v_proj.qzeros_scales', 'model.layers.26.self_attn.v_proj.qzeros_zeros', 'model.layers.27.mlp.down_proj.g_idx', 'model.layers.27.mlp.down_proj.qscales_scales', 'model.layers.27.mlp.down_proj.qscales_zeros', 'model.layers.27.mlp.down_proj.qstatistic', 'model.layers.27.mlp.down_proj.qweight', 'model.layers.27.mlp.down_proj.qzeros_scales', 'model.layers.27.mlp.down_proj.qzeros_zeros', 'model.layers.27.mlp.gate_proj.g_idx', 'model.layers.27.mlp.gate_proj.qscales_scales', 'model.layers.27.mlp.gate_proj.qscales_zeros', 'model.layers.27.mlp.gate_proj.qstatistic', 'model.layers.27.mlp.gate_proj.qweight', 'model.layers.27.mlp.gate_proj.qzeros_scales', 'model.layers.27.mlp.gate_proj.qzeros_zeros', 'model.layers.27.mlp.up_proj.g_idx', 'model.layers.27.mlp.up_proj.qscales_scales', 'model.layers.27.mlp.up_proj.qscales_zeros', 'model.layers.27.mlp.up_proj.qstatistic', 'model.layers.27.mlp.up_proj.qweight', 'model.layers.27.mlp.up_proj.qzeros_scales', 'model.layers.27.mlp.up_proj.qzeros_zeros', 'model.layers.27.self_attn.k_proj.g_idx', 'model.layers.27.self_attn.k_proj.qscales_scales', 'model.layers.27.self_attn.k_proj.qscales_zeros', 'model.layers.27.self_attn.k_proj.qstatistic', 'model.layers.27.self_attn.k_proj.qweight', 'model.layers.27.self_attn.k_proj.qzeros_scales', 'model.layers.27.self_attn.k_proj.qzeros_zeros', 'model.layers.27.self_attn.o_proj.g_idx', 'model.layers.27.self_attn.o_proj.qscales_scales', 'model.layers.27.self_attn.o_proj.qscales_zeros', 'model.layers.27.self_attn.o_proj.qstatistic', 'model.layers.27.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qzeros_scales', 'model.layers.27.self_attn.o_proj.qzeros_zeros', 'model.layers.27.self_attn.q_proj.g_idx', 'model.layers.27.self_attn.q_proj.qscales_scales', 'model.layers.27.self_attn.q_proj.qscales_zeros', 'model.layers.27.self_attn.q_proj.qstatistic', 'model.layers.27.self_attn.q_proj.qweight', 'model.layers.27.self_attn.q_proj.qzeros_scales', 'model.layers.27.self_attn.q_proj.qzeros_zeros', 'model.layers.27.self_attn.v_proj.g_idx', 'model.layers.27.self_attn.v_proj.qscales_scales', 'model.layers.27.self_attn.v_proj.qscales_zeros', 'model.layers.27.self_attn.v_proj.qstatistic', 'model.layers.27.self_attn.v_proj.qweight', 'model.layers.27.self_attn.v_proj.qzeros_scales', 'model.layers.27.self_attn.v_proj.qzeros_zeros', 'model.layers.28.mlp.down_proj.g_idx', 'model.layers.28.mlp.down_proj.qscales_scales', 'model.layers.28.mlp.down_proj.qscales_zeros', 'model.layers.28.mlp.down_proj.qstatistic', 'model.layers.28.mlp.down_proj.qweight', 'model.layers.28.mlp.down_proj.qzeros_scales', 'model.layers.28.mlp.down_proj.qzeros_zeros', 'model.layers.28.mlp.gate_proj.g_idx', 'model.layers.28.mlp.gate_proj.qscales_scales', 'model.layers.28.mlp.gate_proj.qscales_zeros', 'model.layers.28.mlp.gate_proj.qstatistic', 'model.layers.28.mlp.gate_proj.qweight', 'model.layers.28.mlp.gate_proj.qzeros_scales', 'model.layers.28.mlp.gate_proj.qzeros_zeros', 'model.layers.28.mlp.up_proj.g_idx', 'model.layers.28.mlp.up_proj.qscales_scales', 'model.layers.28.mlp.up_proj.qscales_zeros', 'model.layers.28.mlp.up_proj.qstatistic', 'model.layers.28.mlp.up_proj.qweight', 'model.layers.28.mlp.up_proj.qzeros_scales', 'model.layers.28.mlp.up_proj.qzeros_zeros', 'model.layers.28.self_attn.k_proj.g_idx', 'model.layers.28.self_attn.k_proj.qscales_scales', 'model.layers.28.self_attn.k_proj.qscales_zeros', 'model.layers.28.self_attn.k_proj.qstatistic', 'model.layers.28.self_attn.k_proj.qweight', 'model.layers.28.self_attn.k_proj.qzeros_scales', 'model.layers.28.self_attn.k_proj.qzeros_zeros', 'model.layers.28.self_attn.o_proj.g_idx', 'model.layers.28.self_attn.o_proj.qscales_scales', 'model.layers.28.self_attn.o_proj.qscales_zeros', 'model.layers.28.self_attn.o_proj.qstatistic', 'model.layers.28.self_attn.o_proj.qweight', 'model.layers.28.self_attn.o_proj.qzeros_scales', 'model.layers.28.self_attn.o_proj.qzeros_zeros', 'model.layers.28.self_attn.q_proj.g_idx', 'model.layers.28.self_attn.q_proj.qscales_scales', 'model.layers.28.self_attn.q_proj.qscales_zeros', 'model.layers.28.self_attn.q_proj.qstatistic', 'model.layers.28.self_attn.q_proj.qweight', 'model.layers.28.self_attn.q_proj.qzeros_scales', 'model.layers.28.self_attn.q_proj.qzeros_zeros', 'model.layers.28.self_attn.v_proj.g_idx', 'model.layers.28.self_attn.v_proj.qscales_scales', 'model.layers.28.self_attn.v_proj.qscales_zeros', 'model.layers.28.self_attn.v_proj.qstatistic', 'model.layers.28.self_attn.v_proj.qweight', 'model.layers.28.self_attn.v_proj.qzeros_scales', 'model.layers.28.self_attn.v_proj.qzeros_zeros', 'model.layers.29.mlp.down_proj.g_idx', 'model.layers.29.mlp.down_proj.qscales_scales', 'model.layers.29.mlp.down_proj.qscales_zeros', 'model.layers.29.mlp.down_proj.qstatistic', 'model.layers.29.mlp.down_proj.qweight', 'model.layers.29.mlp.down_proj.qzeros_scales', 'model.layers.29.mlp.down_proj.qzeros_zeros', 'model.layers.29.mlp.gate_proj.g_idx', 'model.layers.29.mlp.gate_proj.qscales_scales', 'model.layers.29.mlp.gate_proj.qscales_zeros', 'model.layers.29.mlp.gate_proj.qstatistic', 'model.layers.29.mlp.gate_proj.qweight', 'model.layers.29.mlp.gate_proj.qzeros_scales', 'model.layers.29.mlp.gate_proj.qzeros_zeros', 'model.layers.29.mlp.up_proj.g_idx', 'model.layers.29.mlp.up_proj.qscales_scales', 'model.layers.29.mlp.up_proj.qscales_zeros', 'model.layers.29.mlp.up_proj.qstatistic', 'model.layers.29.mlp.up_proj.qweight', 'model.layers.29.mlp.up_proj.qzeros_scales', 'model.layers.29.mlp.up_proj.qzeros_zeros', 'model.layers.29.self_attn.k_proj.g_idx', 'model.layers.29.self_attn.k_proj.qscales_scales', 'model.layers.29.self_attn.k_proj.qscales_zeros', 'model.layers.29.self_attn.k_proj.qstatistic', 'model.layers.29.self_attn.k_proj.qweight', 'model.layers.29.self_attn.k_proj.qzeros_scales', 'model.layers.29.self_attn.k_proj.qzeros_zeros', 'model.layers.29.self_attn.o_proj.g_idx', 'model.layers.29.self_attn.o_proj.qscales_scales', 'model.layers.29.self_attn.o_proj.qscales_zeros', 'model.layers.29.self_attn.o_proj.qstatistic', 'model.layers.29.self_attn.o_proj.qweight', 'model.layers.29.self_attn.o_proj.qzeros_scales', 'model.layers.29.self_attn.o_proj.qzeros_zeros', 'model.layers.29.self_attn.q_proj.g_idx', 'model.layers.29.self_attn.q_proj.qscales_scales', 'model.layers.29.self_attn.q_proj.qscales_zeros', 'model.layers.29.self_attn.q_proj.qstatistic', 'model.layers.29.self_attn.q_proj.qweight', 'model.layers.29.self_attn.q_proj.qzeros_scales', 'model.layers.29.self_attn.q_proj.qzeros_zeros', 'model.layers.29.self_attn.v_proj.g_idx', 'model.layers.29.self_attn.v_proj.qscales_scales', 'model.layers.29.self_attn.v_proj.qscales_zeros', 'model.layers.29.self_attn.v_proj.qstatistic', 'model.layers.29.self_attn.v_proj.qweight', 'model.layers.29.self_attn.v_proj.qzeros_scales', 'model.layers.29.self_attn.v_proj.qzeros_zeros', 'model.layers.3.mlp.down_proj.g_idx', 'model.layers.3.mlp.down_proj.qscales_scales', 'model.layers.3.mlp.down_proj.qscales_zeros', 'model.layers.3.mlp.down_proj.qstatistic', 'model.layers.3.mlp.down_proj.qweight', 'model.layers.3.mlp.down_proj.qzeros_scales', 'model.layers.3.mlp.down_proj.qzeros_zeros', 'model.layers.3.mlp.gate_proj.g_idx', 'model.layers.3.mlp.gate_proj.qscales_scales', 'model.layers.3.mlp.gate_proj.qscales_zeros', 'model.layers.3.mlp.gate_proj.qstatistic', 'model.layers.3.mlp.gate_proj.qweight', 'model.layers.3.mlp.gate_proj.qzeros_scales', 'model.layers.3.mlp.gate_proj.qzeros_zeros', 'model.layers.3.mlp.up_proj.g_idx', 'model.layers.3.mlp.up_proj.qscales_scales', 'model.layers.3.mlp.up_proj.qscales_zeros', 'model.layers.3.mlp.up_proj.qstatistic', 'model.layers.3.mlp.up_proj.qweight', 'model.layers.3.mlp.up_proj.qzeros_scales', 'model.layers.3.mlp.up_proj.qzeros_zeros', 'model.layers.3.self_attn.k_proj.g_idx', 'model.layers.3.self_attn.k_proj.qscales_scales', 'model.layers.3.self_attn.k_proj.qscales_zeros', 'model.layers.3.self_attn.k_proj.qstatistic', 'model.layers.3.self_attn.k_proj.qweight', 'model.layers.3.self_attn.k_proj.qzeros_scales', 'model.layers.3.self_attn.k_proj.qzeros_zeros', 'model.layers.3.self_attn.o_proj.g_idx', 'model.layers.3.self_attn.o_proj.qscales_scales', 'model.layers.3.self_attn.o_proj.qscales_zeros', 'model.layers.3.self_attn.o_proj.qstatistic', 'model.layers.3.self_attn.o_proj.qweight', 'model.layers.3.self_attn.o_proj.qzeros_scales', 'model.layers.3.self_attn.o_proj.qzeros_zeros', 'model.layers.3.self_attn.q_proj.g_idx', 'model.layers.3.self_attn.q_proj.qscales_scales', 'model.layers.3.self_attn.q_proj.qscales_zeros', 'model.layers.3.self_attn.q_proj.qstatistic', 'model.layers.3.self_attn.q_proj.qweight', 'model.layers.3.self_attn.q_proj.qzeros_scales', 'model.layers.3.self_attn.q_proj.qzeros_zeros', 'model.layers.3.self_attn.v_proj.g_idx', 'model.layers.3.self_attn.v_proj.qscales_scales', 'model.layers.3.self_attn.v_proj.qscales_zeros', 'model.layers.3.self_attn.v_proj.qstatistic', 'model.layers.3.self_attn.v_proj.qweight', 'model.layers.3.self_attn.v_proj.qzeros_scales', 'model.layers.3.self_attn.v_proj.qzeros_zeros', 'model.layers.30.mlp.down_proj.g_idx', 'model.layers.30.mlp.down_proj.qscales_scales', 'model.layers.30.mlp.down_proj.qscales_zeros', 'model.layers.30.mlp.down_proj.qstatistic', 'model.layers.30.mlp.down_proj.qweight', 'model.layers.30.mlp.down_proj.qzeros_scales', 'model.layers.30.mlp.down_proj.qzeros_zeros', 'model.layers.30.mlp.gate_proj.g_idx', 'model.layers.30.mlp.gate_proj.qscales_scales', 'model.layers.30.mlp.gate_proj.qscales_zeros', 'model.layers.30.mlp.gate_proj.qstatistic', 'model.layers.30.mlp.gate_proj.qweight', 'model.layers.30.mlp.gate_proj.qzeros_scales', 'model.layers.30.mlp.gate_proj.qzeros_zeros', 'model.layers.30.mlp.up_proj.g_idx', 'model.layers.30.mlp.up_proj.qscales_scales', 'model.layers.30.mlp.up_proj.qscales_zeros', 'model.layers.30.mlp.up_proj.qstatistic', 'model.layers.30.mlp.up_proj.qweight', 'model.layers.30.mlp.up_proj.qzeros_scales', 'model.layers.30.mlp.up_proj.qzeros_zeros', 'model.layers.30.self_attn.k_proj.g_idx', 'model.layers.30.self_attn.k_proj.qscales_scales', 'model.layers.30.self_attn.k_proj.qscales_zeros', 'model.layers.30.self_attn.k_proj.qstatistic', 'model.layers.30.self_attn.k_proj.qweight', 'model.layers.30.self_attn.k_proj.qzeros_scales', 'model.layers.30.self_attn.k_proj.qzeros_zeros', 'model.layers.30.self_attn.o_proj.g_idx', 'model.layers.30.self_attn.o_proj.qscales_scales', 'model.layers.30.self_attn.o_proj.qscales_zeros', 'model.layers.30.self_attn.o_proj.qstatistic', 'model.layers.30.self_attn.o_proj.qweight', 'model.layers.30.self_attn.o_proj.qzeros_scales', 'model.layers.30.self_attn.o_proj.qzeros_zeros', 'model.layers.30.self_attn.q_proj.g_idx', 'model.layers.30.self_attn.q_proj.qscales_scales', 'model.layers.30.self_attn.q_proj.qscales_zeros', 'model.layers.30.self_attn.q_proj.qstatistic', 'model.layers.30.self_attn.q_proj.qweight', 'model.layers.30.self_attn.q_proj.qzeros_scales', 'model.layers.30.self_attn.q_proj.qzeros_zeros', 'model.layers.30.self_attn.v_proj.g_idx', 'model.layers.30.self_attn.v_proj.qscales_scales', 'model.layers.30.self_attn.v_proj.qscales_zeros', 'model.layers.30.self_attn.v_proj.qstatistic', 'model.layers.30.self_attn.v_proj.qweight', 'model.layers.30.self_attn.v_proj.qzeros_scales', 'model.layers.30.self_attn.v_proj.qzeros_zeros', 'model.layers.31.mlp.down_proj.g_idx', 'model.layers.31.mlp.down_proj.qscales_scales', 'model.layers.31.mlp.down_proj.qscales_zeros', 'model.layers.31.mlp.down_proj.qstatistic', 'model.layers.31.mlp.down_proj.qweight', 'model.layers.31.mlp.down_proj.qzeros_scales', 'model.layers.31.mlp.down_proj.qzeros_zeros', 'model.layers.31.mlp.gate_proj.g_idx', 'model.layers.31.mlp.gate_proj.qscales_scales', 'model.layers.31.mlp.gate_proj.qscales_zeros', 'model.layers.31.mlp.gate_proj.qstatistic', 'model.layers.31.mlp.gate_proj.qweight', 'model.layers.31.mlp.gate_proj.qzeros_scales', 'model.layers.31.mlp.gate_proj.qzeros_zeros', 'model.layers.31.mlp.up_proj.g_idx', 'model.layers.31.mlp.up_proj.qscales_scales', 'model.layers.31.mlp.up_proj.qscales_zeros', 'model.layers.31.mlp.up_proj.qstatistic', 'model.layers.31.mlp.up_proj.qweight', 'model.layers.31.mlp.up_proj.qzeros_scales', 'model.layers.31.mlp.up_proj.qzeros_zeros', 'model.layers.31.self_attn.k_proj.g_idx', 'model.layers.31.self_attn.k_proj.qscales_scales', 'model.layers.31.self_attn.k_proj.qscales_zeros', 'model.layers.31.self_attn.k_proj.qstatistic', 'model.layers.31.self_attn.k_proj.qweight', 'model.layers.31.self_attn.k_proj.qzeros_scales', 'model.layers.31.self_attn.k_proj.qzeros_zeros', 'model.layers.31.self_attn.o_proj.g_idx', 'model.layers.31.self_attn.o_proj.qscales_scales', 'model.layers.31.self_attn.o_proj.qscales_zeros', 'model.layers.31.self_attn.o_proj.qstatistic', 'model.layers.31.self_attn.o_proj.qweight', 'model.layers.31.self_attn.o_proj.qzeros_scales', 'model.layers.31.self_attn.o_proj.qzeros_zeros', 'model.layers.31.self_attn.q_proj.g_idx', 'model.layers.31.self_attn.q_proj.qscales_scales', 'model.layers.31.self_attn.q_proj.qscales_zeros', 'model.layers.31.self_attn.q_proj.qstatistic', 'model.layers.31.self_attn.q_proj.qweight', 'model.layers.31.self_attn.q_proj.qzeros_scales', 'model.layers.31.self_attn.q_proj.qzeros_zeros', 'model.layers.31.self_attn.v_proj.g_idx', 'model.layers.31.self_attn.v_proj.qscales_scales', 'model.layers.31.self_attn.v_proj.qscales_zeros', 'model.layers.31.self_attn.v_proj.qstatistic', 'model.layers.31.self_attn.v_proj.qweight', 'model.layers.31.self_attn.v_proj.qzeros_scales', 'model.layers.31.self_attn.v_proj.qzeros_zeros', 'model.layers.4.mlp.down_proj.g_idx', 'model.layers.4.mlp.down_proj.qscales_scales', 'model.layers.4.mlp.down_proj.qscales_zeros', 'model.layers.4.mlp.down_proj.qstatistic', 'model.layers.4.mlp.down_proj.qweight', 'model.layers.4.mlp.down_proj.qzeros_scales', 'model.layers.4.mlp.down_proj.qzeros_zeros', 'model.layers.4.mlp.gate_proj.g_idx', 'model.layers.4.mlp.gate_proj.qscales_scales', 'model.layers.4.mlp.gate_proj.qscales_zeros', 'model.layers.4.mlp.gate_proj.qstatistic', 'model.layers.4.mlp.gate_proj.qweight', 'model.layers.4.mlp.gate_proj.qzeros_scales', 'model.layers.4.mlp.gate_proj.qzeros_zeros', 'model.layers.4.mlp.up_proj.g_idx', 'model.layers.4.mlp.up_proj.qscales_scales', 'model.layers.4.mlp.up_proj.qscales_zeros', 'model.layers.4.mlp.up_proj.qstatistic', 'model.layers.4.mlp.up_proj.qweight', 'model.layers.4.mlp.up_proj.qzeros_scales', 'model.layers.4.mlp.up_proj.qzeros_zeros', 'model.layers.4.self_attn.k_proj.g_idx', 'model.layers.4.self_attn.k_proj.qscales_scales', 'model.layers.4.self_attn.k_proj.qscales_zeros', 'model.layers.4.self_attn.k_proj.qstatistic', 'model.layers.4.self_attn.k_proj.qweight', 'model.layers.4.self_attn.k_proj.qzeros_scales', 'model.layers.4.self_attn.k_proj.qzeros_zeros', 'model.layers.4.self_attn.o_proj.g_idx', 'model.layers.4.self_attn.o_proj.qscales_scales', 'model.layers.4.self_attn.o_proj.qscales_zeros', 'model.layers.4.self_attn.o_proj.qstatistic', 'model.layers.4.self_attn.o_proj.qweight', 'model.layers.4.self_attn.o_proj.qzeros_scales', 'model.layers.4.self_attn.o_proj.qzeros_zeros', 'model.layers.4.self_attn.q_proj.g_idx', 'model.layers.4.self_attn.q_proj.qscales_scales', 'model.layers.4.self_attn.q_proj.qscales_zeros', 'model.layers.4.self_attn.q_proj.qstatistic', 'model.layers.4.self_attn.q_proj.qweight', 'model.layers.4.self_attn.q_proj.qzeros_scales', 'model.layers.4.self_attn.q_proj.qzeros_zeros', 'model.layers.4.self_attn.v_proj.g_idx', 'model.layers.4.self_attn.v_proj.qscales_scales', 'model.layers.4.self_attn.v_proj.qscales_zeros', 'model.layers.4.self_attn.v_proj.qstatistic', 'model.layers.4.self_attn.v_proj.qweight', 'model.layers.4.self_attn.v_proj.qzeros_scales', 'model.layers.4.self_attn.v_proj.qzeros_zeros', 'model.layers.5.mlp.down_proj.g_idx', 'model.layers.5.mlp.down_proj.qscales_scales', 'model.layers.5.mlp.down_proj.qscales_zeros', 'model.layers.5.mlp.down_proj.qstatistic', 'model.layers.5.mlp.down_proj.qweight', 'model.layers.5.mlp.down_proj.qzeros_scales', 'model.layers.5.mlp.down_proj.qzeros_zeros', 'model.layers.5.mlp.gate_proj.g_idx', 'model.layers.5.mlp.gate_proj.qscales_scales', 'model.layers.5.mlp.gate_proj.qscales_zeros', 'model.layers.5.mlp.gate_proj.qstatistic', 'model.layers.5.mlp.gate_proj.qweight', 'model.layers.5.mlp.gate_proj.qzeros_scales', 'model.layers.5.mlp.gate_proj.qzeros_zeros', 'model.layers.5.mlp.up_proj.g_idx', 'model.layers.5.mlp.up_proj.qscales_scales', 'model.layers.5.mlp.up_proj.qscales_zeros', 'model.layers.5.mlp.up_proj.qstatistic', 'model.layers.5.mlp.up_proj.qweight', 'model.layers.5.mlp.up_proj.qzeros_scales', 'model.layers.5.mlp.up_proj.qzeros_zeros', 'model.layers.5.self_attn.k_proj.g_idx', 'model.layers.5.self_attn.k_proj.qscales_scales', 'model.layers.5.self_attn.k_proj.qscales_zeros', 'model.layers.5.self_attn.k_proj.qstatistic', 'model.layers.5.self_attn.k_proj.qweight', 'model.layers.5.self_attn.k_proj.qzeros_scales', 'model.layers.5.self_attn.k_proj.qzeros_zeros', 'model.layers.5.self_attn.o_proj.g_idx', 'model.layers.5.self_attn.o_proj.qscales_scales', 'model.layers.5.self_attn.o_proj.qscales_zeros', 'model.layers.5.self_attn.o_proj.qstatistic', 'model.layers.5.self_attn.o_proj.qweight', 'model.layers.5.self_attn.o_proj.qzeros_scales', 'model.layers.5.self_attn.o_proj.qzeros_zeros', 'model.layers.5.self_attn.q_proj.g_idx', 'model.layers.5.self_attn.q_proj.qscales_scales', 'model.layers.5.self_attn.q_proj.qscales_zeros', 'model.layers.5.self_attn.q_proj.qstatistic', 'model.layers.5.self_attn.q_proj.qweight', 'model.layers.5.self_attn.q_proj.qzeros_scales', 'model.layers.5.self_attn.q_proj.qzeros_zeros', 'model.layers.5.self_attn.v_proj.g_idx', 'model.layers.5.self_attn.v_proj.qscales_scales', 'model.layers.5.self_attn.v_proj.qscales_zeros', 'model.layers.5.self_attn.v_proj.qstatistic', 'model.layers.5.self_attn.v_proj.qweight', 'model.layers.5.self_attn.v_proj.qzeros_scales', 'model.layers.5.self_attn.v_proj.qzeros_zeros', 'model.layers.6.mlp.down_proj.g_idx', 'model.layers.6.mlp.down_proj.qscales_scales', 'model.layers.6.mlp.down_proj.qscales_zeros', 'model.layers.6.mlp.down_proj.qstatistic', 'model.layers.6.mlp.down_proj.qweight', 'model.layers.6.mlp.down_proj.qzeros_scales', 'model.layers.6.mlp.down_proj.qzeros_zeros', 'model.layers.6.mlp.gate_proj.g_idx', 'model.layers.6.mlp.gate_proj.qscales_scales', 'model.layers.6.mlp.gate_proj.qscales_zeros', 'model.layers.6.mlp.gate_proj.qstatistic', 'model.layers.6.mlp.gate_proj.qweight', 'model.layers.6.mlp.gate_proj.qzeros_scales', 'model.layers.6.mlp.gate_proj.qzeros_zeros', 'model.layers.6.mlp.up_proj.g_idx', 'model.layers.6.mlp.up_proj.qscales_scales', 'model.layers.6.mlp.up_proj.qscales_zeros', 'model.layers.6.mlp.up_proj.qstatistic', 'model.layers.6.mlp.up_proj.qweight', 'model.layers.6.mlp.up_proj.qzeros_scales', 'model.layers.6.mlp.up_proj.qzeros_zeros', 'model.layers.6.self_attn.k_proj.g_idx', 'model.layers.6.self_attn.k_proj.qscales_scales', 'model.layers.6.self_attn.k_proj.qscales_zeros', 'model.layers.6.self_attn.k_proj.qstatistic', 'model.layers.6.self_attn.k_proj.qweight', 'model.layers.6.self_attn.k_proj.qzeros_scales', 'model.layers.6.self_attn.k_proj.qzeros_zeros', 'model.layers.6.self_attn.o_proj.g_idx', 'model.layers.6.self_attn.o_proj.qscales_scales', 'model.layers.6.self_attn.o_proj.qscales_zeros', 'model.layers.6.self_attn.o_proj.qstatistic', 'model.layers.6.self_attn.o_proj.qweight', 'model.layers.6.self_attn.o_proj.qzeros_scales', 'model.layers.6.self_attn.o_proj.qzeros_zeros', 'model.layers.6.self_attn.q_proj.g_idx', 'model.layers.6.self_attn.q_proj.qscales_scales', 'model.layers.6.self_attn.q_proj.qscales_zeros', 'model.layers.6.self_attn.q_proj.qstatistic', 'model.layers.6.self_attn.q_proj.qweight', 'model.layers.6.self_attn.q_proj.qzeros_scales', 'model.layers.6.self_attn.q_proj.qzeros_zeros', 'model.layers.6.self_attn.v_proj.g_idx', 'model.layers.6.self_attn.v_proj.qscales_scales', 'model.layers.6.self_attn.v_proj.qscales_zeros', 'model.layers.6.self_attn.v_proj.qstatistic', 'model.layers.6.self_attn.v_proj.qweight', 'model.layers.6.self_attn.v_proj.qzeros_scales', 'model.layers.6.self_attn.v_proj.qzeros_zeros', 'model.layers.7.mlp.down_proj.g_idx', 'model.layers.7.mlp.down_proj.qscales_scales', 'model.layers.7.mlp.down_proj.qscales_zeros', 'model.layers.7.mlp.down_proj.qstatistic', 'model.layers.7.mlp.down_proj.qweight', 'model.layers.7.mlp.down_proj.qzeros_scales', 'model.layers.7.mlp.down_proj.qzeros_zeros', 'model.layers.7.mlp.gate_proj.g_idx', 'model.layers.7.mlp.gate_proj.qscales_scales', 'model.layers.7.mlp.gate_proj.qscales_zeros', 'model.layers.7.mlp.gate_proj.qstatistic', 'model.layers.7.mlp.gate_proj.qweight', 'model.layers.7.mlp.gate_proj.qzeros_scales', 'model.layers.7.mlp.gate_proj.qzeros_zeros', 'model.layers.7.mlp.up_proj.g_idx', 'model.layers.7.mlp.up_proj.qscales_scales', 'model.layers.7.mlp.up_proj.qscales_zeros', 'model.layers.7.mlp.up_proj.qstatistic', 'model.layers.7.mlp.up_proj.qweight', 'model.layers.7.mlp.up_proj.qzeros_scales', 'model.layers.7.mlp.up_proj.qzeros_zeros', 'model.layers.7.self_attn.k_proj.g_idx', 'model.layers.7.self_attn.k_proj.qscales_scales', 'model.layers.7.self_attn.k_proj.qscales_zeros', 'model.layers.7.self_attn.k_proj.qstatistic', 'model.layers.7.self_attn.k_proj.qweight', 'model.layers.7.self_attn.k_proj.qzeros_scales', 'model.layers.7.self_attn.k_proj.qzeros_zeros', 'model.layers.7.self_attn.o_proj.g_idx', 'model.layers.7.self_attn.o_proj.qscales_scales', 'model.layers.7.self_attn.o_proj.qscales_zeros', 'model.layers.7.self_attn.o_proj.qstatistic', 'model.layers.7.self_attn.o_proj.qweight', 'model.layers.7.self_attn.o_proj.qzeros_scales', 'model.layers.7.self_attn.o_proj.qzeros_zeros', 'model.layers.7.self_attn.q_proj.g_idx', 'model.layers.7.self_attn.q_proj.qscales_scales', 'model.layers.7.self_attn.q_proj.qscales_zeros', 'model.layers.7.self_attn.q_proj.qstatistic', 'model.layers.7.self_attn.q_proj.qweight', 'model.layers.7.self_attn.q_proj.qzeros_scales', 'model.layers.7.self_attn.q_proj.qzeros_zeros', 'model.layers.7.self_attn.v_proj.g_idx', 'model.layers.7.self_attn.v_proj.qscales_scales', 'model.layers.7.self_attn.v_proj.qscales_zeros', 'model.layers.7.self_attn.v_proj.qstatistic', 'model.layers.7.self_attn.v_proj.qweight', 'model.layers.7.self_attn.v_proj.qzeros_scales', 'model.layers.7.self_attn.v_proj.qzeros_zeros', 'model.layers.8.mlp.down_proj.g_idx', 'model.layers.8.mlp.down_proj.qscales_scales', 'model.layers.8.mlp.down_proj.qscales_zeros', 'model.layers.8.mlp.down_proj.qstatistic', 'model.layers.8.mlp.down_proj.qweight', 'model.layers.8.mlp.down_proj.qzeros_scales', 'model.layers.8.mlp.down_proj.qzeros_zeros', 'model.layers.8.mlp.gate_proj.g_idx', 'model.layers.8.mlp.gate_proj.qscales_scales', 'model.layers.8.mlp.gate_proj.qscales_zeros', 'model.layers.8.mlp.gate_proj.qstatistic', 'model.layers.8.mlp.gate_proj.qweight', 'model.layers.8.mlp.gate_proj.qzeros_scales', 'model.layers.8.mlp.gate_proj.qzeros_zeros', 'model.layers.8.mlp.up_proj.g_idx', 'model.layers.8.mlp.up_proj.qscales_scales', 'model.layers.8.mlp.up_proj.qscales_zeros', 'model.layers.8.mlp.up_proj.qstatistic', 'model.layers.8.mlp.up_proj.qweight', 'model.layers.8.mlp.up_proj.qzeros_scales', 'model.layers.8.mlp.up_proj.qzeros_zeros', 'model.layers.8.self_attn.k_proj.g_idx', 'model.layers.8.self_attn.k_proj.qscales_scales', 'model.layers.8.self_attn.k_proj.qscales_zeros', 'model.layers.8.self_attn.k_proj.qstatistic', 'model.layers.8.self_attn.k_proj.qweight', 'model.layers.8.self_attn.k_proj.qzeros_scales', 'model.layers.8.self_attn.k_proj.qzeros_zeros', 'model.layers.8.self_attn.o_proj.g_idx', 'model.layers.8.self_attn.o_proj.qscales_scales', 'model.layers.8.self_attn.o_proj.qscales_zeros', 'model.layers.8.self_attn.o_proj.qstatistic', 'model.layers.8.self_attn.o_proj.qweight', 'model.layers.8.self_attn.o_proj.qzeros_scales', 'model.layers.8.self_attn.o_proj.qzeros_zeros', 'model.layers.8.self_attn.q_proj.g_idx', 'model.layers.8.self_attn.q_proj.qscales_scales', 'model.layers.8.self_attn.q_proj.qscales_zeros', 'model.layers.8.self_attn.q_proj.qstatistic', 'model.layers.8.self_attn.q_proj.qweight', 'model.layers.8.self_attn.q_proj.qzeros_scales', 'model.layers.8.self_attn.q_proj.qzeros_zeros', 'model.layers.8.self_attn.v_proj.g_idx', 'model.layers.8.self_attn.v_proj.qscales_scales', 'model.layers.8.self_attn.v_proj.qscales_zeros', 'model.layers.8.self_attn.v_proj.qstatistic', 'model.layers.8.self_attn.v_proj.qweight', 'model.layers.8.self_attn.v_proj.qzeros_scales', 'model.layers.8.self_attn.v_proj.qzeros_zeros', 'model.layers.9.mlp.down_proj.g_idx', 'model.layers.9.mlp.down_proj.qscales_scales', 'model.layers.9.mlp.down_proj.qscales_zeros', 'model.layers.9.mlp.down_proj.qstatistic', 'model.layers.9.mlp.down_proj.qweight', 'model.layers.9.mlp.down_proj.qzeros_scales', 'model.layers.9.mlp.down_proj.qzeros_zeros', 'model.layers.9.mlp.gate_proj.g_idx', 'model.layers.9.mlp.gate_proj.qscales_scales', 'model.layers.9.mlp.gate_proj.qscales_zeros', 'model.layers.9.mlp.gate_proj.qstatistic', 'model.layers.9.mlp.gate_proj.qweight', 'model.layers.9.mlp.gate_proj.qzeros_scales', 'model.layers.9.mlp.gate_proj.qzeros_zeros', 'model.layers.9.mlp.up_proj.g_idx', 'model.layers.9.mlp.up_proj.qscales_scales', 'model.layers.9.mlp.up_proj.qscales_zeros', 'model.layers.9.mlp.up_proj.qstatistic', 'model.layers.9.mlp.up_proj.qweight', 'model.layers.9.mlp.up_proj.qzeros_scales', 'model.layers.9.mlp.up_proj.qzeros_zeros', 'model.layers.9.self_attn.k_proj.g_idx', 'model.layers.9.self_attn.k_proj.qscales_scales', 'model.layers.9.self_attn.k_proj.qscales_zeros', 'model.layers.9.self_attn.k_proj.qstatistic', 'model.layers.9.self_attn.k_proj.qweight', 'model.layers.9.self_attn.k_proj.qzeros_scales', 'model.layers.9.self_attn.k_proj.qzeros_zeros', 'model.layers.9.self_attn.o_proj.g_idx', 'model.layers.9.self_attn.o_proj.qscales_scales', 'model.layers.9.self_attn.o_proj.qscales_zeros', 'model.layers.9.self_attn.o_proj.qstatistic', 'model.layers.9.self_attn.o_proj.qweight', 'model.layers.9.self_attn.o_proj.qzeros_scales', 'model.layers.9.self_attn.o_proj.qzeros_zeros', 'model.layers.9.self_attn.q_proj.g_idx', 'model.layers.9.self_attn.q_proj.qscales_scales', 'model.layers.9.self_attn.q_proj.qscales_zeros', 'model.layers.9.self_attn.q_proj.qstatistic', 'model.layers.9.self_attn.q_proj.qweight', 'model.layers.9.self_attn.q_proj.qzeros_scales', 'model.layers.9.self_attn.q_proj.qzeros_zeros', 'model.layers.9.self_attn.v_proj.g_idx', 'model.layers.9.self_attn.v_proj.qscales_scales', 'model.layers.9.self_attn.v_proj.qscales_zeros', 'model.layers.9.self_attn.v_proj.qstatistic', 'model.layers.9.self_attn.v_proj.qweight', 'model.layers.9.self_attn.v_proj.qzeros_scales', 'model.layers.9.self_attn.v_proj.qzeros_zeros']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Who is Einstein?\n",
            "Assistant:menmenmenmenmenmenmendydydydydy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_evaluate.py -s 6b -b 2 -g 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkuTg7aE1tS",
        "outputId": "1f18bc6c-616e-4787-fc4f-7ce5a62c336d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 00:35:33.684206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741912534.018672   18486 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741912534.112021   18486 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741912534.815856   18486 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741912534.815917   18486 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741912534.815922   18486 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741912534.815931   18486 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 406, in hf_raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mresponse.raise_for_status()\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise HTTPError(http_error_msg, response=self)\u001b[0m\n",
            "\u001b[0m\u001b[0mrequests.exceptions\u001b[0m.\u001b[0mHTTPError\u001b[0m: \u001b[0m404 Client Error: Not Found for url: https://huggingface.co/GreenBitAI/yi-6b-w2a16g8/resolve/main/config.json\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 424, in cached_files\n",
            "\u001b[0m\u001b[0m    \u001b[0mhf_hub_download(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn _hf_hub_download_to_cache_dir(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 967, in _hf_hub_download_to_cache_dir\n",
            "\u001b[0m\u001b[0m    \u001b[0m_raise_on_head_call_error(head_call_error, force_download, local_files_only)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1482, in _raise_on_head_call_error\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise head_call_error\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1374, in _get_metadata_or_catch_error\n",
            "\u001b[0m\u001b[0m    \u001b[0mmetadata = get_hf_file_metadata(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1294, in get_hf_file_metadata\n",
            "\u001b[0m\u001b[0m    \u001b[0mr = _request_wrapper(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 278, in _request_wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mresponse = _request_wrapper(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 302, in _request_wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mhf_raise_for_status(response)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 454, in hf_raise_for_status\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise _format(RepositoryNotFoundError, message, response) from e\u001b[0m\n",
            "\u001b[0m\u001b[0mhuggingface_hub.errors\u001b[0m.\u001b[0mRepositoryNotFoundError\u001b[0m: \u001b[0m404 Client Error. (Request ID: Root=1-67d379dd-4f5df35b197028d36b0e9407;3ce77675-8542-4219-b7ac-9890c01ed5af)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/GreenBitAI/yi-6b-w2a16g8/resolve/main/config.json.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_evaluate.py\", line 36, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=bits, half=True, v1=v1, asym=asym, kquant=kquant)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 149, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig = AutoConfig.from_pretrained(model_uri, cache_dir=cache_dir)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1090, in from_pretrained\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 594, in get_config_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mconfig_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 653, in _get_config_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mresolved_config_file = cached_file(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 266, in cached_file\n",
            "\u001b[0m\u001b[0m    \u001b[0mfile = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 456, in cached_files\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise EnvironmentError(\u001b[0m\n",
            "\u001b[0m\u001b[0mOSError\u001b[0m: \u001b[0mGreenBitAI/yi-6b-w2a16g8 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token XXXXXXXXXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDsZG0uFE2Kf",
        "outputId": "e72e72b4-4b99-4b59-b85b-a3e060c9ff23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"GreenBitAI/yi-6b-w4a16g32\", torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "question = \"من هو أينشتاين؟\"\n",
        "\n",
        "# مُوجه الدخل\n",
        "prompt = f\"User: {question}\\nAssistant:\"\n",
        "\n",
        "# توليد النص مع معلمات مُعدلة\n",
        "output = generator(prompt, max_new_tokens=50, temperature=0.2, top_k=50, do_sample=True)[0]\n",
        "\n",
        "print(output[\"generated_text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsZF94uLFb_g",
        "outputId": "34d81191-eaad-41f5-b483-6425019c462d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at GreenBitAI/yi-6b-w4a16g32 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.g_idx', 'model.layers.0.mlp.down_proj.qscales_scales', 'model.layers.0.mlp.down_proj.qscales_zeros', 'model.layers.0.mlp.down_proj.qstatistic', 'model.layers.0.mlp.down_proj.qweight', 'model.layers.0.mlp.down_proj.qzeros_scales', 'model.layers.0.mlp.down_proj.qzeros_zeros', 'model.layers.0.mlp.gate_proj.g_idx', 'model.layers.0.mlp.gate_proj.qscales_scales', 'model.layers.0.mlp.gate_proj.qscales_zeros', 'model.layers.0.mlp.gate_proj.qstatistic', 'model.layers.0.mlp.gate_proj.qweight', 'model.layers.0.mlp.gate_proj.qzeros_scales', 'model.layers.0.mlp.gate_proj.qzeros_zeros', 'model.layers.0.mlp.up_proj.g_idx', 'model.layers.0.mlp.up_proj.qscales_scales', 'model.layers.0.mlp.up_proj.qscales_zeros', 'model.layers.0.mlp.up_proj.qstatistic', 'model.layers.0.mlp.up_proj.qweight', 'model.layers.0.mlp.up_proj.qzeros_scales', 'model.layers.0.mlp.up_proj.qzeros_zeros', 'model.layers.0.self_attn.k_proj.g_idx', 'model.layers.0.self_attn.k_proj.qscales_scales', 'model.layers.0.self_attn.k_proj.qscales_zeros', 'model.layers.0.self_attn.k_proj.qstatistic', 'model.layers.0.self_attn.k_proj.qweight', 'model.layers.0.self_attn.k_proj.qzeros_scales', 'model.layers.0.self_attn.k_proj.qzeros_zeros', 'model.layers.0.self_attn.o_proj.g_idx', 'model.layers.0.self_attn.o_proj.qscales_scales', 'model.layers.0.self_attn.o_proj.qscales_zeros', 'model.layers.0.self_attn.o_proj.qstatistic', 'model.layers.0.self_attn.o_proj.qweight', 'model.layers.0.self_attn.o_proj.qzeros_scales', 'model.layers.0.self_attn.o_proj.qzeros_zeros', 'model.layers.0.self_attn.q_proj.g_idx', 'model.layers.0.self_attn.q_proj.qscales_scales', 'model.layers.0.self_attn.q_proj.qscales_zeros', 'model.layers.0.self_attn.q_proj.qstatistic', 'model.layers.0.self_attn.q_proj.qweight', 'model.layers.0.self_attn.q_proj.qzeros_scales', 'model.layers.0.self_attn.q_proj.qzeros_zeros', 'model.layers.0.self_attn.v_proj.g_idx', 'model.layers.0.self_attn.v_proj.qscales_scales', 'model.layers.0.self_attn.v_proj.qscales_zeros', 'model.layers.0.self_attn.v_proj.qstatistic', 'model.layers.0.self_attn.v_proj.qweight', 'model.layers.0.self_attn.v_proj.qzeros_scales', 'model.layers.0.self_attn.v_proj.qzeros_zeros', 'model.layers.1.mlp.down_proj.g_idx', 'model.layers.1.mlp.down_proj.qscales_scales', 'model.layers.1.mlp.down_proj.qscales_zeros', 'model.layers.1.mlp.down_proj.qstatistic', 'model.layers.1.mlp.down_proj.qweight', 'model.layers.1.mlp.down_proj.qzeros_scales', 'model.layers.1.mlp.down_proj.qzeros_zeros', 'model.layers.1.mlp.gate_proj.g_idx', 'model.layers.1.mlp.gate_proj.qscales_scales', 'model.layers.1.mlp.gate_proj.qscales_zeros', 'model.layers.1.mlp.gate_proj.qstatistic', 'model.layers.1.mlp.gate_proj.qweight', 'model.layers.1.mlp.gate_proj.qzeros_scales', 'model.layers.1.mlp.gate_proj.qzeros_zeros', 'model.layers.1.mlp.up_proj.g_idx', 'model.layers.1.mlp.up_proj.qscales_scales', 'model.layers.1.mlp.up_proj.qscales_zeros', 'model.layers.1.mlp.up_proj.qstatistic', 'model.layers.1.mlp.up_proj.qweight', 'model.layers.1.mlp.up_proj.qzeros_scales', 'model.layers.1.mlp.up_proj.qzeros_zeros', 'model.layers.1.self_attn.k_proj.g_idx', 'model.layers.1.self_attn.k_proj.qscales_scales', 'model.layers.1.self_attn.k_proj.qscales_zeros', 'model.layers.1.self_attn.k_proj.qstatistic', 'model.layers.1.self_attn.k_proj.qweight', 'model.layers.1.self_attn.k_proj.qzeros_scales', 'model.layers.1.self_attn.k_proj.qzeros_zeros', 'model.layers.1.self_attn.o_proj.g_idx', 'model.layers.1.self_attn.o_proj.qscales_scales', 'model.layers.1.self_attn.o_proj.qscales_zeros', 'model.layers.1.self_attn.o_proj.qstatistic', 'model.layers.1.self_attn.o_proj.qweight', 'model.layers.1.self_attn.o_proj.qzeros_scales', 'model.layers.1.self_attn.o_proj.qzeros_zeros', 'model.layers.1.self_attn.q_proj.g_idx', 'model.layers.1.self_attn.q_proj.qscales_scales', 'model.layers.1.self_attn.q_proj.qscales_zeros', 'model.layers.1.self_attn.q_proj.qstatistic', 'model.layers.1.self_attn.q_proj.qweight', 'model.layers.1.self_attn.q_proj.qzeros_scales', 'model.layers.1.self_attn.q_proj.qzeros_zeros', 'model.layers.1.self_attn.v_proj.g_idx', 'model.layers.1.self_attn.v_proj.qscales_scales', 'model.layers.1.self_attn.v_proj.qscales_zeros', 'model.layers.1.self_attn.v_proj.qstatistic', 'model.layers.1.self_attn.v_proj.qweight', 'model.layers.1.self_attn.v_proj.qzeros_scales', 'model.layers.1.self_attn.v_proj.qzeros_zeros', 'model.layers.10.mlp.down_proj.g_idx', 'model.layers.10.mlp.down_proj.qscales_scales', 'model.layers.10.mlp.down_proj.qscales_zeros', 'model.layers.10.mlp.down_proj.qstatistic', 'model.layers.10.mlp.down_proj.qweight', 'model.layers.10.mlp.down_proj.qzeros_scales', 'model.layers.10.mlp.down_proj.qzeros_zeros', 'model.layers.10.mlp.gate_proj.g_idx', 'model.layers.10.mlp.gate_proj.qscales_scales', 'model.layers.10.mlp.gate_proj.qscales_zeros', 'model.layers.10.mlp.gate_proj.qstatistic', 'model.layers.10.mlp.gate_proj.qweight', 'model.layers.10.mlp.gate_proj.qzeros_scales', 'model.layers.10.mlp.gate_proj.qzeros_zeros', 'model.layers.10.mlp.up_proj.g_idx', 'model.layers.10.mlp.up_proj.qscales_scales', 'model.layers.10.mlp.up_proj.qscales_zeros', 'model.layers.10.mlp.up_proj.qstatistic', 'model.layers.10.mlp.up_proj.qweight', 'model.layers.10.mlp.up_proj.qzeros_scales', 'model.layers.10.mlp.up_proj.qzeros_zeros', 'model.layers.10.self_attn.k_proj.g_idx', 'model.layers.10.self_attn.k_proj.qscales_scales', 'model.layers.10.self_attn.k_proj.qscales_zeros', 'model.layers.10.self_attn.k_proj.qstatistic', 'model.layers.10.self_attn.k_proj.qweight', 'model.layers.10.self_attn.k_proj.qzeros_scales', 'model.layers.10.self_attn.k_proj.qzeros_zeros', 'model.layers.10.self_attn.o_proj.g_idx', 'model.layers.10.self_attn.o_proj.qscales_scales', 'model.layers.10.self_attn.o_proj.qscales_zeros', 'model.layers.10.self_attn.o_proj.qstatistic', 'model.layers.10.self_attn.o_proj.qweight', 'model.layers.10.self_attn.o_proj.qzeros_scales', 'model.layers.10.self_attn.o_proj.qzeros_zeros', 'model.layers.10.self_attn.q_proj.g_idx', 'model.layers.10.self_attn.q_proj.qscales_scales', 'model.layers.10.self_attn.q_proj.qscales_zeros', 'model.layers.10.self_attn.q_proj.qstatistic', 'model.layers.10.self_attn.q_proj.qweight', 'model.layers.10.self_attn.q_proj.qzeros_scales', 'model.layers.10.self_attn.q_proj.qzeros_zeros', 'model.layers.10.self_attn.v_proj.g_idx', 'model.layers.10.self_attn.v_proj.qscales_scales', 'model.layers.10.self_attn.v_proj.qscales_zeros', 'model.layers.10.self_attn.v_proj.qstatistic', 'model.layers.10.self_attn.v_proj.qweight', 'model.layers.10.self_attn.v_proj.qzeros_scales', 'model.layers.10.self_attn.v_proj.qzeros_zeros', 'model.layers.11.mlp.down_proj.g_idx', 'model.layers.11.mlp.down_proj.qscales_scales', 'model.layers.11.mlp.down_proj.qscales_zeros', 'model.layers.11.mlp.down_proj.qstatistic', 'model.layers.11.mlp.down_proj.qweight', 'model.layers.11.mlp.down_proj.qzeros_scales', 'model.layers.11.mlp.down_proj.qzeros_zeros', 'model.layers.11.mlp.gate_proj.g_idx', 'model.layers.11.mlp.gate_proj.qscales_scales', 'model.layers.11.mlp.gate_proj.qscales_zeros', 'model.layers.11.mlp.gate_proj.qstatistic', 'model.layers.11.mlp.gate_proj.qweight', 'model.layers.11.mlp.gate_proj.qzeros_scales', 'model.layers.11.mlp.gate_proj.qzeros_zeros', 'model.layers.11.mlp.up_proj.g_idx', 'model.layers.11.mlp.up_proj.qscales_scales', 'model.layers.11.mlp.up_proj.qscales_zeros', 'model.layers.11.mlp.up_proj.qstatistic', 'model.layers.11.mlp.up_proj.qweight', 'model.layers.11.mlp.up_proj.qzeros_scales', 'model.layers.11.mlp.up_proj.qzeros_zeros', 'model.layers.11.self_attn.k_proj.g_idx', 'model.layers.11.self_attn.k_proj.qscales_scales', 'model.layers.11.self_attn.k_proj.qscales_zeros', 'model.layers.11.self_attn.k_proj.qstatistic', 'model.layers.11.self_attn.k_proj.qweight', 'model.layers.11.self_attn.k_proj.qzeros_scales', 'model.layers.11.self_attn.k_proj.qzeros_zeros', 'model.layers.11.self_attn.o_proj.g_idx', 'model.layers.11.self_attn.o_proj.qscales_scales', 'model.layers.11.self_attn.o_proj.qscales_zeros', 'model.layers.11.self_attn.o_proj.qstatistic', 'model.layers.11.self_attn.o_proj.qweight', 'model.layers.11.self_attn.o_proj.qzeros_scales', 'model.layers.11.self_attn.o_proj.qzeros_zeros', 'model.layers.11.self_attn.q_proj.g_idx', 'model.layers.11.self_attn.q_proj.qscales_scales', 'model.layers.11.self_attn.q_proj.qscales_zeros', 'model.layers.11.self_attn.q_proj.qstatistic', 'model.layers.11.self_attn.q_proj.qweight', 'model.layers.11.self_attn.q_proj.qzeros_scales', 'model.layers.11.self_attn.q_proj.qzeros_zeros', 'model.layers.11.self_attn.v_proj.g_idx', 'model.layers.11.self_attn.v_proj.qscales_scales', 'model.layers.11.self_attn.v_proj.qscales_zeros', 'model.layers.11.self_attn.v_proj.qstatistic', 'model.layers.11.self_attn.v_proj.qweight', 'model.layers.11.self_attn.v_proj.qzeros_scales', 'model.layers.11.self_attn.v_proj.qzeros_zeros', 'model.layers.12.mlp.down_proj.g_idx', 'model.layers.12.mlp.down_proj.qscales_scales', 'model.layers.12.mlp.down_proj.qscales_zeros', 'model.layers.12.mlp.down_proj.qstatistic', 'model.layers.12.mlp.down_proj.qweight', 'model.layers.12.mlp.down_proj.qzeros_scales', 'model.layers.12.mlp.down_proj.qzeros_zeros', 'model.layers.12.mlp.gate_proj.g_idx', 'model.layers.12.mlp.gate_proj.qscales_scales', 'model.layers.12.mlp.gate_proj.qscales_zeros', 'model.layers.12.mlp.gate_proj.qstatistic', 'model.layers.12.mlp.gate_proj.qweight', 'model.layers.12.mlp.gate_proj.qzeros_scales', 'model.layers.12.mlp.gate_proj.qzeros_zeros', 'model.layers.12.mlp.up_proj.g_idx', 'model.layers.12.mlp.up_proj.qscales_scales', 'model.layers.12.mlp.up_proj.qscales_zeros', 'model.layers.12.mlp.up_proj.qstatistic', 'model.layers.12.mlp.up_proj.qweight', 'model.layers.12.mlp.up_proj.qzeros_scales', 'model.layers.12.mlp.up_proj.qzeros_zeros', 'model.layers.12.self_attn.k_proj.g_idx', 'model.layers.12.self_attn.k_proj.qscales_scales', 'model.layers.12.self_attn.k_proj.qscales_zeros', 'model.layers.12.self_attn.k_proj.qstatistic', 'model.layers.12.self_attn.k_proj.qweight', 'model.layers.12.self_attn.k_proj.qzeros_scales', 'model.layers.12.self_attn.k_proj.qzeros_zeros', 'model.layers.12.self_attn.o_proj.g_idx', 'model.layers.12.self_attn.o_proj.qscales_scales', 'model.layers.12.self_attn.o_proj.qscales_zeros', 'model.layers.12.self_attn.o_proj.qstatistic', 'model.layers.12.self_attn.o_proj.qweight', 'model.layers.12.self_attn.o_proj.qzeros_scales', 'model.layers.12.self_attn.o_proj.qzeros_zeros', 'model.layers.12.self_attn.q_proj.g_idx', 'model.layers.12.self_attn.q_proj.qscales_scales', 'model.layers.12.self_attn.q_proj.qscales_zeros', 'model.layers.12.self_attn.q_proj.qstatistic', 'model.layers.12.self_attn.q_proj.qweight', 'model.layers.12.self_attn.q_proj.qzeros_scales', 'model.layers.12.self_attn.q_proj.qzeros_zeros', 'model.layers.12.self_attn.v_proj.g_idx', 'model.layers.12.self_attn.v_proj.qscales_scales', 'model.layers.12.self_attn.v_proj.qscales_zeros', 'model.layers.12.self_attn.v_proj.qstatistic', 'model.layers.12.self_attn.v_proj.qweight', 'model.layers.12.self_attn.v_proj.qzeros_scales', 'model.layers.12.self_attn.v_proj.qzeros_zeros', 'model.layers.13.mlp.down_proj.g_idx', 'model.layers.13.mlp.down_proj.qscales_scales', 'model.layers.13.mlp.down_proj.qscales_zeros', 'model.layers.13.mlp.down_proj.qstatistic', 'model.layers.13.mlp.down_proj.qweight', 'model.layers.13.mlp.down_proj.qzeros_scales', 'model.layers.13.mlp.down_proj.qzeros_zeros', 'model.layers.13.mlp.gate_proj.g_idx', 'model.layers.13.mlp.gate_proj.qscales_scales', 'model.layers.13.mlp.gate_proj.qscales_zeros', 'model.layers.13.mlp.gate_proj.qstatistic', 'model.layers.13.mlp.gate_proj.qweight', 'model.layers.13.mlp.gate_proj.qzeros_scales', 'model.layers.13.mlp.gate_proj.qzeros_zeros', 'model.layers.13.mlp.up_proj.g_idx', 'model.layers.13.mlp.up_proj.qscales_scales', 'model.layers.13.mlp.up_proj.qscales_zeros', 'model.layers.13.mlp.up_proj.qstatistic', 'model.layers.13.mlp.up_proj.qweight', 'model.layers.13.mlp.up_proj.qzeros_scales', 'model.layers.13.mlp.up_proj.qzeros_zeros', 'model.layers.13.self_attn.k_proj.g_idx', 'model.layers.13.self_attn.k_proj.qscales_scales', 'model.layers.13.self_attn.k_proj.qscales_zeros', 'model.layers.13.self_attn.k_proj.qstatistic', 'model.layers.13.self_attn.k_proj.qweight', 'model.layers.13.self_attn.k_proj.qzeros_scales', 'model.layers.13.self_attn.k_proj.qzeros_zeros', 'model.layers.13.self_attn.o_proj.g_idx', 'model.layers.13.self_attn.o_proj.qscales_scales', 'model.layers.13.self_attn.o_proj.qscales_zeros', 'model.layers.13.self_attn.o_proj.qstatistic', 'model.layers.13.self_attn.o_proj.qweight', 'model.layers.13.self_attn.o_proj.qzeros_scales', 'model.layers.13.self_attn.o_proj.qzeros_zeros', 'model.layers.13.self_attn.q_proj.g_idx', 'model.layers.13.self_attn.q_proj.qscales_scales', 'model.layers.13.self_attn.q_proj.qscales_zeros', 'model.layers.13.self_attn.q_proj.qstatistic', 'model.layers.13.self_attn.q_proj.qweight', 'model.layers.13.self_attn.q_proj.qzeros_scales', 'model.layers.13.self_attn.q_proj.qzeros_zeros', 'model.layers.13.self_attn.v_proj.g_idx', 'model.layers.13.self_attn.v_proj.qscales_scales', 'model.layers.13.self_attn.v_proj.qscales_zeros', 'model.layers.13.self_attn.v_proj.qstatistic', 'model.layers.13.self_attn.v_proj.qweight', 'model.layers.13.self_attn.v_proj.qzeros_scales', 'model.layers.13.self_attn.v_proj.qzeros_zeros', 'model.layers.14.mlp.down_proj.g_idx', 'model.layers.14.mlp.down_proj.qscales_scales', 'model.layers.14.mlp.down_proj.qscales_zeros', 'model.layers.14.mlp.down_proj.qstatistic', 'model.layers.14.mlp.down_proj.qweight', 'model.layers.14.mlp.down_proj.qzeros_scales', 'model.layers.14.mlp.down_proj.qzeros_zeros', 'model.layers.14.mlp.gate_proj.g_idx', 'model.layers.14.mlp.gate_proj.qscales_scales', 'model.layers.14.mlp.gate_proj.qscales_zeros', 'model.layers.14.mlp.gate_proj.qstatistic', 'model.layers.14.mlp.gate_proj.qweight', 'model.layers.14.mlp.gate_proj.qzeros_scales', 'model.layers.14.mlp.gate_proj.qzeros_zeros', 'model.layers.14.mlp.up_proj.g_idx', 'model.layers.14.mlp.up_proj.qscales_scales', 'model.layers.14.mlp.up_proj.qscales_zeros', 'model.layers.14.mlp.up_proj.qstatistic', 'model.layers.14.mlp.up_proj.qweight', 'model.layers.14.mlp.up_proj.qzeros_scales', 'model.layers.14.mlp.up_proj.qzeros_zeros', 'model.layers.14.self_attn.k_proj.g_idx', 'model.layers.14.self_attn.k_proj.qscales_scales', 'model.layers.14.self_attn.k_proj.qscales_zeros', 'model.layers.14.self_attn.k_proj.qstatistic', 'model.layers.14.self_attn.k_proj.qweight', 'model.layers.14.self_attn.k_proj.qzeros_scales', 'model.layers.14.self_attn.k_proj.qzeros_zeros', 'model.layers.14.self_attn.o_proj.g_idx', 'model.layers.14.self_attn.o_proj.qscales_scales', 'model.layers.14.self_attn.o_proj.qscales_zeros', 'model.layers.14.self_attn.o_proj.qstatistic', 'model.layers.14.self_attn.o_proj.qweight', 'model.layers.14.self_attn.o_proj.qzeros_scales', 'model.layers.14.self_attn.o_proj.qzeros_zeros', 'model.layers.14.self_attn.q_proj.g_idx', 'model.layers.14.self_attn.q_proj.qscales_scales', 'model.layers.14.self_attn.q_proj.qscales_zeros', 'model.layers.14.self_attn.q_proj.qstatistic', 'model.layers.14.self_attn.q_proj.qweight', 'model.layers.14.self_attn.q_proj.qzeros_scales', 'model.layers.14.self_attn.q_proj.qzeros_zeros', 'model.layers.14.self_attn.v_proj.g_idx', 'model.layers.14.self_attn.v_proj.qscales_scales', 'model.layers.14.self_attn.v_proj.qscales_zeros', 'model.layers.14.self_attn.v_proj.qstatistic', 'model.layers.14.self_attn.v_proj.qweight', 'model.layers.14.self_attn.v_proj.qzeros_scales', 'model.layers.14.self_attn.v_proj.qzeros_zeros', 'model.layers.15.mlp.down_proj.g_idx', 'model.layers.15.mlp.down_proj.qscales_scales', 'model.layers.15.mlp.down_proj.qscales_zeros', 'model.layers.15.mlp.down_proj.qstatistic', 'model.layers.15.mlp.down_proj.qweight', 'model.layers.15.mlp.down_proj.qzeros_scales', 'model.layers.15.mlp.down_proj.qzeros_zeros', 'model.layers.15.mlp.gate_proj.g_idx', 'model.layers.15.mlp.gate_proj.qscales_scales', 'model.layers.15.mlp.gate_proj.qscales_zeros', 'model.layers.15.mlp.gate_proj.qstatistic', 'model.layers.15.mlp.gate_proj.qweight', 'model.layers.15.mlp.gate_proj.qzeros_scales', 'model.layers.15.mlp.gate_proj.qzeros_zeros', 'model.layers.15.mlp.up_proj.g_idx', 'model.layers.15.mlp.up_proj.qscales_scales', 'model.layers.15.mlp.up_proj.qscales_zeros', 'model.layers.15.mlp.up_proj.qstatistic', 'model.layers.15.mlp.up_proj.qweight', 'model.layers.15.mlp.up_proj.qzeros_scales', 'model.layers.15.mlp.up_proj.qzeros_zeros', 'model.layers.15.self_attn.k_proj.g_idx', 'model.layers.15.self_attn.k_proj.qscales_scales', 'model.layers.15.self_attn.k_proj.qscales_zeros', 'model.layers.15.self_attn.k_proj.qstatistic', 'model.layers.15.self_attn.k_proj.qweight', 'model.layers.15.self_attn.k_proj.qzeros_scales', 'model.layers.15.self_attn.k_proj.qzeros_zeros', 'model.layers.15.self_attn.o_proj.g_idx', 'model.layers.15.self_attn.o_proj.qscales_scales', 'model.layers.15.self_attn.o_proj.qscales_zeros', 'model.layers.15.self_attn.o_proj.qstatistic', 'model.layers.15.self_attn.o_proj.qweight', 'model.layers.15.self_attn.o_proj.qzeros_scales', 'model.layers.15.self_attn.o_proj.qzeros_zeros', 'model.layers.15.self_attn.q_proj.g_idx', 'model.layers.15.self_attn.q_proj.qscales_scales', 'model.layers.15.self_attn.q_proj.qscales_zeros', 'model.layers.15.self_attn.q_proj.qstatistic', 'model.layers.15.self_attn.q_proj.qweight', 'model.layers.15.self_attn.q_proj.qzeros_scales', 'model.layers.15.self_attn.q_proj.qzeros_zeros', 'model.layers.15.self_attn.v_proj.g_idx', 'model.layers.15.self_attn.v_proj.qscales_scales', 'model.layers.15.self_attn.v_proj.qscales_zeros', 'model.layers.15.self_attn.v_proj.qstatistic', 'model.layers.15.self_attn.v_proj.qweight', 'model.layers.15.self_attn.v_proj.qzeros_scales', 'model.layers.15.self_attn.v_proj.qzeros_zeros', 'model.layers.16.mlp.down_proj.g_idx', 'model.layers.16.mlp.down_proj.qscales_scales', 'model.layers.16.mlp.down_proj.qscales_zeros', 'model.layers.16.mlp.down_proj.qstatistic', 'model.layers.16.mlp.down_proj.qweight', 'model.layers.16.mlp.down_proj.qzeros_scales', 'model.layers.16.mlp.down_proj.qzeros_zeros', 'model.layers.16.mlp.gate_proj.g_idx', 'model.layers.16.mlp.gate_proj.qscales_scales', 'model.layers.16.mlp.gate_proj.qscales_zeros', 'model.layers.16.mlp.gate_proj.qstatistic', 'model.layers.16.mlp.gate_proj.qweight', 'model.layers.16.mlp.gate_proj.qzeros_scales', 'model.layers.16.mlp.gate_proj.qzeros_zeros', 'model.layers.16.mlp.up_proj.g_idx', 'model.layers.16.mlp.up_proj.qscales_scales', 'model.layers.16.mlp.up_proj.qscales_zeros', 'model.layers.16.mlp.up_proj.qstatistic', 'model.layers.16.mlp.up_proj.qweight', 'model.layers.16.mlp.up_proj.qzeros_scales', 'model.layers.16.mlp.up_proj.qzeros_zeros', 'model.layers.16.self_attn.k_proj.g_idx', 'model.layers.16.self_attn.k_proj.qscales_scales', 'model.layers.16.self_attn.k_proj.qscales_zeros', 'model.layers.16.self_attn.k_proj.qstatistic', 'model.layers.16.self_attn.k_proj.qweight', 'model.layers.16.self_attn.k_proj.qzeros_scales', 'model.layers.16.self_attn.k_proj.qzeros_zeros', 'model.layers.16.self_attn.o_proj.g_idx', 'model.layers.16.self_attn.o_proj.qscales_scales', 'model.layers.16.self_attn.o_proj.qscales_zeros', 'model.layers.16.self_attn.o_proj.qstatistic', 'model.layers.16.self_attn.o_proj.qweight', 'model.layers.16.self_attn.o_proj.qzeros_scales', 'model.layers.16.self_attn.o_proj.qzeros_zeros', 'model.layers.16.self_attn.q_proj.g_idx', 'model.layers.16.self_attn.q_proj.qscales_scales', 'model.layers.16.self_attn.q_proj.qscales_zeros', 'model.layers.16.self_attn.q_proj.qstatistic', 'model.layers.16.self_attn.q_proj.qweight', 'model.layers.16.self_attn.q_proj.qzeros_scales', 'model.layers.16.self_attn.q_proj.qzeros_zeros', 'model.layers.16.self_attn.v_proj.g_idx', 'model.layers.16.self_attn.v_proj.qscales_scales', 'model.layers.16.self_attn.v_proj.qscales_zeros', 'model.layers.16.self_attn.v_proj.qstatistic', 'model.layers.16.self_attn.v_proj.qweight', 'model.layers.16.self_attn.v_proj.qzeros_scales', 'model.layers.16.self_attn.v_proj.qzeros_zeros', 'model.layers.17.mlp.down_proj.g_idx', 'model.layers.17.mlp.down_proj.qscales_scales', 'model.layers.17.mlp.down_proj.qscales_zeros', 'model.layers.17.mlp.down_proj.qstatistic', 'model.layers.17.mlp.down_proj.qweight', 'model.layers.17.mlp.down_proj.qzeros_scales', 'model.layers.17.mlp.down_proj.qzeros_zeros', 'model.layers.17.mlp.gate_proj.g_idx', 'model.layers.17.mlp.gate_proj.qscales_scales', 'model.layers.17.mlp.gate_proj.qscales_zeros', 'model.layers.17.mlp.gate_proj.qstatistic', 'model.layers.17.mlp.gate_proj.qweight', 'model.layers.17.mlp.gate_proj.qzeros_scales', 'model.layers.17.mlp.gate_proj.qzeros_zeros', 'model.layers.17.mlp.up_proj.g_idx', 'model.layers.17.mlp.up_proj.qscales_scales', 'model.layers.17.mlp.up_proj.qscales_zeros', 'model.layers.17.mlp.up_proj.qstatistic', 'model.layers.17.mlp.up_proj.qweight', 'model.layers.17.mlp.up_proj.qzeros_scales', 'model.layers.17.mlp.up_proj.qzeros_zeros', 'model.layers.17.self_attn.k_proj.g_idx', 'model.layers.17.self_attn.k_proj.qscales_scales', 'model.layers.17.self_attn.k_proj.qscales_zeros', 'model.layers.17.self_attn.k_proj.qstatistic', 'model.layers.17.self_attn.k_proj.qweight', 'model.layers.17.self_attn.k_proj.qzeros_scales', 'model.layers.17.self_attn.k_proj.qzeros_zeros', 'model.layers.17.self_attn.o_proj.g_idx', 'model.layers.17.self_attn.o_proj.qscales_scales', 'model.layers.17.self_attn.o_proj.qscales_zeros', 'model.layers.17.self_attn.o_proj.qstatistic', 'model.layers.17.self_attn.o_proj.qweight', 'model.layers.17.self_attn.o_proj.qzeros_scales', 'model.layers.17.self_attn.o_proj.qzeros_zeros', 'model.layers.17.self_attn.q_proj.g_idx', 'model.layers.17.self_attn.q_proj.qscales_scales', 'model.layers.17.self_attn.q_proj.qscales_zeros', 'model.layers.17.self_attn.q_proj.qstatistic', 'model.layers.17.self_attn.q_proj.qweight', 'model.layers.17.self_attn.q_proj.qzeros_scales', 'model.layers.17.self_attn.q_proj.qzeros_zeros', 'model.layers.17.self_attn.v_proj.g_idx', 'model.layers.17.self_attn.v_proj.qscales_scales', 'model.layers.17.self_attn.v_proj.qscales_zeros', 'model.layers.17.self_attn.v_proj.qstatistic', 'model.layers.17.self_attn.v_proj.qweight', 'model.layers.17.self_attn.v_proj.qzeros_scales', 'model.layers.17.self_attn.v_proj.qzeros_zeros', 'model.layers.18.mlp.down_proj.g_idx', 'model.layers.18.mlp.down_proj.qscales_scales', 'model.layers.18.mlp.down_proj.qscales_zeros', 'model.layers.18.mlp.down_proj.qstatistic', 'model.layers.18.mlp.down_proj.qweight', 'model.layers.18.mlp.down_proj.qzeros_scales', 'model.layers.18.mlp.down_proj.qzeros_zeros', 'model.layers.18.mlp.gate_proj.g_idx', 'model.layers.18.mlp.gate_proj.qscales_scales', 'model.layers.18.mlp.gate_proj.qscales_zeros', 'model.layers.18.mlp.gate_proj.qstatistic', 'model.layers.18.mlp.gate_proj.qweight', 'model.layers.18.mlp.gate_proj.qzeros_scales', 'model.layers.18.mlp.gate_proj.qzeros_zeros', 'model.layers.18.mlp.up_proj.g_idx', 'model.layers.18.mlp.up_proj.qscales_scales', 'model.layers.18.mlp.up_proj.qscales_zeros', 'model.layers.18.mlp.up_proj.qstatistic', 'model.layers.18.mlp.up_proj.qweight', 'model.layers.18.mlp.up_proj.qzeros_scales', 'model.layers.18.mlp.up_proj.qzeros_zeros', 'model.layers.18.self_attn.k_proj.g_idx', 'model.layers.18.self_attn.k_proj.qscales_scales', 'model.layers.18.self_attn.k_proj.qscales_zeros', 'model.layers.18.self_attn.k_proj.qstatistic', 'model.layers.18.self_attn.k_proj.qweight', 'model.layers.18.self_attn.k_proj.qzeros_scales', 'model.layers.18.self_attn.k_proj.qzeros_zeros', 'model.layers.18.self_attn.o_proj.g_idx', 'model.layers.18.self_attn.o_proj.qscales_scales', 'model.layers.18.self_attn.o_proj.qscales_zeros', 'model.layers.18.self_attn.o_proj.qstatistic', 'model.layers.18.self_attn.o_proj.qweight', 'model.layers.18.self_attn.o_proj.qzeros_scales', 'model.layers.18.self_attn.o_proj.qzeros_zeros', 'model.layers.18.self_attn.q_proj.g_idx', 'model.layers.18.self_attn.q_proj.qscales_scales', 'model.layers.18.self_attn.q_proj.qscales_zeros', 'model.layers.18.self_attn.q_proj.qstatistic', 'model.layers.18.self_attn.q_proj.qweight', 'model.layers.18.self_attn.q_proj.qzeros_scales', 'model.layers.18.self_attn.q_proj.qzeros_zeros', 'model.layers.18.self_attn.v_proj.g_idx', 'model.layers.18.self_attn.v_proj.qscales_scales', 'model.layers.18.self_attn.v_proj.qscales_zeros', 'model.layers.18.self_attn.v_proj.qstatistic', 'model.layers.18.self_attn.v_proj.qweight', 'model.layers.18.self_attn.v_proj.qzeros_scales', 'model.layers.18.self_attn.v_proj.qzeros_zeros', 'model.layers.19.mlp.down_proj.g_idx', 'model.layers.19.mlp.down_proj.qscales_scales', 'model.layers.19.mlp.down_proj.qscales_zeros', 'model.layers.19.mlp.down_proj.qstatistic', 'model.layers.19.mlp.down_proj.qweight', 'model.layers.19.mlp.down_proj.qzeros_scales', 'model.layers.19.mlp.down_proj.qzeros_zeros', 'model.layers.19.mlp.gate_proj.g_idx', 'model.layers.19.mlp.gate_proj.qscales_scales', 'model.layers.19.mlp.gate_proj.qscales_zeros', 'model.layers.19.mlp.gate_proj.qstatistic', 'model.layers.19.mlp.gate_proj.qweight', 'model.layers.19.mlp.gate_proj.qzeros_scales', 'model.layers.19.mlp.gate_proj.qzeros_zeros', 'model.layers.19.mlp.up_proj.g_idx', 'model.layers.19.mlp.up_proj.qscales_scales', 'model.layers.19.mlp.up_proj.qscales_zeros', 'model.layers.19.mlp.up_proj.qstatistic', 'model.layers.19.mlp.up_proj.qweight', 'model.layers.19.mlp.up_proj.qzeros_scales', 'model.layers.19.mlp.up_proj.qzeros_zeros', 'model.layers.19.self_attn.k_proj.g_idx', 'model.layers.19.self_attn.k_proj.qscales_scales', 'model.layers.19.self_attn.k_proj.qscales_zeros', 'model.layers.19.self_attn.k_proj.qstatistic', 'model.layers.19.self_attn.k_proj.qweight', 'model.layers.19.self_attn.k_proj.qzeros_scales', 'model.layers.19.self_attn.k_proj.qzeros_zeros', 'model.layers.19.self_attn.o_proj.g_idx', 'model.layers.19.self_attn.o_proj.qscales_scales', 'model.layers.19.self_attn.o_proj.qscales_zeros', 'model.layers.19.self_attn.o_proj.qstatistic', 'model.layers.19.self_attn.o_proj.qweight', 'model.layers.19.self_attn.o_proj.qzeros_scales', 'model.layers.19.self_attn.o_proj.qzeros_zeros', 'model.layers.19.self_attn.q_proj.g_idx', 'model.layers.19.self_attn.q_proj.qscales_scales', 'model.layers.19.self_attn.q_proj.qscales_zeros', 'model.layers.19.self_attn.q_proj.qstatistic', 'model.layers.19.self_attn.q_proj.qweight', 'model.layers.19.self_attn.q_proj.qzeros_scales', 'model.layers.19.self_attn.q_proj.qzeros_zeros', 'model.layers.19.self_attn.v_proj.g_idx', 'model.layers.19.self_attn.v_proj.qscales_scales', 'model.layers.19.self_attn.v_proj.qscales_zeros', 'model.layers.19.self_attn.v_proj.qstatistic', 'model.layers.19.self_attn.v_proj.qweight', 'model.layers.19.self_attn.v_proj.qzeros_scales', 'model.layers.19.self_attn.v_proj.qzeros_zeros', 'model.layers.2.mlp.down_proj.g_idx', 'model.layers.2.mlp.down_proj.qscales_scales', 'model.layers.2.mlp.down_proj.qscales_zeros', 'model.layers.2.mlp.down_proj.qstatistic', 'model.layers.2.mlp.down_proj.qweight', 'model.layers.2.mlp.down_proj.qzeros_scales', 'model.layers.2.mlp.down_proj.qzeros_zeros', 'model.layers.2.mlp.gate_proj.g_idx', 'model.layers.2.mlp.gate_proj.qscales_scales', 'model.layers.2.mlp.gate_proj.qscales_zeros', 'model.layers.2.mlp.gate_proj.qstatistic', 'model.layers.2.mlp.gate_proj.qweight', 'model.layers.2.mlp.gate_proj.qzeros_scales', 'model.layers.2.mlp.gate_proj.qzeros_zeros', 'model.layers.2.mlp.up_proj.g_idx', 'model.layers.2.mlp.up_proj.qscales_scales', 'model.layers.2.mlp.up_proj.qscales_zeros', 'model.layers.2.mlp.up_proj.qstatistic', 'model.layers.2.mlp.up_proj.qweight', 'model.layers.2.mlp.up_proj.qzeros_scales', 'model.layers.2.mlp.up_proj.qzeros_zeros', 'model.layers.2.self_attn.k_proj.g_idx', 'model.layers.2.self_attn.k_proj.qscales_scales', 'model.layers.2.self_attn.k_proj.qscales_zeros', 'model.layers.2.self_attn.k_proj.qstatistic', 'model.layers.2.self_attn.k_proj.qweight', 'model.layers.2.self_attn.k_proj.qzeros_scales', 'model.layers.2.self_attn.k_proj.qzeros_zeros', 'model.layers.2.self_attn.o_proj.g_idx', 'model.layers.2.self_attn.o_proj.qscales_scales', 'model.layers.2.self_attn.o_proj.qscales_zeros', 'model.layers.2.self_attn.o_proj.qstatistic', 'model.layers.2.self_attn.o_proj.qweight', 'model.layers.2.self_attn.o_proj.qzeros_scales', 'model.layers.2.self_attn.o_proj.qzeros_zeros', 'model.layers.2.self_attn.q_proj.g_idx', 'model.layers.2.self_attn.q_proj.qscales_scales', 'model.layers.2.self_attn.q_proj.qscales_zeros', 'model.layers.2.self_attn.q_proj.qstatistic', 'model.layers.2.self_attn.q_proj.qweight', 'model.layers.2.self_attn.q_proj.qzeros_scales', 'model.layers.2.self_attn.q_proj.qzeros_zeros', 'model.layers.2.self_attn.v_proj.g_idx', 'model.layers.2.self_attn.v_proj.qscales_scales', 'model.layers.2.self_attn.v_proj.qscales_zeros', 'model.layers.2.self_attn.v_proj.qstatistic', 'model.layers.2.self_attn.v_proj.qweight', 'model.layers.2.self_attn.v_proj.qzeros_scales', 'model.layers.2.self_attn.v_proj.qzeros_zeros', 'model.layers.20.mlp.down_proj.g_idx', 'model.layers.20.mlp.down_proj.qscales_scales', 'model.layers.20.mlp.down_proj.qscales_zeros', 'model.layers.20.mlp.down_proj.qstatistic', 'model.layers.20.mlp.down_proj.qweight', 'model.layers.20.mlp.down_proj.qzeros_scales', 'model.layers.20.mlp.down_proj.qzeros_zeros', 'model.layers.20.mlp.gate_proj.g_idx', 'model.layers.20.mlp.gate_proj.qscales_scales', 'model.layers.20.mlp.gate_proj.qscales_zeros', 'model.layers.20.mlp.gate_proj.qstatistic', 'model.layers.20.mlp.gate_proj.qweight', 'model.layers.20.mlp.gate_proj.qzeros_scales', 'model.layers.20.mlp.gate_proj.qzeros_zeros', 'model.layers.20.mlp.up_proj.g_idx', 'model.layers.20.mlp.up_proj.qscales_scales', 'model.layers.20.mlp.up_proj.qscales_zeros', 'model.layers.20.mlp.up_proj.qstatistic', 'model.layers.20.mlp.up_proj.qweight', 'model.layers.20.mlp.up_proj.qzeros_scales', 'model.layers.20.mlp.up_proj.qzeros_zeros', 'model.layers.20.self_attn.k_proj.g_idx', 'model.layers.20.self_attn.k_proj.qscales_scales', 'model.layers.20.self_attn.k_proj.qscales_zeros', 'model.layers.20.self_attn.k_proj.qstatistic', 'model.layers.20.self_attn.k_proj.qweight', 'model.layers.20.self_attn.k_proj.qzeros_scales', 'model.layers.20.self_attn.k_proj.qzeros_zeros', 'model.layers.20.self_attn.o_proj.g_idx', 'model.layers.20.self_attn.o_proj.qscales_scales', 'model.layers.20.self_attn.o_proj.qscales_zeros', 'model.layers.20.self_attn.o_proj.qstatistic', 'model.layers.20.self_attn.o_proj.qweight', 'model.layers.20.self_attn.o_proj.qzeros_scales', 'model.layers.20.self_attn.o_proj.qzeros_zeros', 'model.layers.20.self_attn.q_proj.g_idx', 'model.layers.20.self_attn.q_proj.qscales_scales', 'model.layers.20.self_attn.q_proj.qscales_zeros', 'model.layers.20.self_attn.q_proj.qstatistic', 'model.layers.20.self_attn.q_proj.qweight', 'model.layers.20.self_attn.q_proj.qzeros_scales', 'model.layers.20.self_attn.q_proj.qzeros_zeros', 'model.layers.20.self_attn.v_proj.g_idx', 'model.layers.20.self_attn.v_proj.qscales_scales', 'model.layers.20.self_attn.v_proj.qscales_zeros', 'model.layers.20.self_attn.v_proj.qstatistic', 'model.layers.20.self_attn.v_proj.qweight', 'model.layers.20.self_attn.v_proj.qzeros_scales', 'model.layers.20.self_attn.v_proj.qzeros_zeros', 'model.layers.21.mlp.down_proj.g_idx', 'model.layers.21.mlp.down_proj.qscales_scales', 'model.layers.21.mlp.down_proj.qscales_zeros', 'model.layers.21.mlp.down_proj.qstatistic', 'model.layers.21.mlp.down_proj.qweight', 'model.layers.21.mlp.down_proj.qzeros_scales', 'model.layers.21.mlp.down_proj.qzeros_zeros', 'model.layers.21.mlp.gate_proj.g_idx', 'model.layers.21.mlp.gate_proj.qscales_scales', 'model.layers.21.mlp.gate_proj.qscales_zeros', 'model.layers.21.mlp.gate_proj.qstatistic', 'model.layers.21.mlp.gate_proj.qweight', 'model.layers.21.mlp.gate_proj.qzeros_scales', 'model.layers.21.mlp.gate_proj.qzeros_zeros', 'model.layers.21.mlp.up_proj.g_idx', 'model.layers.21.mlp.up_proj.qscales_scales', 'model.layers.21.mlp.up_proj.qscales_zeros', 'model.layers.21.mlp.up_proj.qstatistic', 'model.layers.21.mlp.up_proj.qweight', 'model.layers.21.mlp.up_proj.qzeros_scales', 'model.layers.21.mlp.up_proj.qzeros_zeros', 'model.layers.21.self_attn.k_proj.g_idx', 'model.layers.21.self_attn.k_proj.qscales_scales', 'model.layers.21.self_attn.k_proj.qscales_zeros', 'model.layers.21.self_attn.k_proj.qstatistic', 'model.layers.21.self_attn.k_proj.qweight', 'model.layers.21.self_attn.k_proj.qzeros_scales', 'model.layers.21.self_attn.k_proj.qzeros_zeros', 'model.layers.21.self_attn.o_proj.g_idx', 'model.layers.21.self_attn.o_proj.qscales_scales', 'model.layers.21.self_attn.o_proj.qscales_zeros', 'model.layers.21.self_attn.o_proj.qstatistic', 'model.layers.21.self_attn.o_proj.qweight', 'model.layers.21.self_attn.o_proj.qzeros_scales', 'model.layers.21.self_attn.o_proj.qzeros_zeros', 'model.layers.21.self_attn.q_proj.g_idx', 'model.layers.21.self_attn.q_proj.qscales_scales', 'model.layers.21.self_attn.q_proj.qscales_zeros', 'model.layers.21.self_attn.q_proj.qstatistic', 'model.layers.21.self_attn.q_proj.qweight', 'model.layers.21.self_attn.q_proj.qzeros_scales', 'model.layers.21.self_attn.q_proj.qzeros_zeros', 'model.layers.21.self_attn.v_proj.g_idx', 'model.layers.21.self_attn.v_proj.qscales_scales', 'model.layers.21.self_attn.v_proj.qscales_zeros', 'model.layers.21.self_attn.v_proj.qstatistic', 'model.layers.21.self_attn.v_proj.qweight', 'model.layers.21.self_attn.v_proj.qzeros_scales', 'model.layers.21.self_attn.v_proj.qzeros_zeros', 'model.layers.22.mlp.down_proj.g_idx', 'model.layers.22.mlp.down_proj.qscales_scales', 'model.layers.22.mlp.down_proj.qscales_zeros', 'model.layers.22.mlp.down_proj.qstatistic', 'model.layers.22.mlp.down_proj.qweight', 'model.layers.22.mlp.down_proj.qzeros_scales', 'model.layers.22.mlp.down_proj.qzeros_zeros', 'model.layers.22.mlp.gate_proj.g_idx', 'model.layers.22.mlp.gate_proj.qscales_scales', 'model.layers.22.mlp.gate_proj.qscales_zeros', 'model.layers.22.mlp.gate_proj.qstatistic', 'model.layers.22.mlp.gate_proj.qweight', 'model.layers.22.mlp.gate_proj.qzeros_scales', 'model.layers.22.mlp.gate_proj.qzeros_zeros', 'model.layers.22.mlp.up_proj.g_idx', 'model.layers.22.mlp.up_proj.qscales_scales', 'model.layers.22.mlp.up_proj.qscales_zeros', 'model.layers.22.mlp.up_proj.qstatistic', 'model.layers.22.mlp.up_proj.qweight', 'model.layers.22.mlp.up_proj.qzeros_scales', 'model.layers.22.mlp.up_proj.qzeros_zeros', 'model.layers.22.self_attn.k_proj.g_idx', 'model.layers.22.self_attn.k_proj.qscales_scales', 'model.layers.22.self_attn.k_proj.qscales_zeros', 'model.layers.22.self_attn.k_proj.qstatistic', 'model.layers.22.self_attn.k_proj.qweight', 'model.layers.22.self_attn.k_proj.qzeros_scales', 'model.layers.22.self_attn.k_proj.qzeros_zeros', 'model.layers.22.self_attn.o_proj.g_idx', 'model.layers.22.self_attn.o_proj.qscales_scales', 'model.layers.22.self_attn.o_proj.qscales_zeros', 'model.layers.22.self_attn.o_proj.qstatistic', 'model.layers.22.self_attn.o_proj.qweight', 'model.layers.22.self_attn.o_proj.qzeros_scales', 'model.layers.22.self_attn.o_proj.qzeros_zeros', 'model.layers.22.self_attn.q_proj.g_idx', 'model.layers.22.self_attn.q_proj.qscales_scales', 'model.layers.22.self_attn.q_proj.qscales_zeros', 'model.layers.22.self_attn.q_proj.qstatistic', 'model.layers.22.self_attn.q_proj.qweight', 'model.layers.22.self_attn.q_proj.qzeros_scales', 'model.layers.22.self_attn.q_proj.qzeros_zeros', 'model.layers.22.self_attn.v_proj.g_idx', 'model.layers.22.self_attn.v_proj.qscales_scales', 'model.layers.22.self_attn.v_proj.qscales_zeros', 'model.layers.22.self_attn.v_proj.qstatistic', 'model.layers.22.self_attn.v_proj.qweight', 'model.layers.22.self_attn.v_proj.qzeros_scales', 'model.layers.22.self_attn.v_proj.qzeros_zeros', 'model.layers.23.mlp.down_proj.g_idx', 'model.layers.23.mlp.down_proj.qscales_scales', 'model.layers.23.mlp.down_proj.qscales_zeros', 'model.layers.23.mlp.down_proj.qstatistic', 'model.layers.23.mlp.down_proj.qweight', 'model.layers.23.mlp.down_proj.qzeros_scales', 'model.layers.23.mlp.down_proj.qzeros_zeros', 'model.layers.23.mlp.gate_proj.g_idx', 'model.layers.23.mlp.gate_proj.qscales_scales', 'model.layers.23.mlp.gate_proj.qscales_zeros', 'model.layers.23.mlp.gate_proj.qstatistic', 'model.layers.23.mlp.gate_proj.qweight', 'model.layers.23.mlp.gate_proj.qzeros_scales', 'model.layers.23.mlp.gate_proj.qzeros_zeros', 'model.layers.23.mlp.up_proj.g_idx', 'model.layers.23.mlp.up_proj.qscales_scales', 'model.layers.23.mlp.up_proj.qscales_zeros', 'model.layers.23.mlp.up_proj.qstatistic', 'model.layers.23.mlp.up_proj.qweight', 'model.layers.23.mlp.up_proj.qzeros_scales', 'model.layers.23.mlp.up_proj.qzeros_zeros', 'model.layers.23.self_attn.k_proj.g_idx', 'model.layers.23.self_attn.k_proj.qscales_scales', 'model.layers.23.self_attn.k_proj.qscales_zeros', 'model.layers.23.self_attn.k_proj.qstatistic', 'model.layers.23.self_attn.k_proj.qweight', 'model.layers.23.self_attn.k_proj.qzeros_scales', 'model.layers.23.self_attn.k_proj.qzeros_zeros', 'model.layers.23.self_attn.o_proj.g_idx', 'model.layers.23.self_attn.o_proj.qscales_scales', 'model.layers.23.self_attn.o_proj.qscales_zeros', 'model.layers.23.self_attn.o_proj.qstatistic', 'model.layers.23.self_attn.o_proj.qweight', 'model.layers.23.self_attn.o_proj.qzeros_scales', 'model.layers.23.self_attn.o_proj.qzeros_zeros', 'model.layers.23.self_attn.q_proj.g_idx', 'model.layers.23.self_attn.q_proj.qscales_scales', 'model.layers.23.self_attn.q_proj.qscales_zeros', 'model.layers.23.self_attn.q_proj.qstatistic', 'model.layers.23.self_attn.q_proj.qweight', 'model.layers.23.self_attn.q_proj.qzeros_scales', 'model.layers.23.self_attn.q_proj.qzeros_zeros', 'model.layers.23.self_attn.v_proj.g_idx', 'model.layers.23.self_attn.v_proj.qscales_scales', 'model.layers.23.self_attn.v_proj.qscales_zeros', 'model.layers.23.self_attn.v_proj.qstatistic', 'model.layers.23.self_attn.v_proj.qweight', 'model.layers.23.self_attn.v_proj.qzeros_scales', 'model.layers.23.self_attn.v_proj.qzeros_zeros', 'model.layers.24.mlp.down_proj.g_idx', 'model.layers.24.mlp.down_proj.qscales_scales', 'model.layers.24.mlp.down_proj.qscales_zeros', 'model.layers.24.mlp.down_proj.qstatistic', 'model.layers.24.mlp.down_proj.qweight', 'model.layers.24.mlp.down_proj.qzeros_scales', 'model.layers.24.mlp.down_proj.qzeros_zeros', 'model.layers.24.mlp.gate_proj.g_idx', 'model.layers.24.mlp.gate_proj.qscales_scales', 'model.layers.24.mlp.gate_proj.qscales_zeros', 'model.layers.24.mlp.gate_proj.qstatistic', 'model.layers.24.mlp.gate_proj.qweight', 'model.layers.24.mlp.gate_proj.qzeros_scales', 'model.layers.24.mlp.gate_proj.qzeros_zeros', 'model.layers.24.mlp.up_proj.g_idx', 'model.layers.24.mlp.up_proj.qscales_scales', 'model.layers.24.mlp.up_proj.qscales_zeros', 'model.layers.24.mlp.up_proj.qstatistic', 'model.layers.24.mlp.up_proj.qweight', 'model.layers.24.mlp.up_proj.qzeros_scales', 'model.layers.24.mlp.up_proj.qzeros_zeros', 'model.layers.24.self_attn.k_proj.g_idx', 'model.layers.24.self_attn.k_proj.qscales_scales', 'model.layers.24.self_attn.k_proj.qscales_zeros', 'model.layers.24.self_attn.k_proj.qstatistic', 'model.layers.24.self_attn.k_proj.qweight', 'model.layers.24.self_attn.k_proj.qzeros_scales', 'model.layers.24.self_attn.k_proj.qzeros_zeros', 'model.layers.24.self_attn.o_proj.g_idx', 'model.layers.24.self_attn.o_proj.qscales_scales', 'model.layers.24.self_attn.o_proj.qscales_zeros', 'model.layers.24.self_attn.o_proj.qstatistic', 'model.layers.24.self_attn.o_proj.qweight', 'model.layers.24.self_attn.o_proj.qzeros_scales', 'model.layers.24.self_attn.o_proj.qzeros_zeros', 'model.layers.24.self_attn.q_proj.g_idx', 'model.layers.24.self_attn.q_proj.qscales_scales', 'model.layers.24.self_attn.q_proj.qscales_zeros', 'model.layers.24.self_attn.q_proj.qstatistic', 'model.layers.24.self_attn.q_proj.qweight', 'model.layers.24.self_attn.q_proj.qzeros_scales', 'model.layers.24.self_attn.q_proj.qzeros_zeros', 'model.layers.24.self_attn.v_proj.g_idx', 'model.layers.24.self_attn.v_proj.qscales_scales', 'model.layers.24.self_attn.v_proj.qscales_zeros', 'model.layers.24.self_attn.v_proj.qstatistic', 'model.layers.24.self_attn.v_proj.qweight', 'model.layers.24.self_attn.v_proj.qzeros_scales', 'model.layers.24.self_attn.v_proj.qzeros_zeros', 'model.layers.25.mlp.down_proj.g_idx', 'model.layers.25.mlp.down_proj.qscales_scales', 'model.layers.25.mlp.down_proj.qscales_zeros', 'model.layers.25.mlp.down_proj.qstatistic', 'model.layers.25.mlp.down_proj.qweight', 'model.layers.25.mlp.down_proj.qzeros_scales', 'model.layers.25.mlp.down_proj.qzeros_zeros', 'model.layers.25.mlp.gate_proj.g_idx', 'model.layers.25.mlp.gate_proj.qscales_scales', 'model.layers.25.mlp.gate_proj.qscales_zeros', 'model.layers.25.mlp.gate_proj.qstatistic', 'model.layers.25.mlp.gate_proj.qweight', 'model.layers.25.mlp.gate_proj.qzeros_scales', 'model.layers.25.mlp.gate_proj.qzeros_zeros', 'model.layers.25.mlp.up_proj.g_idx', 'model.layers.25.mlp.up_proj.qscales_scales', 'model.layers.25.mlp.up_proj.qscales_zeros', 'model.layers.25.mlp.up_proj.qstatistic', 'model.layers.25.mlp.up_proj.qweight', 'model.layers.25.mlp.up_proj.qzeros_scales', 'model.layers.25.mlp.up_proj.qzeros_zeros', 'model.layers.25.self_attn.k_proj.g_idx', 'model.layers.25.self_attn.k_proj.qscales_scales', 'model.layers.25.self_attn.k_proj.qscales_zeros', 'model.layers.25.self_attn.k_proj.qstatistic', 'model.layers.25.self_attn.k_proj.qweight', 'model.layers.25.self_attn.k_proj.qzeros_scales', 'model.layers.25.self_attn.k_proj.qzeros_zeros', 'model.layers.25.self_attn.o_proj.g_idx', 'model.layers.25.self_attn.o_proj.qscales_scales', 'model.layers.25.self_attn.o_proj.qscales_zeros', 'model.layers.25.self_attn.o_proj.qstatistic', 'model.layers.25.self_attn.o_proj.qweight', 'model.layers.25.self_attn.o_proj.qzeros_scales', 'model.layers.25.self_attn.o_proj.qzeros_zeros', 'model.layers.25.self_attn.q_proj.g_idx', 'model.layers.25.self_attn.q_proj.qscales_scales', 'model.layers.25.self_attn.q_proj.qscales_zeros', 'model.layers.25.self_attn.q_proj.qstatistic', 'model.layers.25.self_attn.q_proj.qweight', 'model.layers.25.self_attn.q_proj.qzeros_scales', 'model.layers.25.self_attn.q_proj.qzeros_zeros', 'model.layers.25.self_attn.v_proj.g_idx', 'model.layers.25.self_attn.v_proj.qscales_scales', 'model.layers.25.self_attn.v_proj.qscales_zeros', 'model.layers.25.self_attn.v_proj.qstatistic', 'model.layers.25.self_attn.v_proj.qweight', 'model.layers.25.self_attn.v_proj.qzeros_scales', 'model.layers.25.self_attn.v_proj.qzeros_zeros', 'model.layers.26.mlp.down_proj.g_idx', 'model.layers.26.mlp.down_proj.qscales_scales', 'model.layers.26.mlp.down_proj.qscales_zeros', 'model.layers.26.mlp.down_proj.qstatistic', 'model.layers.26.mlp.down_proj.qweight', 'model.layers.26.mlp.down_proj.qzeros_scales', 'model.layers.26.mlp.down_proj.qzeros_zeros', 'model.layers.26.mlp.gate_proj.g_idx', 'model.layers.26.mlp.gate_proj.qscales_scales', 'model.layers.26.mlp.gate_proj.qscales_zeros', 'model.layers.26.mlp.gate_proj.qstatistic', 'model.layers.26.mlp.gate_proj.qweight', 'model.layers.26.mlp.gate_proj.qzeros_scales', 'model.layers.26.mlp.gate_proj.qzeros_zeros', 'model.layers.26.mlp.up_proj.g_idx', 'model.layers.26.mlp.up_proj.qscales_scales', 'model.layers.26.mlp.up_proj.qscales_zeros', 'model.layers.26.mlp.up_proj.qstatistic', 'model.layers.26.mlp.up_proj.qweight', 'model.layers.26.mlp.up_proj.qzeros_scales', 'model.layers.26.mlp.up_proj.qzeros_zeros', 'model.layers.26.self_attn.k_proj.g_idx', 'model.layers.26.self_attn.k_proj.qscales_scales', 'model.layers.26.self_attn.k_proj.qscales_zeros', 'model.layers.26.self_attn.k_proj.qstatistic', 'model.layers.26.self_attn.k_proj.qweight', 'model.layers.26.self_attn.k_proj.qzeros_scales', 'model.layers.26.self_attn.k_proj.qzeros_zeros', 'model.layers.26.self_attn.o_proj.g_idx', 'model.layers.26.self_attn.o_proj.qscales_scales', 'model.layers.26.self_attn.o_proj.qscales_zeros', 'model.layers.26.self_attn.o_proj.qstatistic', 'model.layers.26.self_attn.o_proj.qweight', 'model.layers.26.self_attn.o_proj.qzeros_scales', 'model.layers.26.self_attn.o_proj.qzeros_zeros', 'model.layers.26.self_attn.q_proj.g_idx', 'model.layers.26.self_attn.q_proj.qscales_scales', 'model.layers.26.self_attn.q_proj.qscales_zeros', 'model.layers.26.self_attn.q_proj.qstatistic', 'model.layers.26.self_attn.q_proj.qweight', 'model.layers.26.self_attn.q_proj.qzeros_scales', 'model.layers.26.self_attn.q_proj.qzeros_zeros', 'model.layers.26.self_attn.v_proj.g_idx', 'model.layers.26.self_attn.v_proj.qscales_scales', 'model.layers.26.self_attn.v_proj.qscales_zeros', 'model.layers.26.self_attn.v_proj.qstatistic', 'model.layers.26.self_attn.v_proj.qweight', 'model.layers.26.self_attn.v_proj.qzeros_scales', 'model.layers.26.self_attn.v_proj.qzeros_zeros', 'model.layers.27.mlp.down_proj.g_idx', 'model.layers.27.mlp.down_proj.qscales_scales', 'model.layers.27.mlp.down_proj.qscales_zeros', 'model.layers.27.mlp.down_proj.qstatistic', 'model.layers.27.mlp.down_proj.qweight', 'model.layers.27.mlp.down_proj.qzeros_scales', 'model.layers.27.mlp.down_proj.qzeros_zeros', 'model.layers.27.mlp.gate_proj.g_idx', 'model.layers.27.mlp.gate_proj.qscales_scales', 'model.layers.27.mlp.gate_proj.qscales_zeros', 'model.layers.27.mlp.gate_proj.qstatistic', 'model.layers.27.mlp.gate_proj.qweight', 'model.layers.27.mlp.gate_proj.qzeros_scales', 'model.layers.27.mlp.gate_proj.qzeros_zeros', 'model.layers.27.mlp.up_proj.g_idx', 'model.layers.27.mlp.up_proj.qscales_scales', 'model.layers.27.mlp.up_proj.qscales_zeros', 'model.layers.27.mlp.up_proj.qstatistic', 'model.layers.27.mlp.up_proj.qweight', 'model.layers.27.mlp.up_proj.qzeros_scales', 'model.layers.27.mlp.up_proj.qzeros_zeros', 'model.layers.27.self_attn.k_proj.g_idx', 'model.layers.27.self_attn.k_proj.qscales_scales', 'model.layers.27.self_attn.k_proj.qscales_zeros', 'model.layers.27.self_attn.k_proj.qstatistic', 'model.layers.27.self_attn.k_proj.qweight', 'model.layers.27.self_attn.k_proj.qzeros_scales', 'model.layers.27.self_attn.k_proj.qzeros_zeros', 'model.layers.27.self_attn.o_proj.g_idx', 'model.layers.27.self_attn.o_proj.qscales_scales', 'model.layers.27.self_attn.o_proj.qscales_zeros', 'model.layers.27.self_attn.o_proj.qstatistic', 'model.layers.27.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qzeros_scales', 'model.layers.27.self_attn.o_proj.qzeros_zeros', 'model.layers.27.self_attn.q_proj.g_idx', 'model.layers.27.self_attn.q_proj.qscales_scales', 'model.layers.27.self_attn.q_proj.qscales_zeros', 'model.layers.27.self_attn.q_proj.qstatistic', 'model.layers.27.self_attn.q_proj.qweight', 'model.layers.27.self_attn.q_proj.qzeros_scales', 'model.layers.27.self_attn.q_proj.qzeros_zeros', 'model.layers.27.self_attn.v_proj.g_idx', 'model.layers.27.self_attn.v_proj.qscales_scales', 'model.layers.27.self_attn.v_proj.qscales_zeros', 'model.layers.27.self_attn.v_proj.qstatistic', 'model.layers.27.self_attn.v_proj.qweight', 'model.layers.27.self_attn.v_proj.qzeros_scales', 'model.layers.27.self_attn.v_proj.qzeros_zeros', 'model.layers.28.mlp.down_proj.g_idx', 'model.layers.28.mlp.down_proj.qscales_scales', 'model.layers.28.mlp.down_proj.qscales_zeros', 'model.layers.28.mlp.down_proj.qstatistic', 'model.layers.28.mlp.down_proj.qweight', 'model.layers.28.mlp.down_proj.qzeros_scales', 'model.layers.28.mlp.down_proj.qzeros_zeros', 'model.layers.28.mlp.gate_proj.g_idx', 'model.layers.28.mlp.gate_proj.qscales_scales', 'model.layers.28.mlp.gate_proj.qscales_zeros', 'model.layers.28.mlp.gate_proj.qstatistic', 'model.layers.28.mlp.gate_proj.qweight', 'model.layers.28.mlp.gate_proj.qzeros_scales', 'model.layers.28.mlp.gate_proj.qzeros_zeros', 'model.layers.28.mlp.up_proj.g_idx', 'model.layers.28.mlp.up_proj.qscales_scales', 'model.layers.28.mlp.up_proj.qscales_zeros', 'model.layers.28.mlp.up_proj.qstatistic', 'model.layers.28.mlp.up_proj.qweight', 'model.layers.28.mlp.up_proj.qzeros_scales', 'model.layers.28.mlp.up_proj.qzeros_zeros', 'model.layers.28.self_attn.k_proj.g_idx', 'model.layers.28.self_attn.k_proj.qscales_scales', 'model.layers.28.self_attn.k_proj.qscales_zeros', 'model.layers.28.self_attn.k_proj.qstatistic', 'model.layers.28.self_attn.k_proj.qweight', 'model.layers.28.self_attn.k_proj.qzeros_scales', 'model.layers.28.self_attn.k_proj.qzeros_zeros', 'model.layers.28.self_attn.o_proj.g_idx', 'model.layers.28.self_attn.o_proj.qscales_scales', 'model.layers.28.self_attn.o_proj.qscales_zeros', 'model.layers.28.self_attn.o_proj.qstatistic', 'model.layers.28.self_attn.o_proj.qweight', 'model.layers.28.self_attn.o_proj.qzeros_scales', 'model.layers.28.self_attn.o_proj.qzeros_zeros', 'model.layers.28.self_attn.q_proj.g_idx', 'model.layers.28.self_attn.q_proj.qscales_scales', 'model.layers.28.self_attn.q_proj.qscales_zeros', 'model.layers.28.self_attn.q_proj.qstatistic', 'model.layers.28.self_attn.q_proj.qweight', 'model.layers.28.self_attn.q_proj.qzeros_scales', 'model.layers.28.self_attn.q_proj.qzeros_zeros', 'model.layers.28.self_attn.v_proj.g_idx', 'model.layers.28.self_attn.v_proj.qscales_scales', 'model.layers.28.self_attn.v_proj.qscales_zeros', 'model.layers.28.self_attn.v_proj.qstatistic', 'model.layers.28.self_attn.v_proj.qweight', 'model.layers.28.self_attn.v_proj.qzeros_scales', 'model.layers.28.self_attn.v_proj.qzeros_zeros', 'model.layers.29.mlp.down_proj.g_idx', 'model.layers.29.mlp.down_proj.qscales_scales', 'model.layers.29.mlp.down_proj.qscales_zeros', 'model.layers.29.mlp.down_proj.qstatistic', 'model.layers.29.mlp.down_proj.qweight', 'model.layers.29.mlp.down_proj.qzeros_scales', 'model.layers.29.mlp.down_proj.qzeros_zeros', 'model.layers.29.mlp.gate_proj.g_idx', 'model.layers.29.mlp.gate_proj.qscales_scales', 'model.layers.29.mlp.gate_proj.qscales_zeros', 'model.layers.29.mlp.gate_proj.qstatistic', 'model.layers.29.mlp.gate_proj.qweight', 'model.layers.29.mlp.gate_proj.qzeros_scales', 'model.layers.29.mlp.gate_proj.qzeros_zeros', 'model.layers.29.mlp.up_proj.g_idx', 'model.layers.29.mlp.up_proj.qscales_scales', 'model.layers.29.mlp.up_proj.qscales_zeros', 'model.layers.29.mlp.up_proj.qstatistic', 'model.layers.29.mlp.up_proj.qweight', 'model.layers.29.mlp.up_proj.qzeros_scales', 'model.layers.29.mlp.up_proj.qzeros_zeros', 'model.layers.29.self_attn.k_proj.g_idx', 'model.layers.29.self_attn.k_proj.qscales_scales', 'model.layers.29.self_attn.k_proj.qscales_zeros', 'model.layers.29.self_attn.k_proj.qstatistic', 'model.layers.29.self_attn.k_proj.qweight', 'model.layers.29.self_attn.k_proj.qzeros_scales', 'model.layers.29.self_attn.k_proj.qzeros_zeros', 'model.layers.29.self_attn.o_proj.g_idx', 'model.layers.29.self_attn.o_proj.qscales_scales', 'model.layers.29.self_attn.o_proj.qscales_zeros', 'model.layers.29.self_attn.o_proj.qstatistic', 'model.layers.29.self_attn.o_proj.qweight', 'model.layers.29.self_attn.o_proj.qzeros_scales', 'model.layers.29.self_attn.o_proj.qzeros_zeros', 'model.layers.29.self_attn.q_proj.g_idx', 'model.layers.29.self_attn.q_proj.qscales_scales', 'model.layers.29.self_attn.q_proj.qscales_zeros', 'model.layers.29.self_attn.q_proj.qstatistic', 'model.layers.29.self_attn.q_proj.qweight', 'model.layers.29.self_attn.q_proj.qzeros_scales', 'model.layers.29.self_attn.q_proj.qzeros_zeros', 'model.layers.29.self_attn.v_proj.g_idx', 'model.layers.29.self_attn.v_proj.qscales_scales', 'model.layers.29.self_attn.v_proj.qscales_zeros', 'model.layers.29.self_attn.v_proj.qstatistic', 'model.layers.29.self_attn.v_proj.qweight', 'model.layers.29.self_attn.v_proj.qzeros_scales', 'model.layers.29.self_attn.v_proj.qzeros_zeros', 'model.layers.3.mlp.down_proj.g_idx', 'model.layers.3.mlp.down_proj.qscales_scales', 'model.layers.3.mlp.down_proj.qscales_zeros', 'model.layers.3.mlp.down_proj.qstatistic', 'model.layers.3.mlp.down_proj.qweight', 'model.layers.3.mlp.down_proj.qzeros_scales', 'model.layers.3.mlp.down_proj.qzeros_zeros', 'model.layers.3.mlp.gate_proj.g_idx', 'model.layers.3.mlp.gate_proj.qscales_scales', 'model.layers.3.mlp.gate_proj.qscales_zeros', 'model.layers.3.mlp.gate_proj.qstatistic', 'model.layers.3.mlp.gate_proj.qweight', 'model.layers.3.mlp.gate_proj.qzeros_scales', 'model.layers.3.mlp.gate_proj.qzeros_zeros', 'model.layers.3.mlp.up_proj.g_idx', 'model.layers.3.mlp.up_proj.qscales_scales', 'model.layers.3.mlp.up_proj.qscales_zeros', 'model.layers.3.mlp.up_proj.qstatistic', 'model.layers.3.mlp.up_proj.qweight', 'model.layers.3.mlp.up_proj.qzeros_scales', 'model.layers.3.mlp.up_proj.qzeros_zeros', 'model.layers.3.self_attn.k_proj.g_idx', 'model.layers.3.self_attn.k_proj.qscales_scales', 'model.layers.3.self_attn.k_proj.qscales_zeros', 'model.layers.3.self_attn.k_proj.qstatistic', 'model.layers.3.self_attn.k_proj.qweight', 'model.layers.3.self_attn.k_proj.qzeros_scales', 'model.layers.3.self_attn.k_proj.qzeros_zeros', 'model.layers.3.self_attn.o_proj.g_idx', 'model.layers.3.self_attn.o_proj.qscales_scales', 'model.layers.3.self_attn.o_proj.qscales_zeros', 'model.layers.3.self_attn.o_proj.qstatistic', 'model.layers.3.self_attn.o_proj.qweight', 'model.layers.3.self_attn.o_proj.qzeros_scales', 'model.layers.3.self_attn.o_proj.qzeros_zeros', 'model.layers.3.self_attn.q_proj.g_idx', 'model.layers.3.self_attn.q_proj.qscales_scales', 'model.layers.3.self_attn.q_proj.qscales_zeros', 'model.layers.3.self_attn.q_proj.qstatistic', 'model.layers.3.self_attn.q_proj.qweight', 'model.layers.3.self_attn.q_proj.qzeros_scales', 'model.layers.3.self_attn.q_proj.qzeros_zeros', 'model.layers.3.self_attn.v_proj.g_idx', 'model.layers.3.self_attn.v_proj.qscales_scales', 'model.layers.3.self_attn.v_proj.qscales_zeros', 'model.layers.3.self_attn.v_proj.qstatistic', 'model.layers.3.self_attn.v_proj.qweight', 'model.layers.3.self_attn.v_proj.qzeros_scales', 'model.layers.3.self_attn.v_proj.qzeros_zeros', 'model.layers.30.mlp.down_proj.g_idx', 'model.layers.30.mlp.down_proj.qscales_scales', 'model.layers.30.mlp.down_proj.qscales_zeros', 'model.layers.30.mlp.down_proj.qstatistic', 'model.layers.30.mlp.down_proj.qweight', 'model.layers.30.mlp.down_proj.qzeros_scales', 'model.layers.30.mlp.down_proj.qzeros_zeros', 'model.layers.30.mlp.gate_proj.g_idx', 'model.layers.30.mlp.gate_proj.qscales_scales', 'model.layers.30.mlp.gate_proj.qscales_zeros', 'model.layers.30.mlp.gate_proj.qstatistic', 'model.layers.30.mlp.gate_proj.qweight', 'model.layers.30.mlp.gate_proj.qzeros_scales', 'model.layers.30.mlp.gate_proj.qzeros_zeros', 'model.layers.30.mlp.up_proj.g_idx', 'model.layers.30.mlp.up_proj.qscales_scales', 'model.layers.30.mlp.up_proj.qscales_zeros', 'model.layers.30.mlp.up_proj.qstatistic', 'model.layers.30.mlp.up_proj.qweight', 'model.layers.30.mlp.up_proj.qzeros_scales', 'model.layers.30.mlp.up_proj.qzeros_zeros', 'model.layers.30.self_attn.k_proj.g_idx', 'model.layers.30.self_attn.k_proj.qscales_scales', 'model.layers.30.self_attn.k_proj.qscales_zeros', 'model.layers.30.self_attn.k_proj.qstatistic', 'model.layers.30.self_attn.k_proj.qweight', 'model.layers.30.self_attn.k_proj.qzeros_scales', 'model.layers.30.self_attn.k_proj.qzeros_zeros', 'model.layers.30.self_attn.o_proj.g_idx', 'model.layers.30.self_attn.o_proj.qscales_scales', 'model.layers.30.self_attn.o_proj.qscales_zeros', 'model.layers.30.self_attn.o_proj.qstatistic', 'model.layers.30.self_attn.o_proj.qweight', 'model.layers.30.self_attn.o_proj.qzeros_scales', 'model.layers.30.self_attn.o_proj.qzeros_zeros', 'model.layers.30.self_attn.q_proj.g_idx', 'model.layers.30.self_attn.q_proj.qscales_scales', 'model.layers.30.self_attn.q_proj.qscales_zeros', 'model.layers.30.self_attn.q_proj.qstatistic', 'model.layers.30.self_attn.q_proj.qweight', 'model.layers.30.self_attn.q_proj.qzeros_scales', 'model.layers.30.self_attn.q_proj.qzeros_zeros', 'model.layers.30.self_attn.v_proj.g_idx', 'model.layers.30.self_attn.v_proj.qscales_scales', 'model.layers.30.self_attn.v_proj.qscales_zeros', 'model.layers.30.self_attn.v_proj.qstatistic', 'model.layers.30.self_attn.v_proj.qweight', 'model.layers.30.self_attn.v_proj.qzeros_scales', 'model.layers.30.self_attn.v_proj.qzeros_zeros', 'model.layers.31.mlp.down_proj.g_idx', 'model.layers.31.mlp.down_proj.qscales_scales', 'model.layers.31.mlp.down_proj.qscales_zeros', 'model.layers.31.mlp.down_proj.qstatistic', 'model.layers.31.mlp.down_proj.qweight', 'model.layers.31.mlp.down_proj.qzeros_scales', 'model.layers.31.mlp.down_proj.qzeros_zeros', 'model.layers.31.mlp.gate_proj.g_idx', 'model.layers.31.mlp.gate_proj.qscales_scales', 'model.layers.31.mlp.gate_proj.qscales_zeros', 'model.layers.31.mlp.gate_proj.qstatistic', 'model.layers.31.mlp.gate_proj.qweight', 'model.layers.31.mlp.gate_proj.qzeros_scales', 'model.layers.31.mlp.gate_proj.qzeros_zeros', 'model.layers.31.mlp.up_proj.g_idx', 'model.layers.31.mlp.up_proj.qscales_scales', 'model.layers.31.mlp.up_proj.qscales_zeros', 'model.layers.31.mlp.up_proj.qstatistic', 'model.layers.31.mlp.up_proj.qweight', 'model.layers.31.mlp.up_proj.qzeros_scales', 'model.layers.31.mlp.up_proj.qzeros_zeros', 'model.layers.31.self_attn.k_proj.g_idx', 'model.layers.31.self_attn.k_proj.qscales_scales', 'model.layers.31.self_attn.k_proj.qscales_zeros', 'model.layers.31.self_attn.k_proj.qstatistic', 'model.layers.31.self_attn.k_proj.qweight', 'model.layers.31.self_attn.k_proj.qzeros_scales', 'model.layers.31.self_attn.k_proj.qzeros_zeros', 'model.layers.31.self_attn.o_proj.g_idx', 'model.layers.31.self_attn.o_proj.qscales_scales', 'model.layers.31.self_attn.o_proj.qscales_zeros', 'model.layers.31.self_attn.o_proj.qstatistic', 'model.layers.31.self_attn.o_proj.qweight', 'model.layers.31.self_attn.o_proj.qzeros_scales', 'model.layers.31.self_attn.o_proj.qzeros_zeros', 'model.layers.31.self_attn.q_proj.g_idx', 'model.layers.31.self_attn.q_proj.qscales_scales', 'model.layers.31.self_attn.q_proj.qscales_zeros', 'model.layers.31.self_attn.q_proj.qstatistic', 'model.layers.31.self_attn.q_proj.qweight', 'model.layers.31.self_attn.q_proj.qzeros_scales', 'model.layers.31.self_attn.q_proj.qzeros_zeros', 'model.layers.31.self_attn.v_proj.g_idx', 'model.layers.31.self_attn.v_proj.qscales_scales', 'model.layers.31.self_attn.v_proj.qscales_zeros', 'model.layers.31.self_attn.v_proj.qstatistic', 'model.layers.31.self_attn.v_proj.qweight', 'model.layers.31.self_attn.v_proj.qzeros_scales', 'model.layers.31.self_attn.v_proj.qzeros_zeros', 'model.layers.4.mlp.down_proj.g_idx', 'model.layers.4.mlp.down_proj.qscales_scales', 'model.layers.4.mlp.down_proj.qscales_zeros', 'model.layers.4.mlp.down_proj.qstatistic', 'model.layers.4.mlp.down_proj.qweight', 'model.layers.4.mlp.down_proj.qzeros_scales', 'model.layers.4.mlp.down_proj.qzeros_zeros', 'model.layers.4.mlp.gate_proj.g_idx', 'model.layers.4.mlp.gate_proj.qscales_scales', 'model.layers.4.mlp.gate_proj.qscales_zeros', 'model.layers.4.mlp.gate_proj.qstatistic', 'model.layers.4.mlp.gate_proj.qweight', 'model.layers.4.mlp.gate_proj.qzeros_scales', 'model.layers.4.mlp.gate_proj.qzeros_zeros', 'model.layers.4.mlp.up_proj.g_idx', 'model.layers.4.mlp.up_proj.qscales_scales', 'model.layers.4.mlp.up_proj.qscales_zeros', 'model.layers.4.mlp.up_proj.qstatistic', 'model.layers.4.mlp.up_proj.qweight', 'model.layers.4.mlp.up_proj.qzeros_scales', 'model.layers.4.mlp.up_proj.qzeros_zeros', 'model.layers.4.self_attn.k_proj.g_idx', 'model.layers.4.self_attn.k_proj.qscales_scales', 'model.layers.4.self_attn.k_proj.qscales_zeros', 'model.layers.4.self_attn.k_proj.qstatistic', 'model.layers.4.self_attn.k_proj.qweight', 'model.layers.4.self_attn.k_proj.qzeros_scales', 'model.layers.4.self_attn.k_proj.qzeros_zeros', 'model.layers.4.self_attn.o_proj.g_idx', 'model.layers.4.self_attn.o_proj.qscales_scales', 'model.layers.4.self_attn.o_proj.qscales_zeros', 'model.layers.4.self_attn.o_proj.qstatistic', 'model.layers.4.self_attn.o_proj.qweight', 'model.layers.4.self_attn.o_proj.qzeros_scales', 'model.layers.4.self_attn.o_proj.qzeros_zeros', 'model.layers.4.self_attn.q_proj.g_idx', 'model.layers.4.self_attn.q_proj.qscales_scales', 'model.layers.4.self_attn.q_proj.qscales_zeros', 'model.layers.4.self_attn.q_proj.qstatistic', 'model.layers.4.self_attn.q_proj.qweight', 'model.layers.4.self_attn.q_proj.qzeros_scales', 'model.layers.4.self_attn.q_proj.qzeros_zeros', 'model.layers.4.self_attn.v_proj.g_idx', 'model.layers.4.self_attn.v_proj.qscales_scales', 'model.layers.4.self_attn.v_proj.qscales_zeros', 'model.layers.4.self_attn.v_proj.qstatistic', 'model.layers.4.self_attn.v_proj.qweight', 'model.layers.4.self_attn.v_proj.qzeros_scales', 'model.layers.4.self_attn.v_proj.qzeros_zeros', 'model.layers.5.mlp.down_proj.g_idx', 'model.layers.5.mlp.down_proj.qscales_scales', 'model.layers.5.mlp.down_proj.qscales_zeros', 'model.layers.5.mlp.down_proj.qstatistic', 'model.layers.5.mlp.down_proj.qweight', 'model.layers.5.mlp.down_proj.qzeros_scales', 'model.layers.5.mlp.down_proj.qzeros_zeros', 'model.layers.5.mlp.gate_proj.g_idx', 'model.layers.5.mlp.gate_proj.qscales_scales', 'model.layers.5.mlp.gate_proj.qscales_zeros', 'model.layers.5.mlp.gate_proj.qstatistic', 'model.layers.5.mlp.gate_proj.qweight', 'model.layers.5.mlp.gate_proj.qzeros_scales', 'model.layers.5.mlp.gate_proj.qzeros_zeros', 'model.layers.5.mlp.up_proj.g_idx', 'model.layers.5.mlp.up_proj.qscales_scales', 'model.layers.5.mlp.up_proj.qscales_zeros', 'model.layers.5.mlp.up_proj.qstatistic', 'model.layers.5.mlp.up_proj.qweight', 'model.layers.5.mlp.up_proj.qzeros_scales', 'model.layers.5.mlp.up_proj.qzeros_zeros', 'model.layers.5.self_attn.k_proj.g_idx', 'model.layers.5.self_attn.k_proj.qscales_scales', 'model.layers.5.self_attn.k_proj.qscales_zeros', 'model.layers.5.self_attn.k_proj.qstatistic', 'model.layers.5.self_attn.k_proj.qweight', 'model.layers.5.self_attn.k_proj.qzeros_scales', 'model.layers.5.self_attn.k_proj.qzeros_zeros', 'model.layers.5.self_attn.o_proj.g_idx', 'model.layers.5.self_attn.o_proj.qscales_scales', 'model.layers.5.self_attn.o_proj.qscales_zeros', 'model.layers.5.self_attn.o_proj.qstatistic', 'model.layers.5.self_attn.o_proj.qweight', 'model.layers.5.self_attn.o_proj.qzeros_scales', 'model.layers.5.self_attn.o_proj.qzeros_zeros', 'model.layers.5.self_attn.q_proj.g_idx', 'model.layers.5.self_attn.q_proj.qscales_scales', 'model.layers.5.self_attn.q_proj.qscales_zeros', 'model.layers.5.self_attn.q_proj.qstatistic', 'model.layers.5.self_attn.q_proj.qweight', 'model.layers.5.self_attn.q_proj.qzeros_scales', 'model.layers.5.self_attn.q_proj.qzeros_zeros', 'model.layers.5.self_attn.v_proj.g_idx', 'model.layers.5.self_attn.v_proj.qscales_scales', 'model.layers.5.self_attn.v_proj.qscales_zeros', 'model.layers.5.self_attn.v_proj.qstatistic', 'model.layers.5.self_attn.v_proj.qweight', 'model.layers.5.self_attn.v_proj.qzeros_scales', 'model.layers.5.self_attn.v_proj.qzeros_zeros', 'model.layers.6.mlp.down_proj.g_idx', 'model.layers.6.mlp.down_proj.qscales_scales', 'model.layers.6.mlp.down_proj.qscales_zeros', 'model.layers.6.mlp.down_proj.qstatistic', 'model.layers.6.mlp.down_proj.qweight', 'model.layers.6.mlp.down_proj.qzeros_scales', 'model.layers.6.mlp.down_proj.qzeros_zeros', 'model.layers.6.mlp.gate_proj.g_idx', 'model.layers.6.mlp.gate_proj.qscales_scales', 'model.layers.6.mlp.gate_proj.qscales_zeros', 'model.layers.6.mlp.gate_proj.qstatistic', 'model.layers.6.mlp.gate_proj.qweight', 'model.layers.6.mlp.gate_proj.qzeros_scales', 'model.layers.6.mlp.gate_proj.qzeros_zeros', 'model.layers.6.mlp.up_proj.g_idx', 'model.layers.6.mlp.up_proj.qscales_scales', 'model.layers.6.mlp.up_proj.qscales_zeros', 'model.layers.6.mlp.up_proj.qstatistic', 'model.layers.6.mlp.up_proj.qweight', 'model.layers.6.mlp.up_proj.qzeros_scales', 'model.layers.6.mlp.up_proj.qzeros_zeros', 'model.layers.6.self_attn.k_proj.g_idx', 'model.layers.6.self_attn.k_proj.qscales_scales', 'model.layers.6.self_attn.k_proj.qscales_zeros', 'model.layers.6.self_attn.k_proj.qstatistic', 'model.layers.6.self_attn.k_proj.qweight', 'model.layers.6.self_attn.k_proj.qzeros_scales', 'model.layers.6.self_attn.k_proj.qzeros_zeros', 'model.layers.6.self_attn.o_proj.g_idx', 'model.layers.6.self_attn.o_proj.qscales_scales', 'model.layers.6.self_attn.o_proj.qscales_zeros', 'model.layers.6.self_attn.o_proj.qstatistic', 'model.layers.6.self_attn.o_proj.qweight', 'model.layers.6.self_attn.o_proj.qzeros_scales', 'model.layers.6.self_attn.o_proj.qzeros_zeros', 'model.layers.6.self_attn.q_proj.g_idx', 'model.layers.6.self_attn.q_proj.qscales_scales', 'model.layers.6.self_attn.q_proj.qscales_zeros', 'model.layers.6.self_attn.q_proj.qstatistic', 'model.layers.6.self_attn.q_proj.qweight', 'model.layers.6.self_attn.q_proj.qzeros_scales', 'model.layers.6.self_attn.q_proj.qzeros_zeros', 'model.layers.6.self_attn.v_proj.g_idx', 'model.layers.6.self_attn.v_proj.qscales_scales', 'model.layers.6.self_attn.v_proj.qscales_zeros', 'model.layers.6.self_attn.v_proj.qstatistic', 'model.layers.6.self_attn.v_proj.qweight', 'model.layers.6.self_attn.v_proj.qzeros_scales', 'model.layers.6.self_attn.v_proj.qzeros_zeros', 'model.layers.7.mlp.down_proj.g_idx', 'model.layers.7.mlp.down_proj.qscales_scales', 'model.layers.7.mlp.down_proj.qscales_zeros', 'model.layers.7.mlp.down_proj.qstatistic', 'model.layers.7.mlp.down_proj.qweight', 'model.layers.7.mlp.down_proj.qzeros_scales', 'model.layers.7.mlp.down_proj.qzeros_zeros', 'model.layers.7.mlp.gate_proj.g_idx', 'model.layers.7.mlp.gate_proj.qscales_scales', 'model.layers.7.mlp.gate_proj.qscales_zeros', 'model.layers.7.mlp.gate_proj.qstatistic', 'model.layers.7.mlp.gate_proj.qweight', 'model.layers.7.mlp.gate_proj.qzeros_scales', 'model.layers.7.mlp.gate_proj.qzeros_zeros', 'model.layers.7.mlp.up_proj.g_idx', 'model.layers.7.mlp.up_proj.qscales_scales', 'model.layers.7.mlp.up_proj.qscales_zeros', 'model.layers.7.mlp.up_proj.qstatistic', 'model.layers.7.mlp.up_proj.qweight', 'model.layers.7.mlp.up_proj.qzeros_scales', 'model.layers.7.mlp.up_proj.qzeros_zeros', 'model.layers.7.self_attn.k_proj.g_idx', 'model.layers.7.self_attn.k_proj.qscales_scales', 'model.layers.7.self_attn.k_proj.qscales_zeros', 'model.layers.7.self_attn.k_proj.qstatistic', 'model.layers.7.self_attn.k_proj.qweight', 'model.layers.7.self_attn.k_proj.qzeros_scales', 'model.layers.7.self_attn.k_proj.qzeros_zeros', 'model.layers.7.self_attn.o_proj.g_idx', 'model.layers.7.self_attn.o_proj.qscales_scales', 'model.layers.7.self_attn.o_proj.qscales_zeros', 'model.layers.7.self_attn.o_proj.qstatistic', 'model.layers.7.self_attn.o_proj.qweight', 'model.layers.7.self_attn.o_proj.qzeros_scales', 'model.layers.7.self_attn.o_proj.qzeros_zeros', 'model.layers.7.self_attn.q_proj.g_idx', 'model.layers.7.self_attn.q_proj.qscales_scales', 'model.layers.7.self_attn.q_proj.qscales_zeros', 'model.layers.7.self_attn.q_proj.qstatistic', 'model.layers.7.self_attn.q_proj.qweight', 'model.layers.7.self_attn.q_proj.qzeros_scales', 'model.layers.7.self_attn.q_proj.qzeros_zeros', 'model.layers.7.self_attn.v_proj.g_idx', 'model.layers.7.self_attn.v_proj.qscales_scales', 'model.layers.7.self_attn.v_proj.qscales_zeros', 'model.layers.7.self_attn.v_proj.qstatistic', 'model.layers.7.self_attn.v_proj.qweight', 'model.layers.7.self_attn.v_proj.qzeros_scales', 'model.layers.7.self_attn.v_proj.qzeros_zeros', 'model.layers.8.mlp.down_proj.g_idx', 'model.layers.8.mlp.down_proj.qscales_scales', 'model.layers.8.mlp.down_proj.qscales_zeros', 'model.layers.8.mlp.down_proj.qstatistic', 'model.layers.8.mlp.down_proj.qweight', 'model.layers.8.mlp.down_proj.qzeros_scales', 'model.layers.8.mlp.down_proj.qzeros_zeros', 'model.layers.8.mlp.gate_proj.g_idx', 'model.layers.8.mlp.gate_proj.qscales_scales', 'model.layers.8.mlp.gate_proj.qscales_zeros', 'model.layers.8.mlp.gate_proj.qstatistic', 'model.layers.8.mlp.gate_proj.qweight', 'model.layers.8.mlp.gate_proj.qzeros_scales', 'model.layers.8.mlp.gate_proj.qzeros_zeros', 'model.layers.8.mlp.up_proj.g_idx', 'model.layers.8.mlp.up_proj.qscales_scales', 'model.layers.8.mlp.up_proj.qscales_zeros', 'model.layers.8.mlp.up_proj.qstatistic', 'model.layers.8.mlp.up_proj.qweight', 'model.layers.8.mlp.up_proj.qzeros_scales', 'model.layers.8.mlp.up_proj.qzeros_zeros', 'model.layers.8.self_attn.k_proj.g_idx', 'model.layers.8.self_attn.k_proj.qscales_scales', 'model.layers.8.self_attn.k_proj.qscales_zeros', 'model.layers.8.self_attn.k_proj.qstatistic', 'model.layers.8.self_attn.k_proj.qweight', 'model.layers.8.self_attn.k_proj.qzeros_scales', 'model.layers.8.self_attn.k_proj.qzeros_zeros', 'model.layers.8.self_attn.o_proj.g_idx', 'model.layers.8.self_attn.o_proj.qscales_scales', 'model.layers.8.self_attn.o_proj.qscales_zeros', 'model.layers.8.self_attn.o_proj.qstatistic', 'model.layers.8.self_attn.o_proj.qweight', 'model.layers.8.self_attn.o_proj.qzeros_scales', 'model.layers.8.self_attn.o_proj.qzeros_zeros', 'model.layers.8.self_attn.q_proj.g_idx', 'model.layers.8.self_attn.q_proj.qscales_scales', 'model.layers.8.self_attn.q_proj.qscales_zeros', 'model.layers.8.self_attn.q_proj.qstatistic', 'model.layers.8.self_attn.q_proj.qweight', 'model.layers.8.self_attn.q_proj.qzeros_scales', 'model.layers.8.self_attn.q_proj.qzeros_zeros', 'model.layers.8.self_attn.v_proj.g_idx', 'model.layers.8.self_attn.v_proj.qscales_scales', 'model.layers.8.self_attn.v_proj.qscales_zeros', 'model.layers.8.self_attn.v_proj.qstatistic', 'model.layers.8.self_attn.v_proj.qweight', 'model.layers.8.self_attn.v_proj.qzeros_scales', 'model.layers.8.self_attn.v_proj.qzeros_zeros', 'model.layers.9.mlp.down_proj.g_idx', 'model.layers.9.mlp.down_proj.qscales_scales', 'model.layers.9.mlp.down_proj.qscales_zeros', 'model.layers.9.mlp.down_proj.qstatistic', 'model.layers.9.mlp.down_proj.qweight', 'model.layers.9.mlp.down_proj.qzeros_scales', 'model.layers.9.mlp.down_proj.qzeros_zeros', 'model.layers.9.mlp.gate_proj.g_idx', 'model.layers.9.mlp.gate_proj.qscales_scales', 'model.layers.9.mlp.gate_proj.qscales_zeros', 'model.layers.9.mlp.gate_proj.qstatistic', 'model.layers.9.mlp.gate_proj.qweight', 'model.layers.9.mlp.gate_proj.qzeros_scales', 'model.layers.9.mlp.gate_proj.qzeros_zeros', 'model.layers.9.mlp.up_proj.g_idx', 'model.layers.9.mlp.up_proj.qscales_scales', 'model.layers.9.mlp.up_proj.qscales_zeros', 'model.layers.9.mlp.up_proj.qstatistic', 'model.layers.9.mlp.up_proj.qweight', 'model.layers.9.mlp.up_proj.qzeros_scales', 'model.layers.9.mlp.up_proj.qzeros_zeros', 'model.layers.9.self_attn.k_proj.g_idx', 'model.layers.9.self_attn.k_proj.qscales_scales', 'model.layers.9.self_attn.k_proj.qscales_zeros', 'model.layers.9.self_attn.k_proj.qstatistic', 'model.layers.9.self_attn.k_proj.qweight', 'model.layers.9.self_attn.k_proj.qzeros_scales', 'model.layers.9.self_attn.k_proj.qzeros_zeros', 'model.layers.9.self_attn.o_proj.g_idx', 'model.layers.9.self_attn.o_proj.qscales_scales', 'model.layers.9.self_attn.o_proj.qscales_zeros', 'model.layers.9.self_attn.o_proj.qstatistic', 'model.layers.9.self_attn.o_proj.qweight', 'model.layers.9.self_attn.o_proj.qzeros_scales', 'model.layers.9.self_attn.o_proj.qzeros_zeros', 'model.layers.9.self_attn.q_proj.g_idx', 'model.layers.9.self_attn.q_proj.qscales_scales', 'model.layers.9.self_attn.q_proj.qscales_zeros', 'model.layers.9.self_attn.q_proj.qstatistic', 'model.layers.9.self_attn.q_proj.qweight', 'model.layers.9.self_attn.q_proj.qzeros_scales', 'model.layers.9.self_attn.q_proj.qzeros_zeros', 'model.layers.9.self_attn.v_proj.g_idx', 'model.layers.9.self_attn.v_proj.qscales_scales', 'model.layers.9.self_attn.v_proj.qscales_zeros', 'model.layers.9.self_attn.v_proj.qstatistic', 'model.layers.9.self_attn.v_proj.qweight', 'model.layers.9.self_attn.v_proj.qzeros_scales', 'model.layers.9.self_attn.v_proj.qzeros_zeros']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: من هو أينشتاين؟\n",
            "Assistant:</img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img></img>POSE</img></img></img></img></img></img>POSE</img></img></img></img></img></img></img></img></img>POSE</img></img></img></img></img>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP40gL4NFRjY",
        "outputId": "5a17e714-24b8-4aa3-cac4-6e8f2877071c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 00:43:28.288137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741913008.626753   20532 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741913008.721660   20532 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741913009.421098   20532 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913009.421149   20532 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913009.421153   20532 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913009.421157   20532 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1536: UserWarning: Current model requires 1029047968 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 41, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer, config = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=bits, half=True, v1=v1, asym=asym, kquant=kquant, return_config=return_config)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 168, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel = accelerate.load_checkpoint_and_dispatch(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/big_modeling.py\", line 627, in load_checkpoint_and_dispatch\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn dispatch_model(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/big_modeling.py\", line 422, in dispatch_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook_on_blocks(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 664, in attach_align_device_hook_on_blocks\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook_on_blocks(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 664, in attach_align_device_hook_on_blocks\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook_on_blocks(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 664, in attach_align_device_hook_on_blocks\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook_on_blocks(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 627, in attach_align_device_hook_on_blocks\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 518, in attach_align_device_hook\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 518, in attach_align_device_hook\n",
            "\u001b[0m\u001b[0m    \u001b[0mattach_align_device_hook(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 509, in attach_align_device_hook\n",
            "\u001b[0m\u001b[0m    \u001b[0madd_hook_to_module(module, hook, append=True)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 161, in add_hook_to_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodule = hook.init_hook(module)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 312, in init_hook\n",
            "\u001b[0m\u001b[0m    \u001b[0mset_module_tensor_to_device(\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py\", line 322, in set_module_tensor_to_device\n",
            "\u001b[0m\u001b[0m    \u001b[0mnew_value = old_value.to(device)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0mtorch\u001b[0m.\u001b[0mOutOfMemoryError\u001b[0m: \u001b[0mCUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 18.12 MiB is free. Process 204744 has 11.45 GiB memory in use. Process 221798 has 3.28 GiB memory in use. Of the allocated memory 3.10 GiB is allocated by PyTorch, and 61.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZyDZBRXHY_o",
        "outputId": "b8a9c533-71fa-4fb3-8f34-388f28a4a527"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 00:46:28.225604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741913188.261170   21354 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741913188.271974   21354 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741913188.297959   21354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913188.298019   21354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913188.298031   21354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913188.298039   21354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-14 00:46:28.305455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 7.27 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mstart harness evaluation\u001b[0m\n",
            "\u001b[0mSelected Tasks: ['piqa', 'anli_r3', 'hellaswag', 'wic', 'record', 'openbookqa', 'arc_challenge', 'rte', 'race', 'arc_easy', 'anli_r1', 'anli_r2', 'winogrande', 'boolq', 'truthfulqa_mc']\u001b[0m\n",
            "\u001b[0mThe repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] \u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 55, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mt_results = evaluator.simple_evaluate(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/utils.py\", line 160, in _wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/evaluator.py\", line 66, in simple_evaluate\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_dict = lm_eval.tasks.get_task_dict(task_names)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 342, in get_task_dict\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name_dict = {\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/tasks/__init__.py\", line 343, in <dictcomp>\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_name: get_task(task_name)()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 412, in __init__\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.download(data_dir, cache_dir, download_mode)\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/base.py\", line 441, in download\n",
            "\u001b[0m\u001b[0m    \u001b[0mself.dataset = datasets.load_dataset(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2129, in load_dataset\n",
            "\u001b[0m\u001b[0m    \u001b[0mbuilder_instance = load_dataset_builder(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1849, in load_dataset_builder\n",
            "\u001b[0m\u001b[0m    \u001b[0mdataset_module = dataset_module_factory(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1731, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise e1 from None\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1681, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0m).get_module()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1331, in get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mtrust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise ValueError(\u001b[0m\n",
            "\u001b[0m\u001b[0mValueError\u001b[0m: \u001b[0mThe repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"GreenBitAI/yi-6b-w4a16g32\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6kNfB9DIB1Y",
        "outputId": "4e959277-d0f6-4d84-aaeb-9a5722628b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# اسم النموذج\n",
        "model_name = \"GreenBitAI/yi-6b-w4a16g32\"\n",
        "\n",
        "# تحميل النموذج والمُحلل اللغوي\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# إدخال نص للاختبار\n",
        "input_text = \"ما هو الذكاء الاصطناعي؟\"\n",
        "\n",
        "# ترميز النص\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# توليد النص\n",
        "with torch.no_grad():\n",
        "    output_ids = model.generate(input_ids, max_new_tokens=20, temperature=0.7, top_k=50, top_p=0.9)\n",
        "\n",
        "# فك ترميز الإخراج\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# طباعة النص الناتج\n",
        "print(\"🔹 الإخراج:\\n\", output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "Y1DiVOC2IKCv",
        "outputId": "d087acf5-b59b-4823-f9b0-240cea9a30ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at GreenBitAI/yi-6b-w4a16g32 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.g_idx', 'model.layers.0.mlp.down_proj.qscales_scales', 'model.layers.0.mlp.down_proj.qscales_zeros', 'model.layers.0.mlp.down_proj.qstatistic', 'model.layers.0.mlp.down_proj.qweight', 'model.layers.0.mlp.down_proj.qzeros_scales', 'model.layers.0.mlp.down_proj.qzeros_zeros', 'model.layers.0.mlp.gate_proj.g_idx', 'model.layers.0.mlp.gate_proj.qscales_scales', 'model.layers.0.mlp.gate_proj.qscales_zeros', 'model.layers.0.mlp.gate_proj.qstatistic', 'model.layers.0.mlp.gate_proj.qweight', 'model.layers.0.mlp.gate_proj.qzeros_scales', 'model.layers.0.mlp.gate_proj.qzeros_zeros', 'model.layers.0.mlp.up_proj.g_idx', 'model.layers.0.mlp.up_proj.qscales_scales', 'model.layers.0.mlp.up_proj.qscales_zeros', 'model.layers.0.mlp.up_proj.qstatistic', 'model.layers.0.mlp.up_proj.qweight', 'model.layers.0.mlp.up_proj.qzeros_scales', 'model.layers.0.mlp.up_proj.qzeros_zeros', 'model.layers.0.self_attn.k_proj.g_idx', 'model.layers.0.self_attn.k_proj.qscales_scales', 'model.layers.0.self_attn.k_proj.qscales_zeros', 'model.layers.0.self_attn.k_proj.qstatistic', 'model.layers.0.self_attn.k_proj.qweight', 'model.layers.0.self_attn.k_proj.qzeros_scales', 'model.layers.0.self_attn.k_proj.qzeros_zeros', 'model.layers.0.self_attn.o_proj.g_idx', 'model.layers.0.self_attn.o_proj.qscales_scales', 'model.layers.0.self_attn.o_proj.qscales_zeros', 'model.layers.0.self_attn.o_proj.qstatistic', 'model.layers.0.self_attn.o_proj.qweight', 'model.layers.0.self_attn.o_proj.qzeros_scales', 'model.layers.0.self_attn.o_proj.qzeros_zeros', 'model.layers.0.self_attn.q_proj.g_idx', 'model.layers.0.self_attn.q_proj.qscales_scales', 'model.layers.0.self_attn.q_proj.qscales_zeros', 'model.layers.0.self_attn.q_proj.qstatistic', 'model.layers.0.self_attn.q_proj.qweight', 'model.layers.0.self_attn.q_proj.qzeros_scales', 'model.layers.0.self_attn.q_proj.qzeros_zeros', 'model.layers.0.self_attn.v_proj.g_idx', 'model.layers.0.self_attn.v_proj.qscales_scales', 'model.layers.0.self_attn.v_proj.qscales_zeros', 'model.layers.0.self_attn.v_proj.qstatistic', 'model.layers.0.self_attn.v_proj.qweight', 'model.layers.0.self_attn.v_proj.qzeros_scales', 'model.layers.0.self_attn.v_proj.qzeros_zeros', 'model.layers.1.mlp.down_proj.g_idx', 'model.layers.1.mlp.down_proj.qscales_scales', 'model.layers.1.mlp.down_proj.qscales_zeros', 'model.layers.1.mlp.down_proj.qstatistic', 'model.layers.1.mlp.down_proj.qweight', 'model.layers.1.mlp.down_proj.qzeros_scales', 'model.layers.1.mlp.down_proj.qzeros_zeros', 'model.layers.1.mlp.gate_proj.g_idx', 'model.layers.1.mlp.gate_proj.qscales_scales', 'model.layers.1.mlp.gate_proj.qscales_zeros', 'model.layers.1.mlp.gate_proj.qstatistic', 'model.layers.1.mlp.gate_proj.qweight', 'model.layers.1.mlp.gate_proj.qzeros_scales', 'model.layers.1.mlp.gate_proj.qzeros_zeros', 'model.layers.1.mlp.up_proj.g_idx', 'model.layers.1.mlp.up_proj.qscales_scales', 'model.layers.1.mlp.up_proj.qscales_zeros', 'model.layers.1.mlp.up_proj.qstatistic', 'model.layers.1.mlp.up_proj.qweight', 'model.layers.1.mlp.up_proj.qzeros_scales', 'model.layers.1.mlp.up_proj.qzeros_zeros', 'model.layers.1.self_attn.k_proj.g_idx', 'model.layers.1.self_attn.k_proj.qscales_scales', 'model.layers.1.self_attn.k_proj.qscales_zeros', 'model.layers.1.self_attn.k_proj.qstatistic', 'model.layers.1.self_attn.k_proj.qweight', 'model.layers.1.self_attn.k_proj.qzeros_scales', 'model.layers.1.self_attn.k_proj.qzeros_zeros', 'model.layers.1.self_attn.o_proj.g_idx', 'model.layers.1.self_attn.o_proj.qscales_scales', 'model.layers.1.self_attn.o_proj.qscales_zeros', 'model.layers.1.self_attn.o_proj.qstatistic', 'model.layers.1.self_attn.o_proj.qweight', 'model.layers.1.self_attn.o_proj.qzeros_scales', 'model.layers.1.self_attn.o_proj.qzeros_zeros', 'model.layers.1.self_attn.q_proj.g_idx', 'model.layers.1.self_attn.q_proj.qscales_scales', 'model.layers.1.self_attn.q_proj.qscales_zeros', 'model.layers.1.self_attn.q_proj.qstatistic', 'model.layers.1.self_attn.q_proj.qweight', 'model.layers.1.self_attn.q_proj.qzeros_scales', 'model.layers.1.self_attn.q_proj.qzeros_zeros', 'model.layers.1.self_attn.v_proj.g_idx', 'model.layers.1.self_attn.v_proj.qscales_scales', 'model.layers.1.self_attn.v_proj.qscales_zeros', 'model.layers.1.self_attn.v_proj.qstatistic', 'model.layers.1.self_attn.v_proj.qweight', 'model.layers.1.self_attn.v_proj.qzeros_scales', 'model.layers.1.self_attn.v_proj.qzeros_zeros', 'model.layers.10.mlp.down_proj.g_idx', 'model.layers.10.mlp.down_proj.qscales_scales', 'model.layers.10.mlp.down_proj.qscales_zeros', 'model.layers.10.mlp.down_proj.qstatistic', 'model.layers.10.mlp.down_proj.qweight', 'model.layers.10.mlp.down_proj.qzeros_scales', 'model.layers.10.mlp.down_proj.qzeros_zeros', 'model.layers.10.mlp.gate_proj.g_idx', 'model.layers.10.mlp.gate_proj.qscales_scales', 'model.layers.10.mlp.gate_proj.qscales_zeros', 'model.layers.10.mlp.gate_proj.qstatistic', 'model.layers.10.mlp.gate_proj.qweight', 'model.layers.10.mlp.gate_proj.qzeros_scales', 'model.layers.10.mlp.gate_proj.qzeros_zeros', 'model.layers.10.mlp.up_proj.g_idx', 'model.layers.10.mlp.up_proj.qscales_scales', 'model.layers.10.mlp.up_proj.qscales_zeros', 'model.layers.10.mlp.up_proj.qstatistic', 'model.layers.10.mlp.up_proj.qweight', 'model.layers.10.mlp.up_proj.qzeros_scales', 'model.layers.10.mlp.up_proj.qzeros_zeros', 'model.layers.10.self_attn.k_proj.g_idx', 'model.layers.10.self_attn.k_proj.qscales_scales', 'model.layers.10.self_attn.k_proj.qscales_zeros', 'model.layers.10.self_attn.k_proj.qstatistic', 'model.layers.10.self_attn.k_proj.qweight', 'model.layers.10.self_attn.k_proj.qzeros_scales', 'model.layers.10.self_attn.k_proj.qzeros_zeros', 'model.layers.10.self_attn.o_proj.g_idx', 'model.layers.10.self_attn.o_proj.qscales_scales', 'model.layers.10.self_attn.o_proj.qscales_zeros', 'model.layers.10.self_attn.o_proj.qstatistic', 'model.layers.10.self_attn.o_proj.qweight', 'model.layers.10.self_attn.o_proj.qzeros_scales', 'model.layers.10.self_attn.o_proj.qzeros_zeros', 'model.layers.10.self_attn.q_proj.g_idx', 'model.layers.10.self_attn.q_proj.qscales_scales', 'model.layers.10.self_attn.q_proj.qscales_zeros', 'model.layers.10.self_attn.q_proj.qstatistic', 'model.layers.10.self_attn.q_proj.qweight', 'model.layers.10.self_attn.q_proj.qzeros_scales', 'model.layers.10.self_attn.q_proj.qzeros_zeros', 'model.layers.10.self_attn.v_proj.g_idx', 'model.layers.10.self_attn.v_proj.qscales_scales', 'model.layers.10.self_attn.v_proj.qscales_zeros', 'model.layers.10.self_attn.v_proj.qstatistic', 'model.layers.10.self_attn.v_proj.qweight', 'model.layers.10.self_attn.v_proj.qzeros_scales', 'model.layers.10.self_attn.v_proj.qzeros_zeros', 'model.layers.11.mlp.down_proj.g_idx', 'model.layers.11.mlp.down_proj.qscales_scales', 'model.layers.11.mlp.down_proj.qscales_zeros', 'model.layers.11.mlp.down_proj.qstatistic', 'model.layers.11.mlp.down_proj.qweight', 'model.layers.11.mlp.down_proj.qzeros_scales', 'model.layers.11.mlp.down_proj.qzeros_zeros', 'model.layers.11.mlp.gate_proj.g_idx', 'model.layers.11.mlp.gate_proj.qscales_scales', 'model.layers.11.mlp.gate_proj.qscales_zeros', 'model.layers.11.mlp.gate_proj.qstatistic', 'model.layers.11.mlp.gate_proj.qweight', 'model.layers.11.mlp.gate_proj.qzeros_scales', 'model.layers.11.mlp.gate_proj.qzeros_zeros', 'model.layers.11.mlp.up_proj.g_idx', 'model.layers.11.mlp.up_proj.qscales_scales', 'model.layers.11.mlp.up_proj.qscales_zeros', 'model.layers.11.mlp.up_proj.qstatistic', 'model.layers.11.mlp.up_proj.qweight', 'model.layers.11.mlp.up_proj.qzeros_scales', 'model.layers.11.mlp.up_proj.qzeros_zeros', 'model.layers.11.self_attn.k_proj.g_idx', 'model.layers.11.self_attn.k_proj.qscales_scales', 'model.layers.11.self_attn.k_proj.qscales_zeros', 'model.layers.11.self_attn.k_proj.qstatistic', 'model.layers.11.self_attn.k_proj.qweight', 'model.layers.11.self_attn.k_proj.qzeros_scales', 'model.layers.11.self_attn.k_proj.qzeros_zeros', 'model.layers.11.self_attn.o_proj.g_idx', 'model.layers.11.self_attn.o_proj.qscales_scales', 'model.layers.11.self_attn.o_proj.qscales_zeros', 'model.layers.11.self_attn.o_proj.qstatistic', 'model.layers.11.self_attn.o_proj.qweight', 'model.layers.11.self_attn.o_proj.qzeros_scales', 'model.layers.11.self_attn.o_proj.qzeros_zeros', 'model.layers.11.self_attn.q_proj.g_idx', 'model.layers.11.self_attn.q_proj.qscales_scales', 'model.layers.11.self_attn.q_proj.qscales_zeros', 'model.layers.11.self_attn.q_proj.qstatistic', 'model.layers.11.self_attn.q_proj.qweight', 'model.layers.11.self_attn.q_proj.qzeros_scales', 'model.layers.11.self_attn.q_proj.qzeros_zeros', 'model.layers.11.self_attn.v_proj.g_idx', 'model.layers.11.self_attn.v_proj.qscales_scales', 'model.layers.11.self_attn.v_proj.qscales_zeros', 'model.layers.11.self_attn.v_proj.qstatistic', 'model.layers.11.self_attn.v_proj.qweight', 'model.layers.11.self_attn.v_proj.qzeros_scales', 'model.layers.11.self_attn.v_proj.qzeros_zeros', 'model.layers.12.mlp.down_proj.g_idx', 'model.layers.12.mlp.down_proj.qscales_scales', 'model.layers.12.mlp.down_proj.qscales_zeros', 'model.layers.12.mlp.down_proj.qstatistic', 'model.layers.12.mlp.down_proj.qweight', 'model.layers.12.mlp.down_proj.qzeros_scales', 'model.layers.12.mlp.down_proj.qzeros_zeros', 'model.layers.12.mlp.gate_proj.g_idx', 'model.layers.12.mlp.gate_proj.qscales_scales', 'model.layers.12.mlp.gate_proj.qscales_zeros', 'model.layers.12.mlp.gate_proj.qstatistic', 'model.layers.12.mlp.gate_proj.qweight', 'model.layers.12.mlp.gate_proj.qzeros_scales', 'model.layers.12.mlp.gate_proj.qzeros_zeros', 'model.layers.12.mlp.up_proj.g_idx', 'model.layers.12.mlp.up_proj.qscales_scales', 'model.layers.12.mlp.up_proj.qscales_zeros', 'model.layers.12.mlp.up_proj.qstatistic', 'model.layers.12.mlp.up_proj.qweight', 'model.layers.12.mlp.up_proj.qzeros_scales', 'model.layers.12.mlp.up_proj.qzeros_zeros', 'model.layers.12.self_attn.k_proj.g_idx', 'model.layers.12.self_attn.k_proj.qscales_scales', 'model.layers.12.self_attn.k_proj.qscales_zeros', 'model.layers.12.self_attn.k_proj.qstatistic', 'model.layers.12.self_attn.k_proj.qweight', 'model.layers.12.self_attn.k_proj.qzeros_scales', 'model.layers.12.self_attn.k_proj.qzeros_zeros', 'model.layers.12.self_attn.o_proj.g_idx', 'model.layers.12.self_attn.o_proj.qscales_scales', 'model.layers.12.self_attn.o_proj.qscales_zeros', 'model.layers.12.self_attn.o_proj.qstatistic', 'model.layers.12.self_attn.o_proj.qweight', 'model.layers.12.self_attn.o_proj.qzeros_scales', 'model.layers.12.self_attn.o_proj.qzeros_zeros', 'model.layers.12.self_attn.q_proj.g_idx', 'model.layers.12.self_attn.q_proj.qscales_scales', 'model.layers.12.self_attn.q_proj.qscales_zeros', 'model.layers.12.self_attn.q_proj.qstatistic', 'model.layers.12.self_attn.q_proj.qweight', 'model.layers.12.self_attn.q_proj.qzeros_scales', 'model.layers.12.self_attn.q_proj.qzeros_zeros', 'model.layers.12.self_attn.v_proj.g_idx', 'model.layers.12.self_attn.v_proj.qscales_scales', 'model.layers.12.self_attn.v_proj.qscales_zeros', 'model.layers.12.self_attn.v_proj.qstatistic', 'model.layers.12.self_attn.v_proj.qweight', 'model.layers.12.self_attn.v_proj.qzeros_scales', 'model.layers.12.self_attn.v_proj.qzeros_zeros', 'model.layers.13.mlp.down_proj.g_idx', 'model.layers.13.mlp.down_proj.qscales_scales', 'model.layers.13.mlp.down_proj.qscales_zeros', 'model.layers.13.mlp.down_proj.qstatistic', 'model.layers.13.mlp.down_proj.qweight', 'model.layers.13.mlp.down_proj.qzeros_scales', 'model.layers.13.mlp.down_proj.qzeros_zeros', 'model.layers.13.mlp.gate_proj.g_idx', 'model.layers.13.mlp.gate_proj.qscales_scales', 'model.layers.13.mlp.gate_proj.qscales_zeros', 'model.layers.13.mlp.gate_proj.qstatistic', 'model.layers.13.mlp.gate_proj.qweight', 'model.layers.13.mlp.gate_proj.qzeros_scales', 'model.layers.13.mlp.gate_proj.qzeros_zeros', 'model.layers.13.mlp.up_proj.g_idx', 'model.layers.13.mlp.up_proj.qscales_scales', 'model.layers.13.mlp.up_proj.qscales_zeros', 'model.layers.13.mlp.up_proj.qstatistic', 'model.layers.13.mlp.up_proj.qweight', 'model.layers.13.mlp.up_proj.qzeros_scales', 'model.layers.13.mlp.up_proj.qzeros_zeros', 'model.layers.13.self_attn.k_proj.g_idx', 'model.layers.13.self_attn.k_proj.qscales_scales', 'model.layers.13.self_attn.k_proj.qscales_zeros', 'model.layers.13.self_attn.k_proj.qstatistic', 'model.layers.13.self_attn.k_proj.qweight', 'model.layers.13.self_attn.k_proj.qzeros_scales', 'model.layers.13.self_attn.k_proj.qzeros_zeros', 'model.layers.13.self_attn.o_proj.g_idx', 'model.layers.13.self_attn.o_proj.qscales_scales', 'model.layers.13.self_attn.o_proj.qscales_zeros', 'model.layers.13.self_attn.o_proj.qstatistic', 'model.layers.13.self_attn.o_proj.qweight', 'model.layers.13.self_attn.o_proj.qzeros_scales', 'model.layers.13.self_attn.o_proj.qzeros_zeros', 'model.layers.13.self_attn.q_proj.g_idx', 'model.layers.13.self_attn.q_proj.qscales_scales', 'model.layers.13.self_attn.q_proj.qscales_zeros', 'model.layers.13.self_attn.q_proj.qstatistic', 'model.layers.13.self_attn.q_proj.qweight', 'model.layers.13.self_attn.q_proj.qzeros_scales', 'model.layers.13.self_attn.q_proj.qzeros_zeros', 'model.layers.13.self_attn.v_proj.g_idx', 'model.layers.13.self_attn.v_proj.qscales_scales', 'model.layers.13.self_attn.v_proj.qscales_zeros', 'model.layers.13.self_attn.v_proj.qstatistic', 'model.layers.13.self_attn.v_proj.qweight', 'model.layers.13.self_attn.v_proj.qzeros_scales', 'model.layers.13.self_attn.v_proj.qzeros_zeros', 'model.layers.14.mlp.down_proj.g_idx', 'model.layers.14.mlp.down_proj.qscales_scales', 'model.layers.14.mlp.down_proj.qscales_zeros', 'model.layers.14.mlp.down_proj.qstatistic', 'model.layers.14.mlp.down_proj.qweight', 'model.layers.14.mlp.down_proj.qzeros_scales', 'model.layers.14.mlp.down_proj.qzeros_zeros', 'model.layers.14.mlp.gate_proj.g_idx', 'model.layers.14.mlp.gate_proj.qscales_scales', 'model.layers.14.mlp.gate_proj.qscales_zeros', 'model.layers.14.mlp.gate_proj.qstatistic', 'model.layers.14.mlp.gate_proj.qweight', 'model.layers.14.mlp.gate_proj.qzeros_scales', 'model.layers.14.mlp.gate_proj.qzeros_zeros', 'model.layers.14.mlp.up_proj.g_idx', 'model.layers.14.mlp.up_proj.qscales_scales', 'model.layers.14.mlp.up_proj.qscales_zeros', 'model.layers.14.mlp.up_proj.qstatistic', 'model.layers.14.mlp.up_proj.qweight', 'model.layers.14.mlp.up_proj.qzeros_scales', 'model.layers.14.mlp.up_proj.qzeros_zeros', 'model.layers.14.self_attn.k_proj.g_idx', 'model.layers.14.self_attn.k_proj.qscales_scales', 'model.layers.14.self_attn.k_proj.qscales_zeros', 'model.layers.14.self_attn.k_proj.qstatistic', 'model.layers.14.self_attn.k_proj.qweight', 'model.layers.14.self_attn.k_proj.qzeros_scales', 'model.layers.14.self_attn.k_proj.qzeros_zeros', 'model.layers.14.self_attn.o_proj.g_idx', 'model.layers.14.self_attn.o_proj.qscales_scales', 'model.layers.14.self_attn.o_proj.qscales_zeros', 'model.layers.14.self_attn.o_proj.qstatistic', 'model.layers.14.self_attn.o_proj.qweight', 'model.layers.14.self_attn.o_proj.qzeros_scales', 'model.layers.14.self_attn.o_proj.qzeros_zeros', 'model.layers.14.self_attn.q_proj.g_idx', 'model.layers.14.self_attn.q_proj.qscales_scales', 'model.layers.14.self_attn.q_proj.qscales_zeros', 'model.layers.14.self_attn.q_proj.qstatistic', 'model.layers.14.self_attn.q_proj.qweight', 'model.layers.14.self_attn.q_proj.qzeros_scales', 'model.layers.14.self_attn.q_proj.qzeros_zeros', 'model.layers.14.self_attn.v_proj.g_idx', 'model.layers.14.self_attn.v_proj.qscales_scales', 'model.layers.14.self_attn.v_proj.qscales_zeros', 'model.layers.14.self_attn.v_proj.qstatistic', 'model.layers.14.self_attn.v_proj.qweight', 'model.layers.14.self_attn.v_proj.qzeros_scales', 'model.layers.14.self_attn.v_proj.qzeros_zeros', 'model.layers.15.mlp.down_proj.g_idx', 'model.layers.15.mlp.down_proj.qscales_scales', 'model.layers.15.mlp.down_proj.qscales_zeros', 'model.layers.15.mlp.down_proj.qstatistic', 'model.layers.15.mlp.down_proj.qweight', 'model.layers.15.mlp.down_proj.qzeros_scales', 'model.layers.15.mlp.down_proj.qzeros_zeros', 'model.layers.15.mlp.gate_proj.g_idx', 'model.layers.15.mlp.gate_proj.qscales_scales', 'model.layers.15.mlp.gate_proj.qscales_zeros', 'model.layers.15.mlp.gate_proj.qstatistic', 'model.layers.15.mlp.gate_proj.qweight', 'model.layers.15.mlp.gate_proj.qzeros_scales', 'model.layers.15.mlp.gate_proj.qzeros_zeros', 'model.layers.15.mlp.up_proj.g_idx', 'model.layers.15.mlp.up_proj.qscales_scales', 'model.layers.15.mlp.up_proj.qscales_zeros', 'model.layers.15.mlp.up_proj.qstatistic', 'model.layers.15.mlp.up_proj.qweight', 'model.layers.15.mlp.up_proj.qzeros_scales', 'model.layers.15.mlp.up_proj.qzeros_zeros', 'model.layers.15.self_attn.k_proj.g_idx', 'model.layers.15.self_attn.k_proj.qscales_scales', 'model.layers.15.self_attn.k_proj.qscales_zeros', 'model.layers.15.self_attn.k_proj.qstatistic', 'model.layers.15.self_attn.k_proj.qweight', 'model.layers.15.self_attn.k_proj.qzeros_scales', 'model.layers.15.self_attn.k_proj.qzeros_zeros', 'model.layers.15.self_attn.o_proj.g_idx', 'model.layers.15.self_attn.o_proj.qscales_scales', 'model.layers.15.self_attn.o_proj.qscales_zeros', 'model.layers.15.self_attn.o_proj.qstatistic', 'model.layers.15.self_attn.o_proj.qweight', 'model.layers.15.self_attn.o_proj.qzeros_scales', 'model.layers.15.self_attn.o_proj.qzeros_zeros', 'model.layers.15.self_attn.q_proj.g_idx', 'model.layers.15.self_attn.q_proj.qscales_scales', 'model.layers.15.self_attn.q_proj.qscales_zeros', 'model.layers.15.self_attn.q_proj.qstatistic', 'model.layers.15.self_attn.q_proj.qweight', 'model.layers.15.self_attn.q_proj.qzeros_scales', 'model.layers.15.self_attn.q_proj.qzeros_zeros', 'model.layers.15.self_attn.v_proj.g_idx', 'model.layers.15.self_attn.v_proj.qscales_scales', 'model.layers.15.self_attn.v_proj.qscales_zeros', 'model.layers.15.self_attn.v_proj.qstatistic', 'model.layers.15.self_attn.v_proj.qweight', 'model.layers.15.self_attn.v_proj.qzeros_scales', 'model.layers.15.self_attn.v_proj.qzeros_zeros', 'model.layers.16.mlp.down_proj.g_idx', 'model.layers.16.mlp.down_proj.qscales_scales', 'model.layers.16.mlp.down_proj.qscales_zeros', 'model.layers.16.mlp.down_proj.qstatistic', 'model.layers.16.mlp.down_proj.qweight', 'model.layers.16.mlp.down_proj.qzeros_scales', 'model.layers.16.mlp.down_proj.qzeros_zeros', 'model.layers.16.mlp.gate_proj.g_idx', 'model.layers.16.mlp.gate_proj.qscales_scales', 'model.layers.16.mlp.gate_proj.qscales_zeros', 'model.layers.16.mlp.gate_proj.qstatistic', 'model.layers.16.mlp.gate_proj.qweight', 'model.layers.16.mlp.gate_proj.qzeros_scales', 'model.layers.16.mlp.gate_proj.qzeros_zeros', 'model.layers.16.mlp.up_proj.g_idx', 'model.layers.16.mlp.up_proj.qscales_scales', 'model.layers.16.mlp.up_proj.qscales_zeros', 'model.layers.16.mlp.up_proj.qstatistic', 'model.layers.16.mlp.up_proj.qweight', 'model.layers.16.mlp.up_proj.qzeros_scales', 'model.layers.16.mlp.up_proj.qzeros_zeros', 'model.layers.16.self_attn.k_proj.g_idx', 'model.layers.16.self_attn.k_proj.qscales_scales', 'model.layers.16.self_attn.k_proj.qscales_zeros', 'model.layers.16.self_attn.k_proj.qstatistic', 'model.layers.16.self_attn.k_proj.qweight', 'model.layers.16.self_attn.k_proj.qzeros_scales', 'model.layers.16.self_attn.k_proj.qzeros_zeros', 'model.layers.16.self_attn.o_proj.g_idx', 'model.layers.16.self_attn.o_proj.qscales_scales', 'model.layers.16.self_attn.o_proj.qscales_zeros', 'model.layers.16.self_attn.o_proj.qstatistic', 'model.layers.16.self_attn.o_proj.qweight', 'model.layers.16.self_attn.o_proj.qzeros_scales', 'model.layers.16.self_attn.o_proj.qzeros_zeros', 'model.layers.16.self_attn.q_proj.g_idx', 'model.layers.16.self_attn.q_proj.qscales_scales', 'model.layers.16.self_attn.q_proj.qscales_zeros', 'model.layers.16.self_attn.q_proj.qstatistic', 'model.layers.16.self_attn.q_proj.qweight', 'model.layers.16.self_attn.q_proj.qzeros_scales', 'model.layers.16.self_attn.q_proj.qzeros_zeros', 'model.layers.16.self_attn.v_proj.g_idx', 'model.layers.16.self_attn.v_proj.qscales_scales', 'model.layers.16.self_attn.v_proj.qscales_zeros', 'model.layers.16.self_attn.v_proj.qstatistic', 'model.layers.16.self_attn.v_proj.qweight', 'model.layers.16.self_attn.v_proj.qzeros_scales', 'model.layers.16.self_attn.v_proj.qzeros_zeros', 'model.layers.17.mlp.down_proj.g_idx', 'model.layers.17.mlp.down_proj.qscales_scales', 'model.layers.17.mlp.down_proj.qscales_zeros', 'model.layers.17.mlp.down_proj.qstatistic', 'model.layers.17.mlp.down_proj.qweight', 'model.layers.17.mlp.down_proj.qzeros_scales', 'model.layers.17.mlp.down_proj.qzeros_zeros', 'model.layers.17.mlp.gate_proj.g_idx', 'model.layers.17.mlp.gate_proj.qscales_scales', 'model.layers.17.mlp.gate_proj.qscales_zeros', 'model.layers.17.mlp.gate_proj.qstatistic', 'model.layers.17.mlp.gate_proj.qweight', 'model.layers.17.mlp.gate_proj.qzeros_scales', 'model.layers.17.mlp.gate_proj.qzeros_zeros', 'model.layers.17.mlp.up_proj.g_idx', 'model.layers.17.mlp.up_proj.qscales_scales', 'model.layers.17.mlp.up_proj.qscales_zeros', 'model.layers.17.mlp.up_proj.qstatistic', 'model.layers.17.mlp.up_proj.qweight', 'model.layers.17.mlp.up_proj.qzeros_scales', 'model.layers.17.mlp.up_proj.qzeros_zeros', 'model.layers.17.self_attn.k_proj.g_idx', 'model.layers.17.self_attn.k_proj.qscales_scales', 'model.layers.17.self_attn.k_proj.qscales_zeros', 'model.layers.17.self_attn.k_proj.qstatistic', 'model.layers.17.self_attn.k_proj.qweight', 'model.layers.17.self_attn.k_proj.qzeros_scales', 'model.layers.17.self_attn.k_proj.qzeros_zeros', 'model.layers.17.self_attn.o_proj.g_idx', 'model.layers.17.self_attn.o_proj.qscales_scales', 'model.layers.17.self_attn.o_proj.qscales_zeros', 'model.layers.17.self_attn.o_proj.qstatistic', 'model.layers.17.self_attn.o_proj.qweight', 'model.layers.17.self_attn.o_proj.qzeros_scales', 'model.layers.17.self_attn.o_proj.qzeros_zeros', 'model.layers.17.self_attn.q_proj.g_idx', 'model.layers.17.self_attn.q_proj.qscales_scales', 'model.layers.17.self_attn.q_proj.qscales_zeros', 'model.layers.17.self_attn.q_proj.qstatistic', 'model.layers.17.self_attn.q_proj.qweight', 'model.layers.17.self_attn.q_proj.qzeros_scales', 'model.layers.17.self_attn.q_proj.qzeros_zeros', 'model.layers.17.self_attn.v_proj.g_idx', 'model.layers.17.self_attn.v_proj.qscales_scales', 'model.layers.17.self_attn.v_proj.qscales_zeros', 'model.layers.17.self_attn.v_proj.qstatistic', 'model.layers.17.self_attn.v_proj.qweight', 'model.layers.17.self_attn.v_proj.qzeros_scales', 'model.layers.17.self_attn.v_proj.qzeros_zeros', 'model.layers.18.mlp.down_proj.g_idx', 'model.layers.18.mlp.down_proj.qscales_scales', 'model.layers.18.mlp.down_proj.qscales_zeros', 'model.layers.18.mlp.down_proj.qstatistic', 'model.layers.18.mlp.down_proj.qweight', 'model.layers.18.mlp.down_proj.qzeros_scales', 'model.layers.18.mlp.down_proj.qzeros_zeros', 'model.layers.18.mlp.gate_proj.g_idx', 'model.layers.18.mlp.gate_proj.qscales_scales', 'model.layers.18.mlp.gate_proj.qscales_zeros', 'model.layers.18.mlp.gate_proj.qstatistic', 'model.layers.18.mlp.gate_proj.qweight', 'model.layers.18.mlp.gate_proj.qzeros_scales', 'model.layers.18.mlp.gate_proj.qzeros_zeros', 'model.layers.18.mlp.up_proj.g_idx', 'model.layers.18.mlp.up_proj.qscales_scales', 'model.layers.18.mlp.up_proj.qscales_zeros', 'model.layers.18.mlp.up_proj.qstatistic', 'model.layers.18.mlp.up_proj.qweight', 'model.layers.18.mlp.up_proj.qzeros_scales', 'model.layers.18.mlp.up_proj.qzeros_zeros', 'model.layers.18.self_attn.k_proj.g_idx', 'model.layers.18.self_attn.k_proj.qscales_scales', 'model.layers.18.self_attn.k_proj.qscales_zeros', 'model.layers.18.self_attn.k_proj.qstatistic', 'model.layers.18.self_attn.k_proj.qweight', 'model.layers.18.self_attn.k_proj.qzeros_scales', 'model.layers.18.self_attn.k_proj.qzeros_zeros', 'model.layers.18.self_attn.o_proj.g_idx', 'model.layers.18.self_attn.o_proj.qscales_scales', 'model.layers.18.self_attn.o_proj.qscales_zeros', 'model.layers.18.self_attn.o_proj.qstatistic', 'model.layers.18.self_attn.o_proj.qweight', 'model.layers.18.self_attn.o_proj.qzeros_scales', 'model.layers.18.self_attn.o_proj.qzeros_zeros', 'model.layers.18.self_attn.q_proj.g_idx', 'model.layers.18.self_attn.q_proj.qscales_scales', 'model.layers.18.self_attn.q_proj.qscales_zeros', 'model.layers.18.self_attn.q_proj.qstatistic', 'model.layers.18.self_attn.q_proj.qweight', 'model.layers.18.self_attn.q_proj.qzeros_scales', 'model.layers.18.self_attn.q_proj.qzeros_zeros', 'model.layers.18.self_attn.v_proj.g_idx', 'model.layers.18.self_attn.v_proj.qscales_scales', 'model.layers.18.self_attn.v_proj.qscales_zeros', 'model.layers.18.self_attn.v_proj.qstatistic', 'model.layers.18.self_attn.v_proj.qweight', 'model.layers.18.self_attn.v_proj.qzeros_scales', 'model.layers.18.self_attn.v_proj.qzeros_zeros', 'model.layers.19.mlp.down_proj.g_idx', 'model.layers.19.mlp.down_proj.qscales_scales', 'model.layers.19.mlp.down_proj.qscales_zeros', 'model.layers.19.mlp.down_proj.qstatistic', 'model.layers.19.mlp.down_proj.qweight', 'model.layers.19.mlp.down_proj.qzeros_scales', 'model.layers.19.mlp.down_proj.qzeros_zeros', 'model.layers.19.mlp.gate_proj.g_idx', 'model.layers.19.mlp.gate_proj.qscales_scales', 'model.layers.19.mlp.gate_proj.qscales_zeros', 'model.layers.19.mlp.gate_proj.qstatistic', 'model.layers.19.mlp.gate_proj.qweight', 'model.layers.19.mlp.gate_proj.qzeros_scales', 'model.layers.19.mlp.gate_proj.qzeros_zeros', 'model.layers.19.mlp.up_proj.g_idx', 'model.layers.19.mlp.up_proj.qscales_scales', 'model.layers.19.mlp.up_proj.qscales_zeros', 'model.layers.19.mlp.up_proj.qstatistic', 'model.layers.19.mlp.up_proj.qweight', 'model.layers.19.mlp.up_proj.qzeros_scales', 'model.layers.19.mlp.up_proj.qzeros_zeros', 'model.layers.19.self_attn.k_proj.g_idx', 'model.layers.19.self_attn.k_proj.qscales_scales', 'model.layers.19.self_attn.k_proj.qscales_zeros', 'model.layers.19.self_attn.k_proj.qstatistic', 'model.layers.19.self_attn.k_proj.qweight', 'model.layers.19.self_attn.k_proj.qzeros_scales', 'model.layers.19.self_attn.k_proj.qzeros_zeros', 'model.layers.19.self_attn.o_proj.g_idx', 'model.layers.19.self_attn.o_proj.qscales_scales', 'model.layers.19.self_attn.o_proj.qscales_zeros', 'model.layers.19.self_attn.o_proj.qstatistic', 'model.layers.19.self_attn.o_proj.qweight', 'model.layers.19.self_attn.o_proj.qzeros_scales', 'model.layers.19.self_attn.o_proj.qzeros_zeros', 'model.layers.19.self_attn.q_proj.g_idx', 'model.layers.19.self_attn.q_proj.qscales_scales', 'model.layers.19.self_attn.q_proj.qscales_zeros', 'model.layers.19.self_attn.q_proj.qstatistic', 'model.layers.19.self_attn.q_proj.qweight', 'model.layers.19.self_attn.q_proj.qzeros_scales', 'model.layers.19.self_attn.q_proj.qzeros_zeros', 'model.layers.19.self_attn.v_proj.g_idx', 'model.layers.19.self_attn.v_proj.qscales_scales', 'model.layers.19.self_attn.v_proj.qscales_zeros', 'model.layers.19.self_attn.v_proj.qstatistic', 'model.layers.19.self_attn.v_proj.qweight', 'model.layers.19.self_attn.v_proj.qzeros_scales', 'model.layers.19.self_attn.v_proj.qzeros_zeros', 'model.layers.2.mlp.down_proj.g_idx', 'model.layers.2.mlp.down_proj.qscales_scales', 'model.layers.2.mlp.down_proj.qscales_zeros', 'model.layers.2.mlp.down_proj.qstatistic', 'model.layers.2.mlp.down_proj.qweight', 'model.layers.2.mlp.down_proj.qzeros_scales', 'model.layers.2.mlp.down_proj.qzeros_zeros', 'model.layers.2.mlp.gate_proj.g_idx', 'model.layers.2.mlp.gate_proj.qscales_scales', 'model.layers.2.mlp.gate_proj.qscales_zeros', 'model.layers.2.mlp.gate_proj.qstatistic', 'model.layers.2.mlp.gate_proj.qweight', 'model.layers.2.mlp.gate_proj.qzeros_scales', 'model.layers.2.mlp.gate_proj.qzeros_zeros', 'model.layers.2.mlp.up_proj.g_idx', 'model.layers.2.mlp.up_proj.qscales_scales', 'model.layers.2.mlp.up_proj.qscales_zeros', 'model.layers.2.mlp.up_proj.qstatistic', 'model.layers.2.mlp.up_proj.qweight', 'model.layers.2.mlp.up_proj.qzeros_scales', 'model.layers.2.mlp.up_proj.qzeros_zeros', 'model.layers.2.self_attn.k_proj.g_idx', 'model.layers.2.self_attn.k_proj.qscales_scales', 'model.layers.2.self_attn.k_proj.qscales_zeros', 'model.layers.2.self_attn.k_proj.qstatistic', 'model.layers.2.self_attn.k_proj.qweight', 'model.layers.2.self_attn.k_proj.qzeros_scales', 'model.layers.2.self_attn.k_proj.qzeros_zeros', 'model.layers.2.self_attn.o_proj.g_idx', 'model.layers.2.self_attn.o_proj.qscales_scales', 'model.layers.2.self_attn.o_proj.qscales_zeros', 'model.layers.2.self_attn.o_proj.qstatistic', 'model.layers.2.self_attn.o_proj.qweight', 'model.layers.2.self_attn.o_proj.qzeros_scales', 'model.layers.2.self_attn.o_proj.qzeros_zeros', 'model.layers.2.self_attn.q_proj.g_idx', 'model.layers.2.self_attn.q_proj.qscales_scales', 'model.layers.2.self_attn.q_proj.qscales_zeros', 'model.layers.2.self_attn.q_proj.qstatistic', 'model.layers.2.self_attn.q_proj.qweight', 'model.layers.2.self_attn.q_proj.qzeros_scales', 'model.layers.2.self_attn.q_proj.qzeros_zeros', 'model.layers.2.self_attn.v_proj.g_idx', 'model.layers.2.self_attn.v_proj.qscales_scales', 'model.layers.2.self_attn.v_proj.qscales_zeros', 'model.layers.2.self_attn.v_proj.qstatistic', 'model.layers.2.self_attn.v_proj.qweight', 'model.layers.2.self_attn.v_proj.qzeros_scales', 'model.layers.2.self_attn.v_proj.qzeros_zeros', 'model.layers.20.mlp.down_proj.g_idx', 'model.layers.20.mlp.down_proj.qscales_scales', 'model.layers.20.mlp.down_proj.qscales_zeros', 'model.layers.20.mlp.down_proj.qstatistic', 'model.layers.20.mlp.down_proj.qweight', 'model.layers.20.mlp.down_proj.qzeros_scales', 'model.layers.20.mlp.down_proj.qzeros_zeros', 'model.layers.20.mlp.gate_proj.g_idx', 'model.layers.20.mlp.gate_proj.qscales_scales', 'model.layers.20.mlp.gate_proj.qscales_zeros', 'model.layers.20.mlp.gate_proj.qstatistic', 'model.layers.20.mlp.gate_proj.qweight', 'model.layers.20.mlp.gate_proj.qzeros_scales', 'model.layers.20.mlp.gate_proj.qzeros_zeros', 'model.layers.20.mlp.up_proj.g_idx', 'model.layers.20.mlp.up_proj.qscales_scales', 'model.layers.20.mlp.up_proj.qscales_zeros', 'model.layers.20.mlp.up_proj.qstatistic', 'model.layers.20.mlp.up_proj.qweight', 'model.layers.20.mlp.up_proj.qzeros_scales', 'model.layers.20.mlp.up_proj.qzeros_zeros', 'model.layers.20.self_attn.k_proj.g_idx', 'model.layers.20.self_attn.k_proj.qscales_scales', 'model.layers.20.self_attn.k_proj.qscales_zeros', 'model.layers.20.self_attn.k_proj.qstatistic', 'model.layers.20.self_attn.k_proj.qweight', 'model.layers.20.self_attn.k_proj.qzeros_scales', 'model.layers.20.self_attn.k_proj.qzeros_zeros', 'model.layers.20.self_attn.o_proj.g_idx', 'model.layers.20.self_attn.o_proj.qscales_scales', 'model.layers.20.self_attn.o_proj.qscales_zeros', 'model.layers.20.self_attn.o_proj.qstatistic', 'model.layers.20.self_attn.o_proj.qweight', 'model.layers.20.self_attn.o_proj.qzeros_scales', 'model.layers.20.self_attn.o_proj.qzeros_zeros', 'model.layers.20.self_attn.q_proj.g_idx', 'model.layers.20.self_attn.q_proj.qscales_scales', 'model.layers.20.self_attn.q_proj.qscales_zeros', 'model.layers.20.self_attn.q_proj.qstatistic', 'model.layers.20.self_attn.q_proj.qweight', 'model.layers.20.self_attn.q_proj.qzeros_scales', 'model.layers.20.self_attn.q_proj.qzeros_zeros', 'model.layers.20.self_attn.v_proj.g_idx', 'model.layers.20.self_attn.v_proj.qscales_scales', 'model.layers.20.self_attn.v_proj.qscales_zeros', 'model.layers.20.self_attn.v_proj.qstatistic', 'model.layers.20.self_attn.v_proj.qweight', 'model.layers.20.self_attn.v_proj.qzeros_scales', 'model.layers.20.self_attn.v_proj.qzeros_zeros', 'model.layers.21.mlp.down_proj.g_idx', 'model.layers.21.mlp.down_proj.qscales_scales', 'model.layers.21.mlp.down_proj.qscales_zeros', 'model.layers.21.mlp.down_proj.qstatistic', 'model.layers.21.mlp.down_proj.qweight', 'model.layers.21.mlp.down_proj.qzeros_scales', 'model.layers.21.mlp.down_proj.qzeros_zeros', 'model.layers.21.mlp.gate_proj.g_idx', 'model.layers.21.mlp.gate_proj.qscales_scales', 'model.layers.21.mlp.gate_proj.qscales_zeros', 'model.layers.21.mlp.gate_proj.qstatistic', 'model.layers.21.mlp.gate_proj.qweight', 'model.layers.21.mlp.gate_proj.qzeros_scales', 'model.layers.21.mlp.gate_proj.qzeros_zeros', 'model.layers.21.mlp.up_proj.g_idx', 'model.layers.21.mlp.up_proj.qscales_scales', 'model.layers.21.mlp.up_proj.qscales_zeros', 'model.layers.21.mlp.up_proj.qstatistic', 'model.layers.21.mlp.up_proj.qweight', 'model.layers.21.mlp.up_proj.qzeros_scales', 'model.layers.21.mlp.up_proj.qzeros_zeros', 'model.layers.21.self_attn.k_proj.g_idx', 'model.layers.21.self_attn.k_proj.qscales_scales', 'model.layers.21.self_attn.k_proj.qscales_zeros', 'model.layers.21.self_attn.k_proj.qstatistic', 'model.layers.21.self_attn.k_proj.qweight', 'model.layers.21.self_attn.k_proj.qzeros_scales', 'model.layers.21.self_attn.k_proj.qzeros_zeros', 'model.layers.21.self_attn.o_proj.g_idx', 'model.layers.21.self_attn.o_proj.qscales_scales', 'model.layers.21.self_attn.o_proj.qscales_zeros', 'model.layers.21.self_attn.o_proj.qstatistic', 'model.layers.21.self_attn.o_proj.qweight', 'model.layers.21.self_attn.o_proj.qzeros_scales', 'model.layers.21.self_attn.o_proj.qzeros_zeros', 'model.layers.21.self_attn.q_proj.g_idx', 'model.layers.21.self_attn.q_proj.qscales_scales', 'model.layers.21.self_attn.q_proj.qscales_zeros', 'model.layers.21.self_attn.q_proj.qstatistic', 'model.layers.21.self_attn.q_proj.qweight', 'model.layers.21.self_attn.q_proj.qzeros_scales', 'model.layers.21.self_attn.q_proj.qzeros_zeros', 'model.layers.21.self_attn.v_proj.g_idx', 'model.layers.21.self_attn.v_proj.qscales_scales', 'model.layers.21.self_attn.v_proj.qscales_zeros', 'model.layers.21.self_attn.v_proj.qstatistic', 'model.layers.21.self_attn.v_proj.qweight', 'model.layers.21.self_attn.v_proj.qzeros_scales', 'model.layers.21.self_attn.v_proj.qzeros_zeros', 'model.layers.22.mlp.down_proj.g_idx', 'model.layers.22.mlp.down_proj.qscales_scales', 'model.layers.22.mlp.down_proj.qscales_zeros', 'model.layers.22.mlp.down_proj.qstatistic', 'model.layers.22.mlp.down_proj.qweight', 'model.layers.22.mlp.down_proj.qzeros_scales', 'model.layers.22.mlp.down_proj.qzeros_zeros', 'model.layers.22.mlp.gate_proj.g_idx', 'model.layers.22.mlp.gate_proj.qscales_scales', 'model.layers.22.mlp.gate_proj.qscales_zeros', 'model.layers.22.mlp.gate_proj.qstatistic', 'model.layers.22.mlp.gate_proj.qweight', 'model.layers.22.mlp.gate_proj.qzeros_scales', 'model.layers.22.mlp.gate_proj.qzeros_zeros', 'model.layers.22.mlp.up_proj.g_idx', 'model.layers.22.mlp.up_proj.qscales_scales', 'model.layers.22.mlp.up_proj.qscales_zeros', 'model.layers.22.mlp.up_proj.qstatistic', 'model.layers.22.mlp.up_proj.qweight', 'model.layers.22.mlp.up_proj.qzeros_scales', 'model.layers.22.mlp.up_proj.qzeros_zeros', 'model.layers.22.self_attn.k_proj.g_idx', 'model.layers.22.self_attn.k_proj.qscales_scales', 'model.layers.22.self_attn.k_proj.qscales_zeros', 'model.layers.22.self_attn.k_proj.qstatistic', 'model.layers.22.self_attn.k_proj.qweight', 'model.layers.22.self_attn.k_proj.qzeros_scales', 'model.layers.22.self_attn.k_proj.qzeros_zeros', 'model.layers.22.self_attn.o_proj.g_idx', 'model.layers.22.self_attn.o_proj.qscales_scales', 'model.layers.22.self_attn.o_proj.qscales_zeros', 'model.layers.22.self_attn.o_proj.qstatistic', 'model.layers.22.self_attn.o_proj.qweight', 'model.layers.22.self_attn.o_proj.qzeros_scales', 'model.layers.22.self_attn.o_proj.qzeros_zeros', 'model.layers.22.self_attn.q_proj.g_idx', 'model.layers.22.self_attn.q_proj.qscales_scales', 'model.layers.22.self_attn.q_proj.qscales_zeros', 'model.layers.22.self_attn.q_proj.qstatistic', 'model.layers.22.self_attn.q_proj.qweight', 'model.layers.22.self_attn.q_proj.qzeros_scales', 'model.layers.22.self_attn.q_proj.qzeros_zeros', 'model.layers.22.self_attn.v_proj.g_idx', 'model.layers.22.self_attn.v_proj.qscales_scales', 'model.layers.22.self_attn.v_proj.qscales_zeros', 'model.layers.22.self_attn.v_proj.qstatistic', 'model.layers.22.self_attn.v_proj.qweight', 'model.layers.22.self_attn.v_proj.qzeros_scales', 'model.layers.22.self_attn.v_proj.qzeros_zeros', 'model.layers.23.mlp.down_proj.g_idx', 'model.layers.23.mlp.down_proj.qscales_scales', 'model.layers.23.mlp.down_proj.qscales_zeros', 'model.layers.23.mlp.down_proj.qstatistic', 'model.layers.23.mlp.down_proj.qweight', 'model.layers.23.mlp.down_proj.qzeros_scales', 'model.layers.23.mlp.down_proj.qzeros_zeros', 'model.layers.23.mlp.gate_proj.g_idx', 'model.layers.23.mlp.gate_proj.qscales_scales', 'model.layers.23.mlp.gate_proj.qscales_zeros', 'model.layers.23.mlp.gate_proj.qstatistic', 'model.layers.23.mlp.gate_proj.qweight', 'model.layers.23.mlp.gate_proj.qzeros_scales', 'model.layers.23.mlp.gate_proj.qzeros_zeros', 'model.layers.23.mlp.up_proj.g_idx', 'model.layers.23.mlp.up_proj.qscales_scales', 'model.layers.23.mlp.up_proj.qscales_zeros', 'model.layers.23.mlp.up_proj.qstatistic', 'model.layers.23.mlp.up_proj.qweight', 'model.layers.23.mlp.up_proj.qzeros_scales', 'model.layers.23.mlp.up_proj.qzeros_zeros', 'model.layers.23.self_attn.k_proj.g_idx', 'model.layers.23.self_attn.k_proj.qscales_scales', 'model.layers.23.self_attn.k_proj.qscales_zeros', 'model.layers.23.self_attn.k_proj.qstatistic', 'model.layers.23.self_attn.k_proj.qweight', 'model.layers.23.self_attn.k_proj.qzeros_scales', 'model.layers.23.self_attn.k_proj.qzeros_zeros', 'model.layers.23.self_attn.o_proj.g_idx', 'model.layers.23.self_attn.o_proj.qscales_scales', 'model.layers.23.self_attn.o_proj.qscales_zeros', 'model.layers.23.self_attn.o_proj.qstatistic', 'model.layers.23.self_attn.o_proj.qweight', 'model.layers.23.self_attn.o_proj.qzeros_scales', 'model.layers.23.self_attn.o_proj.qzeros_zeros', 'model.layers.23.self_attn.q_proj.g_idx', 'model.layers.23.self_attn.q_proj.qscales_scales', 'model.layers.23.self_attn.q_proj.qscales_zeros', 'model.layers.23.self_attn.q_proj.qstatistic', 'model.layers.23.self_attn.q_proj.qweight', 'model.layers.23.self_attn.q_proj.qzeros_scales', 'model.layers.23.self_attn.q_proj.qzeros_zeros', 'model.layers.23.self_attn.v_proj.g_idx', 'model.layers.23.self_attn.v_proj.qscales_scales', 'model.layers.23.self_attn.v_proj.qscales_zeros', 'model.layers.23.self_attn.v_proj.qstatistic', 'model.layers.23.self_attn.v_proj.qweight', 'model.layers.23.self_attn.v_proj.qzeros_scales', 'model.layers.23.self_attn.v_proj.qzeros_zeros', 'model.layers.24.mlp.down_proj.g_idx', 'model.layers.24.mlp.down_proj.qscales_scales', 'model.layers.24.mlp.down_proj.qscales_zeros', 'model.layers.24.mlp.down_proj.qstatistic', 'model.layers.24.mlp.down_proj.qweight', 'model.layers.24.mlp.down_proj.qzeros_scales', 'model.layers.24.mlp.down_proj.qzeros_zeros', 'model.layers.24.mlp.gate_proj.g_idx', 'model.layers.24.mlp.gate_proj.qscales_scales', 'model.layers.24.mlp.gate_proj.qscales_zeros', 'model.layers.24.mlp.gate_proj.qstatistic', 'model.layers.24.mlp.gate_proj.qweight', 'model.layers.24.mlp.gate_proj.qzeros_scales', 'model.layers.24.mlp.gate_proj.qzeros_zeros', 'model.layers.24.mlp.up_proj.g_idx', 'model.layers.24.mlp.up_proj.qscales_scales', 'model.layers.24.mlp.up_proj.qscales_zeros', 'model.layers.24.mlp.up_proj.qstatistic', 'model.layers.24.mlp.up_proj.qweight', 'model.layers.24.mlp.up_proj.qzeros_scales', 'model.layers.24.mlp.up_proj.qzeros_zeros', 'model.layers.24.self_attn.k_proj.g_idx', 'model.layers.24.self_attn.k_proj.qscales_scales', 'model.layers.24.self_attn.k_proj.qscales_zeros', 'model.layers.24.self_attn.k_proj.qstatistic', 'model.layers.24.self_attn.k_proj.qweight', 'model.layers.24.self_attn.k_proj.qzeros_scales', 'model.layers.24.self_attn.k_proj.qzeros_zeros', 'model.layers.24.self_attn.o_proj.g_idx', 'model.layers.24.self_attn.o_proj.qscales_scales', 'model.layers.24.self_attn.o_proj.qscales_zeros', 'model.layers.24.self_attn.o_proj.qstatistic', 'model.layers.24.self_attn.o_proj.qweight', 'model.layers.24.self_attn.o_proj.qzeros_scales', 'model.layers.24.self_attn.o_proj.qzeros_zeros', 'model.layers.24.self_attn.q_proj.g_idx', 'model.layers.24.self_attn.q_proj.qscales_scales', 'model.layers.24.self_attn.q_proj.qscales_zeros', 'model.layers.24.self_attn.q_proj.qstatistic', 'model.layers.24.self_attn.q_proj.qweight', 'model.layers.24.self_attn.q_proj.qzeros_scales', 'model.layers.24.self_attn.q_proj.qzeros_zeros', 'model.layers.24.self_attn.v_proj.g_idx', 'model.layers.24.self_attn.v_proj.qscales_scales', 'model.layers.24.self_attn.v_proj.qscales_zeros', 'model.layers.24.self_attn.v_proj.qstatistic', 'model.layers.24.self_attn.v_proj.qweight', 'model.layers.24.self_attn.v_proj.qzeros_scales', 'model.layers.24.self_attn.v_proj.qzeros_zeros', 'model.layers.25.mlp.down_proj.g_idx', 'model.layers.25.mlp.down_proj.qscales_scales', 'model.layers.25.mlp.down_proj.qscales_zeros', 'model.layers.25.mlp.down_proj.qstatistic', 'model.layers.25.mlp.down_proj.qweight', 'model.layers.25.mlp.down_proj.qzeros_scales', 'model.layers.25.mlp.down_proj.qzeros_zeros', 'model.layers.25.mlp.gate_proj.g_idx', 'model.layers.25.mlp.gate_proj.qscales_scales', 'model.layers.25.mlp.gate_proj.qscales_zeros', 'model.layers.25.mlp.gate_proj.qstatistic', 'model.layers.25.mlp.gate_proj.qweight', 'model.layers.25.mlp.gate_proj.qzeros_scales', 'model.layers.25.mlp.gate_proj.qzeros_zeros', 'model.layers.25.mlp.up_proj.g_idx', 'model.layers.25.mlp.up_proj.qscales_scales', 'model.layers.25.mlp.up_proj.qscales_zeros', 'model.layers.25.mlp.up_proj.qstatistic', 'model.layers.25.mlp.up_proj.qweight', 'model.layers.25.mlp.up_proj.qzeros_scales', 'model.layers.25.mlp.up_proj.qzeros_zeros', 'model.layers.25.self_attn.k_proj.g_idx', 'model.layers.25.self_attn.k_proj.qscales_scales', 'model.layers.25.self_attn.k_proj.qscales_zeros', 'model.layers.25.self_attn.k_proj.qstatistic', 'model.layers.25.self_attn.k_proj.qweight', 'model.layers.25.self_attn.k_proj.qzeros_scales', 'model.layers.25.self_attn.k_proj.qzeros_zeros', 'model.layers.25.self_attn.o_proj.g_idx', 'model.layers.25.self_attn.o_proj.qscales_scales', 'model.layers.25.self_attn.o_proj.qscales_zeros', 'model.layers.25.self_attn.o_proj.qstatistic', 'model.layers.25.self_attn.o_proj.qweight', 'model.layers.25.self_attn.o_proj.qzeros_scales', 'model.layers.25.self_attn.o_proj.qzeros_zeros', 'model.layers.25.self_attn.q_proj.g_idx', 'model.layers.25.self_attn.q_proj.qscales_scales', 'model.layers.25.self_attn.q_proj.qscales_zeros', 'model.layers.25.self_attn.q_proj.qstatistic', 'model.layers.25.self_attn.q_proj.qweight', 'model.layers.25.self_attn.q_proj.qzeros_scales', 'model.layers.25.self_attn.q_proj.qzeros_zeros', 'model.layers.25.self_attn.v_proj.g_idx', 'model.layers.25.self_attn.v_proj.qscales_scales', 'model.layers.25.self_attn.v_proj.qscales_zeros', 'model.layers.25.self_attn.v_proj.qstatistic', 'model.layers.25.self_attn.v_proj.qweight', 'model.layers.25.self_attn.v_proj.qzeros_scales', 'model.layers.25.self_attn.v_proj.qzeros_zeros', 'model.layers.26.mlp.down_proj.g_idx', 'model.layers.26.mlp.down_proj.qscales_scales', 'model.layers.26.mlp.down_proj.qscales_zeros', 'model.layers.26.mlp.down_proj.qstatistic', 'model.layers.26.mlp.down_proj.qweight', 'model.layers.26.mlp.down_proj.qzeros_scales', 'model.layers.26.mlp.down_proj.qzeros_zeros', 'model.layers.26.mlp.gate_proj.g_idx', 'model.layers.26.mlp.gate_proj.qscales_scales', 'model.layers.26.mlp.gate_proj.qscales_zeros', 'model.layers.26.mlp.gate_proj.qstatistic', 'model.layers.26.mlp.gate_proj.qweight', 'model.layers.26.mlp.gate_proj.qzeros_scales', 'model.layers.26.mlp.gate_proj.qzeros_zeros', 'model.layers.26.mlp.up_proj.g_idx', 'model.layers.26.mlp.up_proj.qscales_scales', 'model.layers.26.mlp.up_proj.qscales_zeros', 'model.layers.26.mlp.up_proj.qstatistic', 'model.layers.26.mlp.up_proj.qweight', 'model.layers.26.mlp.up_proj.qzeros_scales', 'model.layers.26.mlp.up_proj.qzeros_zeros', 'model.layers.26.self_attn.k_proj.g_idx', 'model.layers.26.self_attn.k_proj.qscales_scales', 'model.layers.26.self_attn.k_proj.qscales_zeros', 'model.layers.26.self_attn.k_proj.qstatistic', 'model.layers.26.self_attn.k_proj.qweight', 'model.layers.26.self_attn.k_proj.qzeros_scales', 'model.layers.26.self_attn.k_proj.qzeros_zeros', 'model.layers.26.self_attn.o_proj.g_idx', 'model.layers.26.self_attn.o_proj.qscales_scales', 'model.layers.26.self_attn.o_proj.qscales_zeros', 'model.layers.26.self_attn.o_proj.qstatistic', 'model.layers.26.self_attn.o_proj.qweight', 'model.layers.26.self_attn.o_proj.qzeros_scales', 'model.layers.26.self_attn.o_proj.qzeros_zeros', 'model.layers.26.self_attn.q_proj.g_idx', 'model.layers.26.self_attn.q_proj.qscales_scales', 'model.layers.26.self_attn.q_proj.qscales_zeros', 'model.layers.26.self_attn.q_proj.qstatistic', 'model.layers.26.self_attn.q_proj.qweight', 'model.layers.26.self_attn.q_proj.qzeros_scales', 'model.layers.26.self_attn.q_proj.qzeros_zeros', 'model.layers.26.self_attn.v_proj.g_idx', 'model.layers.26.self_attn.v_proj.qscales_scales', 'model.layers.26.self_attn.v_proj.qscales_zeros', 'model.layers.26.self_attn.v_proj.qstatistic', 'model.layers.26.self_attn.v_proj.qweight', 'model.layers.26.self_attn.v_proj.qzeros_scales', 'model.layers.26.self_attn.v_proj.qzeros_zeros', 'model.layers.27.mlp.down_proj.g_idx', 'model.layers.27.mlp.down_proj.qscales_scales', 'model.layers.27.mlp.down_proj.qscales_zeros', 'model.layers.27.mlp.down_proj.qstatistic', 'model.layers.27.mlp.down_proj.qweight', 'model.layers.27.mlp.down_proj.qzeros_scales', 'model.layers.27.mlp.down_proj.qzeros_zeros', 'model.layers.27.mlp.gate_proj.g_idx', 'model.layers.27.mlp.gate_proj.qscales_scales', 'model.layers.27.mlp.gate_proj.qscales_zeros', 'model.layers.27.mlp.gate_proj.qstatistic', 'model.layers.27.mlp.gate_proj.qweight', 'model.layers.27.mlp.gate_proj.qzeros_scales', 'model.layers.27.mlp.gate_proj.qzeros_zeros', 'model.layers.27.mlp.up_proj.g_idx', 'model.layers.27.mlp.up_proj.qscales_scales', 'model.layers.27.mlp.up_proj.qscales_zeros', 'model.layers.27.mlp.up_proj.qstatistic', 'model.layers.27.mlp.up_proj.qweight', 'model.layers.27.mlp.up_proj.qzeros_scales', 'model.layers.27.mlp.up_proj.qzeros_zeros', 'model.layers.27.self_attn.k_proj.g_idx', 'model.layers.27.self_attn.k_proj.qscales_scales', 'model.layers.27.self_attn.k_proj.qscales_zeros', 'model.layers.27.self_attn.k_proj.qstatistic', 'model.layers.27.self_attn.k_proj.qweight', 'model.layers.27.self_attn.k_proj.qzeros_scales', 'model.layers.27.self_attn.k_proj.qzeros_zeros', 'model.layers.27.self_attn.o_proj.g_idx', 'model.layers.27.self_attn.o_proj.qscales_scales', 'model.layers.27.self_attn.o_proj.qscales_zeros', 'model.layers.27.self_attn.o_proj.qstatistic', 'model.layers.27.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qzeros_scales', 'model.layers.27.self_attn.o_proj.qzeros_zeros', 'model.layers.27.self_attn.q_proj.g_idx', 'model.layers.27.self_attn.q_proj.qscales_scales', 'model.layers.27.self_attn.q_proj.qscales_zeros', 'model.layers.27.self_attn.q_proj.qstatistic', 'model.layers.27.self_attn.q_proj.qweight', 'model.layers.27.self_attn.q_proj.qzeros_scales', 'model.layers.27.self_attn.q_proj.qzeros_zeros', 'model.layers.27.self_attn.v_proj.g_idx', 'model.layers.27.self_attn.v_proj.qscales_scales', 'model.layers.27.self_attn.v_proj.qscales_zeros', 'model.layers.27.self_attn.v_proj.qstatistic', 'model.layers.27.self_attn.v_proj.qweight', 'model.layers.27.self_attn.v_proj.qzeros_scales', 'model.layers.27.self_attn.v_proj.qzeros_zeros', 'model.layers.28.mlp.down_proj.g_idx', 'model.layers.28.mlp.down_proj.qscales_scales', 'model.layers.28.mlp.down_proj.qscales_zeros', 'model.layers.28.mlp.down_proj.qstatistic', 'model.layers.28.mlp.down_proj.qweight', 'model.layers.28.mlp.down_proj.qzeros_scales', 'model.layers.28.mlp.down_proj.qzeros_zeros', 'model.layers.28.mlp.gate_proj.g_idx', 'model.layers.28.mlp.gate_proj.qscales_scales', 'model.layers.28.mlp.gate_proj.qscales_zeros', 'model.layers.28.mlp.gate_proj.qstatistic', 'model.layers.28.mlp.gate_proj.qweight', 'model.layers.28.mlp.gate_proj.qzeros_scales', 'model.layers.28.mlp.gate_proj.qzeros_zeros', 'model.layers.28.mlp.up_proj.g_idx', 'model.layers.28.mlp.up_proj.qscales_scales', 'model.layers.28.mlp.up_proj.qscales_zeros', 'model.layers.28.mlp.up_proj.qstatistic', 'model.layers.28.mlp.up_proj.qweight', 'model.layers.28.mlp.up_proj.qzeros_scales', 'model.layers.28.mlp.up_proj.qzeros_zeros', 'model.layers.28.self_attn.k_proj.g_idx', 'model.layers.28.self_attn.k_proj.qscales_scales', 'model.layers.28.self_attn.k_proj.qscales_zeros', 'model.layers.28.self_attn.k_proj.qstatistic', 'model.layers.28.self_attn.k_proj.qweight', 'model.layers.28.self_attn.k_proj.qzeros_scales', 'model.layers.28.self_attn.k_proj.qzeros_zeros', 'model.layers.28.self_attn.o_proj.g_idx', 'model.layers.28.self_attn.o_proj.qscales_scales', 'model.layers.28.self_attn.o_proj.qscales_zeros', 'model.layers.28.self_attn.o_proj.qstatistic', 'model.layers.28.self_attn.o_proj.qweight', 'model.layers.28.self_attn.o_proj.qzeros_scales', 'model.layers.28.self_attn.o_proj.qzeros_zeros', 'model.layers.28.self_attn.q_proj.g_idx', 'model.layers.28.self_attn.q_proj.qscales_scales', 'model.layers.28.self_attn.q_proj.qscales_zeros', 'model.layers.28.self_attn.q_proj.qstatistic', 'model.layers.28.self_attn.q_proj.qweight', 'model.layers.28.self_attn.q_proj.qzeros_scales', 'model.layers.28.self_attn.q_proj.qzeros_zeros', 'model.layers.28.self_attn.v_proj.g_idx', 'model.layers.28.self_attn.v_proj.qscales_scales', 'model.layers.28.self_attn.v_proj.qscales_zeros', 'model.layers.28.self_attn.v_proj.qstatistic', 'model.layers.28.self_attn.v_proj.qweight', 'model.layers.28.self_attn.v_proj.qzeros_scales', 'model.layers.28.self_attn.v_proj.qzeros_zeros', 'model.layers.29.mlp.down_proj.g_idx', 'model.layers.29.mlp.down_proj.qscales_scales', 'model.layers.29.mlp.down_proj.qscales_zeros', 'model.layers.29.mlp.down_proj.qstatistic', 'model.layers.29.mlp.down_proj.qweight', 'model.layers.29.mlp.down_proj.qzeros_scales', 'model.layers.29.mlp.down_proj.qzeros_zeros', 'model.layers.29.mlp.gate_proj.g_idx', 'model.layers.29.mlp.gate_proj.qscales_scales', 'model.layers.29.mlp.gate_proj.qscales_zeros', 'model.layers.29.mlp.gate_proj.qstatistic', 'model.layers.29.mlp.gate_proj.qweight', 'model.layers.29.mlp.gate_proj.qzeros_scales', 'model.layers.29.mlp.gate_proj.qzeros_zeros', 'model.layers.29.mlp.up_proj.g_idx', 'model.layers.29.mlp.up_proj.qscales_scales', 'model.layers.29.mlp.up_proj.qscales_zeros', 'model.layers.29.mlp.up_proj.qstatistic', 'model.layers.29.mlp.up_proj.qweight', 'model.layers.29.mlp.up_proj.qzeros_scales', 'model.layers.29.mlp.up_proj.qzeros_zeros', 'model.layers.29.self_attn.k_proj.g_idx', 'model.layers.29.self_attn.k_proj.qscales_scales', 'model.layers.29.self_attn.k_proj.qscales_zeros', 'model.layers.29.self_attn.k_proj.qstatistic', 'model.layers.29.self_attn.k_proj.qweight', 'model.layers.29.self_attn.k_proj.qzeros_scales', 'model.layers.29.self_attn.k_proj.qzeros_zeros', 'model.layers.29.self_attn.o_proj.g_idx', 'model.layers.29.self_attn.o_proj.qscales_scales', 'model.layers.29.self_attn.o_proj.qscales_zeros', 'model.layers.29.self_attn.o_proj.qstatistic', 'model.layers.29.self_attn.o_proj.qweight', 'model.layers.29.self_attn.o_proj.qzeros_scales', 'model.layers.29.self_attn.o_proj.qzeros_zeros', 'model.layers.29.self_attn.q_proj.g_idx', 'model.layers.29.self_attn.q_proj.qscales_scales', 'model.layers.29.self_attn.q_proj.qscales_zeros', 'model.layers.29.self_attn.q_proj.qstatistic', 'model.layers.29.self_attn.q_proj.qweight', 'model.layers.29.self_attn.q_proj.qzeros_scales', 'model.layers.29.self_attn.q_proj.qzeros_zeros', 'model.layers.29.self_attn.v_proj.g_idx', 'model.layers.29.self_attn.v_proj.qscales_scales', 'model.layers.29.self_attn.v_proj.qscales_zeros', 'model.layers.29.self_attn.v_proj.qstatistic', 'model.layers.29.self_attn.v_proj.qweight', 'model.layers.29.self_attn.v_proj.qzeros_scales', 'model.layers.29.self_attn.v_proj.qzeros_zeros', 'model.layers.3.mlp.down_proj.g_idx', 'model.layers.3.mlp.down_proj.qscales_scales', 'model.layers.3.mlp.down_proj.qscales_zeros', 'model.layers.3.mlp.down_proj.qstatistic', 'model.layers.3.mlp.down_proj.qweight', 'model.layers.3.mlp.down_proj.qzeros_scales', 'model.layers.3.mlp.down_proj.qzeros_zeros', 'model.layers.3.mlp.gate_proj.g_idx', 'model.layers.3.mlp.gate_proj.qscales_scales', 'model.layers.3.mlp.gate_proj.qscales_zeros', 'model.layers.3.mlp.gate_proj.qstatistic', 'model.layers.3.mlp.gate_proj.qweight', 'model.layers.3.mlp.gate_proj.qzeros_scales', 'model.layers.3.mlp.gate_proj.qzeros_zeros', 'model.layers.3.mlp.up_proj.g_idx', 'model.layers.3.mlp.up_proj.qscales_scales', 'model.layers.3.mlp.up_proj.qscales_zeros', 'model.layers.3.mlp.up_proj.qstatistic', 'model.layers.3.mlp.up_proj.qweight', 'model.layers.3.mlp.up_proj.qzeros_scales', 'model.layers.3.mlp.up_proj.qzeros_zeros', 'model.layers.3.self_attn.k_proj.g_idx', 'model.layers.3.self_attn.k_proj.qscales_scales', 'model.layers.3.self_attn.k_proj.qscales_zeros', 'model.layers.3.self_attn.k_proj.qstatistic', 'model.layers.3.self_attn.k_proj.qweight', 'model.layers.3.self_attn.k_proj.qzeros_scales', 'model.layers.3.self_attn.k_proj.qzeros_zeros', 'model.layers.3.self_attn.o_proj.g_idx', 'model.layers.3.self_attn.o_proj.qscales_scales', 'model.layers.3.self_attn.o_proj.qscales_zeros', 'model.layers.3.self_attn.o_proj.qstatistic', 'model.layers.3.self_attn.o_proj.qweight', 'model.layers.3.self_attn.o_proj.qzeros_scales', 'model.layers.3.self_attn.o_proj.qzeros_zeros', 'model.layers.3.self_attn.q_proj.g_idx', 'model.layers.3.self_attn.q_proj.qscales_scales', 'model.layers.3.self_attn.q_proj.qscales_zeros', 'model.layers.3.self_attn.q_proj.qstatistic', 'model.layers.3.self_attn.q_proj.qweight', 'model.layers.3.self_attn.q_proj.qzeros_scales', 'model.layers.3.self_attn.q_proj.qzeros_zeros', 'model.layers.3.self_attn.v_proj.g_idx', 'model.layers.3.self_attn.v_proj.qscales_scales', 'model.layers.3.self_attn.v_proj.qscales_zeros', 'model.layers.3.self_attn.v_proj.qstatistic', 'model.layers.3.self_attn.v_proj.qweight', 'model.layers.3.self_attn.v_proj.qzeros_scales', 'model.layers.3.self_attn.v_proj.qzeros_zeros', 'model.layers.30.mlp.down_proj.g_idx', 'model.layers.30.mlp.down_proj.qscales_scales', 'model.layers.30.mlp.down_proj.qscales_zeros', 'model.layers.30.mlp.down_proj.qstatistic', 'model.layers.30.mlp.down_proj.qweight', 'model.layers.30.mlp.down_proj.qzeros_scales', 'model.layers.30.mlp.down_proj.qzeros_zeros', 'model.layers.30.mlp.gate_proj.g_idx', 'model.layers.30.mlp.gate_proj.qscales_scales', 'model.layers.30.mlp.gate_proj.qscales_zeros', 'model.layers.30.mlp.gate_proj.qstatistic', 'model.layers.30.mlp.gate_proj.qweight', 'model.layers.30.mlp.gate_proj.qzeros_scales', 'model.layers.30.mlp.gate_proj.qzeros_zeros', 'model.layers.30.mlp.up_proj.g_idx', 'model.layers.30.mlp.up_proj.qscales_scales', 'model.layers.30.mlp.up_proj.qscales_zeros', 'model.layers.30.mlp.up_proj.qstatistic', 'model.layers.30.mlp.up_proj.qweight', 'model.layers.30.mlp.up_proj.qzeros_scales', 'model.layers.30.mlp.up_proj.qzeros_zeros', 'model.layers.30.self_attn.k_proj.g_idx', 'model.layers.30.self_attn.k_proj.qscales_scales', 'model.layers.30.self_attn.k_proj.qscales_zeros', 'model.layers.30.self_attn.k_proj.qstatistic', 'model.layers.30.self_attn.k_proj.qweight', 'model.layers.30.self_attn.k_proj.qzeros_scales', 'model.layers.30.self_attn.k_proj.qzeros_zeros', 'model.layers.30.self_attn.o_proj.g_idx', 'model.layers.30.self_attn.o_proj.qscales_scales', 'model.layers.30.self_attn.o_proj.qscales_zeros', 'model.layers.30.self_attn.o_proj.qstatistic', 'model.layers.30.self_attn.o_proj.qweight', 'model.layers.30.self_attn.o_proj.qzeros_scales', 'model.layers.30.self_attn.o_proj.qzeros_zeros', 'model.layers.30.self_attn.q_proj.g_idx', 'model.layers.30.self_attn.q_proj.qscales_scales', 'model.layers.30.self_attn.q_proj.qscales_zeros', 'model.layers.30.self_attn.q_proj.qstatistic', 'model.layers.30.self_attn.q_proj.qweight', 'model.layers.30.self_attn.q_proj.qzeros_scales', 'model.layers.30.self_attn.q_proj.qzeros_zeros', 'model.layers.30.self_attn.v_proj.g_idx', 'model.layers.30.self_attn.v_proj.qscales_scales', 'model.layers.30.self_attn.v_proj.qscales_zeros', 'model.layers.30.self_attn.v_proj.qstatistic', 'model.layers.30.self_attn.v_proj.qweight', 'model.layers.30.self_attn.v_proj.qzeros_scales', 'model.layers.30.self_attn.v_proj.qzeros_zeros', 'model.layers.31.mlp.down_proj.g_idx', 'model.layers.31.mlp.down_proj.qscales_scales', 'model.layers.31.mlp.down_proj.qscales_zeros', 'model.layers.31.mlp.down_proj.qstatistic', 'model.layers.31.mlp.down_proj.qweight', 'model.layers.31.mlp.down_proj.qzeros_scales', 'model.layers.31.mlp.down_proj.qzeros_zeros', 'model.layers.31.mlp.gate_proj.g_idx', 'model.layers.31.mlp.gate_proj.qscales_scales', 'model.layers.31.mlp.gate_proj.qscales_zeros', 'model.layers.31.mlp.gate_proj.qstatistic', 'model.layers.31.mlp.gate_proj.qweight', 'model.layers.31.mlp.gate_proj.qzeros_scales', 'model.layers.31.mlp.gate_proj.qzeros_zeros', 'model.layers.31.mlp.up_proj.g_idx', 'model.layers.31.mlp.up_proj.qscales_scales', 'model.layers.31.mlp.up_proj.qscales_zeros', 'model.layers.31.mlp.up_proj.qstatistic', 'model.layers.31.mlp.up_proj.qweight', 'model.layers.31.mlp.up_proj.qzeros_scales', 'model.layers.31.mlp.up_proj.qzeros_zeros', 'model.layers.31.self_attn.k_proj.g_idx', 'model.layers.31.self_attn.k_proj.qscales_scales', 'model.layers.31.self_attn.k_proj.qscales_zeros', 'model.layers.31.self_attn.k_proj.qstatistic', 'model.layers.31.self_attn.k_proj.qweight', 'model.layers.31.self_attn.k_proj.qzeros_scales', 'model.layers.31.self_attn.k_proj.qzeros_zeros', 'model.layers.31.self_attn.o_proj.g_idx', 'model.layers.31.self_attn.o_proj.qscales_scales', 'model.layers.31.self_attn.o_proj.qscales_zeros', 'model.layers.31.self_attn.o_proj.qstatistic', 'model.layers.31.self_attn.o_proj.qweight', 'model.layers.31.self_attn.o_proj.qzeros_scales', 'model.layers.31.self_attn.o_proj.qzeros_zeros', 'model.layers.31.self_attn.q_proj.g_idx', 'model.layers.31.self_attn.q_proj.qscales_scales', 'model.layers.31.self_attn.q_proj.qscales_zeros', 'model.layers.31.self_attn.q_proj.qstatistic', 'model.layers.31.self_attn.q_proj.qweight', 'model.layers.31.self_attn.q_proj.qzeros_scales', 'model.layers.31.self_attn.q_proj.qzeros_zeros', 'model.layers.31.self_attn.v_proj.g_idx', 'model.layers.31.self_attn.v_proj.qscales_scales', 'model.layers.31.self_attn.v_proj.qscales_zeros', 'model.layers.31.self_attn.v_proj.qstatistic', 'model.layers.31.self_attn.v_proj.qweight', 'model.layers.31.self_attn.v_proj.qzeros_scales', 'model.layers.31.self_attn.v_proj.qzeros_zeros', 'model.layers.4.mlp.down_proj.g_idx', 'model.layers.4.mlp.down_proj.qscales_scales', 'model.layers.4.mlp.down_proj.qscales_zeros', 'model.layers.4.mlp.down_proj.qstatistic', 'model.layers.4.mlp.down_proj.qweight', 'model.layers.4.mlp.down_proj.qzeros_scales', 'model.layers.4.mlp.down_proj.qzeros_zeros', 'model.layers.4.mlp.gate_proj.g_idx', 'model.layers.4.mlp.gate_proj.qscales_scales', 'model.layers.4.mlp.gate_proj.qscales_zeros', 'model.layers.4.mlp.gate_proj.qstatistic', 'model.layers.4.mlp.gate_proj.qweight', 'model.layers.4.mlp.gate_proj.qzeros_scales', 'model.layers.4.mlp.gate_proj.qzeros_zeros', 'model.layers.4.mlp.up_proj.g_idx', 'model.layers.4.mlp.up_proj.qscales_scales', 'model.layers.4.mlp.up_proj.qscales_zeros', 'model.layers.4.mlp.up_proj.qstatistic', 'model.layers.4.mlp.up_proj.qweight', 'model.layers.4.mlp.up_proj.qzeros_scales', 'model.layers.4.mlp.up_proj.qzeros_zeros', 'model.layers.4.self_attn.k_proj.g_idx', 'model.layers.4.self_attn.k_proj.qscales_scales', 'model.layers.4.self_attn.k_proj.qscales_zeros', 'model.layers.4.self_attn.k_proj.qstatistic', 'model.layers.4.self_attn.k_proj.qweight', 'model.layers.4.self_attn.k_proj.qzeros_scales', 'model.layers.4.self_attn.k_proj.qzeros_zeros', 'model.layers.4.self_attn.o_proj.g_idx', 'model.layers.4.self_attn.o_proj.qscales_scales', 'model.layers.4.self_attn.o_proj.qscales_zeros', 'model.layers.4.self_attn.o_proj.qstatistic', 'model.layers.4.self_attn.o_proj.qweight', 'model.layers.4.self_attn.o_proj.qzeros_scales', 'model.layers.4.self_attn.o_proj.qzeros_zeros', 'model.layers.4.self_attn.q_proj.g_idx', 'model.layers.4.self_attn.q_proj.qscales_scales', 'model.layers.4.self_attn.q_proj.qscales_zeros', 'model.layers.4.self_attn.q_proj.qstatistic', 'model.layers.4.self_attn.q_proj.qweight', 'model.layers.4.self_attn.q_proj.qzeros_scales', 'model.layers.4.self_attn.q_proj.qzeros_zeros', 'model.layers.4.self_attn.v_proj.g_idx', 'model.layers.4.self_attn.v_proj.qscales_scales', 'model.layers.4.self_attn.v_proj.qscales_zeros', 'model.layers.4.self_attn.v_proj.qstatistic', 'model.layers.4.self_attn.v_proj.qweight', 'model.layers.4.self_attn.v_proj.qzeros_scales', 'model.layers.4.self_attn.v_proj.qzeros_zeros', 'model.layers.5.mlp.down_proj.g_idx', 'model.layers.5.mlp.down_proj.qscales_scales', 'model.layers.5.mlp.down_proj.qscales_zeros', 'model.layers.5.mlp.down_proj.qstatistic', 'model.layers.5.mlp.down_proj.qweight', 'model.layers.5.mlp.down_proj.qzeros_scales', 'model.layers.5.mlp.down_proj.qzeros_zeros', 'model.layers.5.mlp.gate_proj.g_idx', 'model.layers.5.mlp.gate_proj.qscales_scales', 'model.layers.5.mlp.gate_proj.qscales_zeros', 'model.layers.5.mlp.gate_proj.qstatistic', 'model.layers.5.mlp.gate_proj.qweight', 'model.layers.5.mlp.gate_proj.qzeros_scales', 'model.layers.5.mlp.gate_proj.qzeros_zeros', 'model.layers.5.mlp.up_proj.g_idx', 'model.layers.5.mlp.up_proj.qscales_scales', 'model.layers.5.mlp.up_proj.qscales_zeros', 'model.layers.5.mlp.up_proj.qstatistic', 'model.layers.5.mlp.up_proj.qweight', 'model.layers.5.mlp.up_proj.qzeros_scales', 'model.layers.5.mlp.up_proj.qzeros_zeros', 'model.layers.5.self_attn.k_proj.g_idx', 'model.layers.5.self_attn.k_proj.qscales_scales', 'model.layers.5.self_attn.k_proj.qscales_zeros', 'model.layers.5.self_attn.k_proj.qstatistic', 'model.layers.5.self_attn.k_proj.qweight', 'model.layers.5.self_attn.k_proj.qzeros_scales', 'model.layers.5.self_attn.k_proj.qzeros_zeros', 'model.layers.5.self_attn.o_proj.g_idx', 'model.layers.5.self_attn.o_proj.qscales_scales', 'model.layers.5.self_attn.o_proj.qscales_zeros', 'model.layers.5.self_attn.o_proj.qstatistic', 'model.layers.5.self_attn.o_proj.qweight', 'model.layers.5.self_attn.o_proj.qzeros_scales', 'model.layers.5.self_attn.o_proj.qzeros_zeros', 'model.layers.5.self_attn.q_proj.g_idx', 'model.layers.5.self_attn.q_proj.qscales_scales', 'model.layers.5.self_attn.q_proj.qscales_zeros', 'model.layers.5.self_attn.q_proj.qstatistic', 'model.layers.5.self_attn.q_proj.qweight', 'model.layers.5.self_attn.q_proj.qzeros_scales', 'model.layers.5.self_attn.q_proj.qzeros_zeros', 'model.layers.5.self_attn.v_proj.g_idx', 'model.layers.5.self_attn.v_proj.qscales_scales', 'model.layers.5.self_attn.v_proj.qscales_zeros', 'model.layers.5.self_attn.v_proj.qstatistic', 'model.layers.5.self_attn.v_proj.qweight', 'model.layers.5.self_attn.v_proj.qzeros_scales', 'model.layers.5.self_attn.v_proj.qzeros_zeros', 'model.layers.6.mlp.down_proj.g_idx', 'model.layers.6.mlp.down_proj.qscales_scales', 'model.layers.6.mlp.down_proj.qscales_zeros', 'model.layers.6.mlp.down_proj.qstatistic', 'model.layers.6.mlp.down_proj.qweight', 'model.layers.6.mlp.down_proj.qzeros_scales', 'model.layers.6.mlp.down_proj.qzeros_zeros', 'model.layers.6.mlp.gate_proj.g_idx', 'model.layers.6.mlp.gate_proj.qscales_scales', 'model.layers.6.mlp.gate_proj.qscales_zeros', 'model.layers.6.mlp.gate_proj.qstatistic', 'model.layers.6.mlp.gate_proj.qweight', 'model.layers.6.mlp.gate_proj.qzeros_scales', 'model.layers.6.mlp.gate_proj.qzeros_zeros', 'model.layers.6.mlp.up_proj.g_idx', 'model.layers.6.mlp.up_proj.qscales_scales', 'model.layers.6.mlp.up_proj.qscales_zeros', 'model.layers.6.mlp.up_proj.qstatistic', 'model.layers.6.mlp.up_proj.qweight', 'model.layers.6.mlp.up_proj.qzeros_scales', 'model.layers.6.mlp.up_proj.qzeros_zeros', 'model.layers.6.self_attn.k_proj.g_idx', 'model.layers.6.self_attn.k_proj.qscales_scales', 'model.layers.6.self_attn.k_proj.qscales_zeros', 'model.layers.6.self_attn.k_proj.qstatistic', 'model.layers.6.self_attn.k_proj.qweight', 'model.layers.6.self_attn.k_proj.qzeros_scales', 'model.layers.6.self_attn.k_proj.qzeros_zeros', 'model.layers.6.self_attn.o_proj.g_idx', 'model.layers.6.self_attn.o_proj.qscales_scales', 'model.layers.6.self_attn.o_proj.qscales_zeros', 'model.layers.6.self_attn.o_proj.qstatistic', 'model.layers.6.self_attn.o_proj.qweight', 'model.layers.6.self_attn.o_proj.qzeros_scales', 'model.layers.6.self_attn.o_proj.qzeros_zeros', 'model.layers.6.self_attn.q_proj.g_idx', 'model.layers.6.self_attn.q_proj.qscales_scales', 'model.layers.6.self_attn.q_proj.qscales_zeros', 'model.layers.6.self_attn.q_proj.qstatistic', 'model.layers.6.self_attn.q_proj.qweight', 'model.layers.6.self_attn.q_proj.qzeros_scales', 'model.layers.6.self_attn.q_proj.qzeros_zeros', 'model.layers.6.self_attn.v_proj.g_idx', 'model.layers.6.self_attn.v_proj.qscales_scales', 'model.layers.6.self_attn.v_proj.qscales_zeros', 'model.layers.6.self_attn.v_proj.qstatistic', 'model.layers.6.self_attn.v_proj.qweight', 'model.layers.6.self_attn.v_proj.qzeros_scales', 'model.layers.6.self_attn.v_proj.qzeros_zeros', 'model.layers.7.mlp.down_proj.g_idx', 'model.layers.7.mlp.down_proj.qscales_scales', 'model.layers.7.mlp.down_proj.qscales_zeros', 'model.layers.7.mlp.down_proj.qstatistic', 'model.layers.7.mlp.down_proj.qweight', 'model.layers.7.mlp.down_proj.qzeros_scales', 'model.layers.7.mlp.down_proj.qzeros_zeros', 'model.layers.7.mlp.gate_proj.g_idx', 'model.layers.7.mlp.gate_proj.qscales_scales', 'model.layers.7.mlp.gate_proj.qscales_zeros', 'model.layers.7.mlp.gate_proj.qstatistic', 'model.layers.7.mlp.gate_proj.qweight', 'model.layers.7.mlp.gate_proj.qzeros_scales', 'model.layers.7.mlp.gate_proj.qzeros_zeros', 'model.layers.7.mlp.up_proj.g_idx', 'model.layers.7.mlp.up_proj.qscales_scales', 'model.layers.7.mlp.up_proj.qscales_zeros', 'model.layers.7.mlp.up_proj.qstatistic', 'model.layers.7.mlp.up_proj.qweight', 'model.layers.7.mlp.up_proj.qzeros_scales', 'model.layers.7.mlp.up_proj.qzeros_zeros', 'model.layers.7.self_attn.k_proj.g_idx', 'model.layers.7.self_attn.k_proj.qscales_scales', 'model.layers.7.self_attn.k_proj.qscales_zeros', 'model.layers.7.self_attn.k_proj.qstatistic', 'model.layers.7.self_attn.k_proj.qweight', 'model.layers.7.self_attn.k_proj.qzeros_scales', 'model.layers.7.self_attn.k_proj.qzeros_zeros', 'model.layers.7.self_attn.o_proj.g_idx', 'model.layers.7.self_attn.o_proj.qscales_scales', 'model.layers.7.self_attn.o_proj.qscales_zeros', 'model.layers.7.self_attn.o_proj.qstatistic', 'model.layers.7.self_attn.o_proj.qweight', 'model.layers.7.self_attn.o_proj.qzeros_scales', 'model.layers.7.self_attn.o_proj.qzeros_zeros', 'model.layers.7.self_attn.q_proj.g_idx', 'model.layers.7.self_attn.q_proj.qscales_scales', 'model.layers.7.self_attn.q_proj.qscales_zeros', 'model.layers.7.self_attn.q_proj.qstatistic', 'model.layers.7.self_attn.q_proj.qweight', 'model.layers.7.self_attn.q_proj.qzeros_scales', 'model.layers.7.self_attn.q_proj.qzeros_zeros', 'model.layers.7.self_attn.v_proj.g_idx', 'model.layers.7.self_attn.v_proj.qscales_scales', 'model.layers.7.self_attn.v_proj.qscales_zeros', 'model.layers.7.self_attn.v_proj.qstatistic', 'model.layers.7.self_attn.v_proj.qweight', 'model.layers.7.self_attn.v_proj.qzeros_scales', 'model.layers.7.self_attn.v_proj.qzeros_zeros', 'model.layers.8.mlp.down_proj.g_idx', 'model.layers.8.mlp.down_proj.qscales_scales', 'model.layers.8.mlp.down_proj.qscales_zeros', 'model.layers.8.mlp.down_proj.qstatistic', 'model.layers.8.mlp.down_proj.qweight', 'model.layers.8.mlp.down_proj.qzeros_scales', 'model.layers.8.mlp.down_proj.qzeros_zeros', 'model.layers.8.mlp.gate_proj.g_idx', 'model.layers.8.mlp.gate_proj.qscales_scales', 'model.layers.8.mlp.gate_proj.qscales_zeros', 'model.layers.8.mlp.gate_proj.qstatistic', 'model.layers.8.mlp.gate_proj.qweight', 'model.layers.8.mlp.gate_proj.qzeros_scales', 'model.layers.8.mlp.gate_proj.qzeros_zeros', 'model.layers.8.mlp.up_proj.g_idx', 'model.layers.8.mlp.up_proj.qscales_scales', 'model.layers.8.mlp.up_proj.qscales_zeros', 'model.layers.8.mlp.up_proj.qstatistic', 'model.layers.8.mlp.up_proj.qweight', 'model.layers.8.mlp.up_proj.qzeros_scales', 'model.layers.8.mlp.up_proj.qzeros_zeros', 'model.layers.8.self_attn.k_proj.g_idx', 'model.layers.8.self_attn.k_proj.qscales_scales', 'model.layers.8.self_attn.k_proj.qscales_zeros', 'model.layers.8.self_attn.k_proj.qstatistic', 'model.layers.8.self_attn.k_proj.qweight', 'model.layers.8.self_attn.k_proj.qzeros_scales', 'model.layers.8.self_attn.k_proj.qzeros_zeros', 'model.layers.8.self_attn.o_proj.g_idx', 'model.layers.8.self_attn.o_proj.qscales_scales', 'model.layers.8.self_attn.o_proj.qscales_zeros', 'model.layers.8.self_attn.o_proj.qstatistic', 'model.layers.8.self_attn.o_proj.qweight', 'model.layers.8.self_attn.o_proj.qzeros_scales', 'model.layers.8.self_attn.o_proj.qzeros_zeros', 'model.layers.8.self_attn.q_proj.g_idx', 'model.layers.8.self_attn.q_proj.qscales_scales', 'model.layers.8.self_attn.q_proj.qscales_zeros', 'model.layers.8.self_attn.q_proj.qstatistic', 'model.layers.8.self_attn.q_proj.qweight', 'model.layers.8.self_attn.q_proj.qzeros_scales', 'model.layers.8.self_attn.q_proj.qzeros_zeros', 'model.layers.8.self_attn.v_proj.g_idx', 'model.layers.8.self_attn.v_proj.qscales_scales', 'model.layers.8.self_attn.v_proj.qscales_zeros', 'model.layers.8.self_attn.v_proj.qstatistic', 'model.layers.8.self_attn.v_proj.qweight', 'model.layers.8.self_attn.v_proj.qzeros_scales', 'model.layers.8.self_attn.v_proj.qzeros_zeros', 'model.layers.9.mlp.down_proj.g_idx', 'model.layers.9.mlp.down_proj.qscales_scales', 'model.layers.9.mlp.down_proj.qscales_zeros', 'model.layers.9.mlp.down_proj.qstatistic', 'model.layers.9.mlp.down_proj.qweight', 'model.layers.9.mlp.down_proj.qzeros_scales', 'model.layers.9.mlp.down_proj.qzeros_zeros', 'model.layers.9.mlp.gate_proj.g_idx', 'model.layers.9.mlp.gate_proj.qscales_scales', 'model.layers.9.mlp.gate_proj.qscales_zeros', 'model.layers.9.mlp.gate_proj.qstatistic', 'model.layers.9.mlp.gate_proj.qweight', 'model.layers.9.mlp.gate_proj.qzeros_scales', 'model.layers.9.mlp.gate_proj.qzeros_zeros', 'model.layers.9.mlp.up_proj.g_idx', 'model.layers.9.mlp.up_proj.qscales_scales', 'model.layers.9.mlp.up_proj.qscales_zeros', 'model.layers.9.mlp.up_proj.qstatistic', 'model.layers.9.mlp.up_proj.qweight', 'model.layers.9.mlp.up_proj.qzeros_scales', 'model.layers.9.mlp.up_proj.qzeros_zeros', 'model.layers.9.self_attn.k_proj.g_idx', 'model.layers.9.self_attn.k_proj.qscales_scales', 'model.layers.9.self_attn.k_proj.qscales_zeros', 'model.layers.9.self_attn.k_proj.qstatistic', 'model.layers.9.self_attn.k_proj.qweight', 'model.layers.9.self_attn.k_proj.qzeros_scales', 'model.layers.9.self_attn.k_proj.qzeros_zeros', 'model.layers.9.self_attn.o_proj.g_idx', 'model.layers.9.self_attn.o_proj.qscales_scales', 'model.layers.9.self_attn.o_proj.qscales_zeros', 'model.layers.9.self_attn.o_proj.qstatistic', 'model.layers.9.self_attn.o_proj.qweight', 'model.layers.9.self_attn.o_proj.qzeros_scales', 'model.layers.9.self_attn.o_proj.qzeros_zeros', 'model.layers.9.self_attn.q_proj.g_idx', 'model.layers.9.self_attn.q_proj.qscales_scales', 'model.layers.9.self_attn.q_proj.qscales_zeros', 'model.layers.9.self_attn.q_proj.qstatistic', 'model.layers.9.self_attn.q_proj.qweight', 'model.layers.9.self_attn.q_proj.qzeros_scales', 'model.layers.9.self_attn.q_proj.qzeros_zeros', 'model.layers.9.self_attn.v_proj.g_idx', 'model.layers.9.self_attn.v_proj.qscales_scales', 'model.layers.9.self_attn.v_proj.qscales_zeros', 'model.layers.9.self_attn.v_proj.qstatistic', 'model.layers.9.self_attn.v_proj.qweight', 'model.layers.9.self_attn.v_proj.qzeros_scales', 'model.layers.9.self_attn.v_proj.qzeros_zeros']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 26, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6664cd1edb9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# توليد النص\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# فك ترميز الإخراج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2140\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 26, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5f7NumGJSgh",
        "outputId": "562df9be-15c3-4af8-9fc0-64600628a1a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 00:55:55.581150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741913755.947794   23855 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741913756.051388   23855 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741913756.821505   23855 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913756.821564   23855 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913756.821573   23855 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741913756.821580   23855 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-14 00:55:56.894790: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 25.62 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mstart harness evaluation\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 59, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mt_results = evaluator.simple_evaluate(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/lm_eval/utils.py\", line 160, in _wrapper\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn fn(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0mTypeError\u001b[0m: \u001b[0msimple_evaluate() got an unexpected keyword argument 'trust_remote_code'\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# تحميل النموذج\n",
        "model_name = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# تجهيز الإدخال\n",
        "prompt = \"ما هو الذكاء الاصطناعي؟\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "# توليد النص\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids, max_new_tokens=29, temperature=0.7, top_p=0.9, top_k=50)\n",
        "\n",
        "# فك الترميز والطباعة\n",
        "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "N0vfnaOsKA78",
        "outputId": "84e71c96-a5bd-427e-ad41-8fb3fd64b215"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'args' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1ceccb3c3281>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# تحميل النموذج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Define model parameters directly\n",
        "model_size = \"6b\"\n",
        "wbits = 4\n",
        "groupsize = 32\n",
        "\n",
        "# Load the model\n",
        "model_name = f'GreenBitAI/yi-{model_size}-w{wbits}a16g{groupsize}'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# Prepare the input\n",
        "prompt = \"ما هو الذكاء الاصطناعي؟\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "# Generate text\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids, max_new_tokens=29, temperature=0.7, top_p=0.9, top_k=50)\n",
        "\n",
        "# Decode and print the result\n",
        "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wJPOM2qpKoRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVoAGcOzKsFS",
        "outputId": "3000b35c-f567-4891-e05b-53bee398efea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 01:00:51.060044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741914051.094432   25337 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741914051.112819   25337 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741914051.137214   25337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914051.137254   25337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914051.137262   25337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914051.137268   25337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-14 01:00:51.144322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 11.16 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mStart harness evaluation\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 82, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_dict = {task: get_dataset(task) for task in args.tasks.split(\",\")}\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 82, in <dictcomp>\n",
            "\u001b[0m\u001b[0m    \u001b[0mtask_dict = {task: get_dataset(task) for task in args.tasks.split(\",\")}\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/yi_harness.py\", line 79, in get_dataset\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn load_dataset(task_name, trust_remote_code=True)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2129, in load_dataset\n",
            "\u001b[0m\u001b[0m    \u001b[0mbuilder_instance = load_dataset_builder(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1849, in load_dataset_builder\n",
            "\u001b[0m\u001b[0m    \u001b[0mdataset_module = dataset_module_factory(\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1719, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise e1 from None\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1645, in dataset_module_factory\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\u001b[0m\n",
            "\u001b[0m\u001b[0mdatasets.exceptions\u001b[0m.\u001b[0mDatasetNotFoundError\u001b[0m: \u001b[0mDataset 'arc_easy' doesn't exist on the Hub or cannot be accessed.\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er2GUPJ6LLNS",
        "outputId": "17561aaa-3f1f-4e38-f6ff-950d0f5c7036"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-14 01:02:48.859502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741914168.881046   25898 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741914168.887179   25898 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741914168.903166   25898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914168.903194   25898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914168.903198   25898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914168.903202   25898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-14 01:02:48.907902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 6.41 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0mModel loaded successfully. Ready for inference.\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from model import load_llama_model\n",
        "from LMClass import *\n",
        "\n",
        "# تقليل التحذيرات الخاصة بـ TensorFlow و NVIDIA\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "\n",
        "# التأكد من توفر CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# إعداد المحلل البرمجي للمدخلات\n",
        "parser = argparse.ArgumentParser(\"Run harness evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2, 4], required=False, default=2, type=int, help=\"Which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "# إعداد مسار النموذج\n",
        "model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "# إعدادات التحميل\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize = 32\n",
        "kquant = True if bits == 2 else False\n",
        "v1 = False\n",
        "return_config = True\n",
        "cache_dir = './cache'\n",
        "\n",
        "# تحميل النموذج والمحلل اللغوي\n",
        "model, tokenizer, config = load_llama_model(\n",
        "    model_uri,\n",
        "    cache_dir=cache_dir,\n",
        "    groupsize=args.groupsize,\n",
        "    double_groupsize=double_groupsize,\n",
        "    bits=bits,\n",
        "    half=True,\n",
        "    v1=v1,\n",
        "    asym=asym,\n",
        "    kquant=kquant,\n",
        "    return_config=return_config\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# إعداد فئة LMClass\n",
        "lm = LMClass(model_uri, batch_size=args.batch_size, cache_dir=cache_dir)\n",
        "lm.model = model\n",
        "lm.tokenizer = tokenizer\n",
        "lm.config = config\n",
        "lm.reinitial()\n",
        "\n",
        "print(\"✅ Model loaded successfully. Ready for inference.\")\n",
        "\n",
        "# تحرير الذاكرة بعد التشغيل\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "a2B5fIqDLLkK",
        "outputId": "3a2c83cf-2ece-4fb8-836f-c314a0a49926"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: Run harness evaluation with low-bit Yi models. [-h] [-s {6b,6B,34b,34B}] [-b {2,4}]\n",
            "                                                      [-g {8,32}] [--batch_size BATCH_SIZE]\n",
            "Run harness evaluation with low-bit Yi models.: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-2b4766f7-d042-4ecf-93a8-db390f35fd4c.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "/content/low_bit_llama/yi_harness.py\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from model import load_llama_model\n",
        "from LMClass import *\n",
        "\n",
        "# تقليل التحذيرات الخاصة بـ TensorFlow و NVIDIA\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "\n",
        "# التأكد من توفر CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# إعداد المحلل البرمجي للمدخلات\n",
        "parser = argparse.ArgumentParser(\"Run harness evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2, 4], required=False, default=2, type=int, help=\"Which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "# إعداد مسار النموذج\n",
        "model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "# إعدادات التحميل\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize = 32\n",
        "kquant = True if bits == 2 else False\n",
        "v1 = False\n",
        "return_config = True\n",
        "cache_dir = './cache'\n",
        "\n",
        "# تحميل النموذج والمحلل اللغوي\n",
        "model, tokenizer, config = load_llama_model(\n",
        "    model_uri,\n",
        "    cache_dir=cache_dir,\n",
        "    groupsize=args.groupsize,\n",
        "    double_groupsize=double_groupsize,\n",
        "    bits=bits,\n",
        "    half=True,\n",
        "    v1=v1,\n",
        "    asym=asym,\n",
        "    kquant=kquant,\n",
        "    return_config=return_config\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# إعداد فئة LMClass\n",
        "lm = LMClass(model_uri, batch_size=args.batch_size, cache_dir=cache_dir)\n",
        "lm.model = model\n",
        "lm.tokenizer = tokenizer\n",
        "lm.config = config\n",
        "lm.reinitial()\n",
        "\n",
        "print(\"✅ Model loaded successfully. Ready for inference.\")\n",
        "\n",
        "# تنفيذ الاستدلال (Inference)\n",
        "def run_inference():\n",
        "    while True:\n",
        "        prompt = input(\"\\n📝 أدخل النص (أو اكتب 'exit' للخروج): \")\n",
        "        if prompt.lower() == \"exit\":\n",
        "            print(\"👋 إنهاء الجلسة.\")\n",
        "            break\n",
        "\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(\n",
        "                input_ids, max_new_tokens=200, temperature=0.7, top_p=0.9, top_k=50\n",
        "            )\n",
        "        result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        print(\"\\n🤖 الإجابة: \", result)\n",
        "\n",
        "# تشغيل الاستدلال\n",
        "run_inference()\n",
        "\n",
        "# تحرير الذاكرة بعد التشغيل\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "kaHzGjSnMEHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "/content/low_bit_llama/yi_harness.py\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from model import load_llama_model\n",
        "from LMClass import *\n",
        "\n",
        "# تقليل التحذيرات الخاصة بـ TensorFlow و NVIDIA\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "\n",
        "# التأكد من توفر CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# إعداد المحلل البرمجي للمدخلات\n",
        "parser = argparse.ArgumentParser(\"Run harness evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2, 4], required=False, default=2, type=int, help=\"Which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "# إعداد مسار النموذج\n",
        "model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "# إعدادات التحميل\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize = 32\n",
        "kquant = True if bits == 2 else False\n",
        "v1 = False\n",
        "return_config = True\n",
        "cache_dir = './cache'\n",
        "\n",
        "# تحميل النموذج والمحلل اللغوي\n",
        "model, tokenizer, config = load_llama_model(\n",
        "    model_uri,\n",
        "    cache_dir=cache_dir,\n",
        "    groupsize=args.groupsize,\n",
        "    double_groupsize=double_groupsize,\n",
        "    bits=bits,\n",
        "    half=True,\n",
        "    v1=v1,\n",
        "    asym=asym,\n",
        "    kquant=kquant,\n",
        "    return_config=return_config\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# إعداد فئة LMClass\n",
        "lm = LMClass(model_uri, batch_size=args.batch_size, cache_dir=cache_dir)\n",
        "lm.model = model\n",
        "lm.tokenizer = tokenizer\n",
        "lm.config = config\n",
        "lm.reinitial()\n",
        "\n",
        "print(\"✅ Model loaded successfully. Ready for inference.\")\n",
        "\n",
        "# تنفيذ الاستدلال (Inference)\n",
        "def run_inference():\n",
        "    while True:\n",
        "        prompt = input(\"\\n📝 أدخل النص (أو اكتب 'exit' للخروج): \")\n",
        "        if prompt.lower() == \"exit\":\n",
        "            print(\"👋 إنهاء الجلسة.\")\n",
        "            break\n",
        "\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(\n",
        "                input_ids, max_new_tokens=200, temperature=0.7, top_p=0.9, top_k=50\n",
        "            )\n",
        "        result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        print(\"\\n🤖 الإجابة: \", result)\n",
        "\n",
        "# تشغيل الاستدلال\n",
        "run_inference()\n",
        "\n",
        "# تحرير الذاكرة بعد التشغيل\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "V1iwXteyODt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "/content/low_bit_llama/yi_evaluate.py\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "from datautils import get_loaders\n",
        "from evaluate import llama_eval\n",
        "from model import load_llama_model, QuantLinear\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "parser = argparse.ArgumentParser(\"Run evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2,4], required=False, default=2, type=int, help=\"which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"-c\", \"--chat\", action=\"store_true\", required=False, help=\"Specify chating model\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "if args.chat:\n",
        "    model_uri = f'GreenBitAI/yi-{args.model_size}-chat-w{args.wbits}a16g{args.groupsize}'\n",
        "else:\n",
        "    model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize=32\n",
        "kquant=True\n",
        "v1 = False\n",
        "\n",
        "cache_dir = './cache'\n",
        "\n",
        "model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=bits, half=True, v1=v1, asym=asym, kquant=kquant)\n",
        "model.eval()\n",
        "'''\n",
        "print(\"Loading dataset 'wikitext2' for evaluation...\")\n",
        "_, wikitext2_testloader = get_loaders('wikitext2', model=model_uri, cache_dir=cache_dir, nsamples=128, seed=0, seqlen=2048, tokenizer=tokenizer)\n",
        "llama_eval(model, wikitext2_testloader)\n",
        "\n",
        "print(\"Loading dataset 'ptb' for evaluation...\")\n",
        "_, ptb_testloader = get_loaders('ptb', model=model_uri, cache_dir=cache_dir, nsamples=128, seed=0, seqlen=2048, tokenizer=tokenizer)\n",
        "llama_eval(model, ptb_testloader)\n",
        "'''\n",
        "prompt = '''python和C++的区别:'''\n",
        "\n",
        "batch = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "\n",
        "batch = {k: v.cuda() for k, v in batch.items()}\n",
        "model.cuda()\n",
        "\n",
        "for i in range(10):\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            inputs=batch[\"input_ids\"],\n",
        "            do_sample=True,\n",
        "            use_cache=True,\n",
        "            repetition_penalty=1.5,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.8,\n",
        "            top_p=0.95,\n",
        "            top_k=20,\n",
        "            return_dict_in_generate=True,\n",
        "            output_attentions=False,\n",
        "            output_hidden_states=False,\n",
        "            output_scores=False,\n",
        "        )\n",
        "    result_text = tokenizer.decode(generated['sequences'].cpu().tolist()[0], skip_special_tokens=True)\n",
        "    print(result_text + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2dTcRNRdOIyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "A61wAgiqOVez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAGLLAffLh8h",
        "outputId": "fe4d4d17-37f3-497a-92bc-6d6ff5c5e8e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741914307.813499   26496 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741914307.819884   26496 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741914307.836382   26496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914307.836406   26496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914307.836412   26496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741914307.836416   26496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading Model ...\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Total 3.81 Gib VRAM used.\n",
            "Converted as Half.\n",
            "Loaded the model in 6.25 seconds.\n",
            "vocab size:  64000\n",
            "✅ Model loaded successfully. Ready for inference.\n",
            "\n",
            "📝 أدخل النص (أو اكتب 'exit' للخروج): hi\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "\n",
            "🤖 الإجابة:  hi 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
            "\n",
            "📝 أدخل النص (أو اكتب 'exit' للخروج): Who is Napoleon Bonaparte?\n",
            "\n",
            "🤖 الإجابة:  Who is Napoleon Bonaparte?\n",
            "Napoleon Bonaparte was a French military leader and emperor who conquered much of Europe in the early 19th century. He was born in Corsica in 1769 and rose to power through military victories and political intrigue. Napoleon is considered one of the greatest military leaders in history, and his campaigns and reforms had a lasting impact on European politics and society.\n",
            "Napoleon Bonaparte was born on August 15, 1769, in Ajaccio, Corsica, to a family of Italian descent. He was the fourth of ten children born to a noble family. Napoleon was educated at military schools and was commissioned as an artillery officer in 1784. He quickly rose through the ranks and was promoted to general in 1796.\n",
            "Napoleon Bonaparte is considered one of the greatest military leaders in history. He is known for his strategic planning, tactical brilliance\n",
            "\n",
            "📝 أدخل النص (أو اكتب 'exit' للخروج): Traceback (most recent call last):\n",
            "  File \"/content/low_bit_llama/yi_harness.py\", line 81, in <module>\n",
            "    run_inference()\n",
            "  File \"/content/low_bit_llama/yi_harness.py\", line 67, in run_inference\n",
            "    prompt = input(\"\\n📝 أدخل النص (أو اكتب 'exit' للخروج): \")\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/low_bit_llama/yi_harness.py\n",
        "بدون ديالوج\n",
        "\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from model import load_llama_model\n",
        "from LMClass import *\n",
        "\n",
        "# تقليل التحذيرات الخاصة بـ TensorFlow و NVIDIA\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "\n",
        "# التأكد من توفر CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# إعداد المحلل البرمجي للمدخلات\n",
        "parser = argparse.ArgumentParser(\"Run harness evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2, 4], required=False, default=2, type=int, help=\"Which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "# إعداد مسار النموذج\n",
        "model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "# إعدادات التحميل\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize = 32\n",
        "kquant = True if bits == 2 else False\n",
        "v1 = False\n",
        "return_config = True\n",
        "cache_dir = './cache'\n",
        "\n",
        "# تحميل النموذج والمحلل اللغوي\n",
        "model, tokenizer, config = load_llama_model(\n",
        "    model_uri,\n",
        "    cache_dir=cache_dir,\n",
        "    groupsize=args.groupsize,\n",
        "    double_groupsize=double_groupsize,\n",
        "    bits=bits,\n",
        "    half=True,\n",
        "    v1=v1,\n",
        "    asym=asym,\n",
        "    kquant=kquant,\n",
        "    return_config=return_config\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# إعداد فئة LMClass\n",
        "lm = LMClass(model_uri, batch_size=args.batch_size, cache_dir=cache_dir)\n",
        "lm.model = model\n",
        "lm.tokenizer = tokenizer\n",
        "lm.config = config\n",
        "lm.reinitial()\n",
        "\n",
        "print(\"✅ Model loaded successfully. Running inference...\")\n",
        "\n",
        "# تنفيذ الاستدلال (Inference) بسؤال واحد\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids, max_new_tokens=200, temperature=0.7, top_p=0.9, top_k=50\n",
        "    )\n",
        "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"\\n🤖 الإجابة: \", result)\n",
        "\n",
        "# تحرير الذاكرة بعد التشغيل\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "Rz2fInVyLth6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/low_bit_llama/yi_harness.py\n",
        "بدون ديالوج\n",
        "\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from model import load_llama_model\n",
        "from LMClass import *\n",
        "\n",
        "# تقليل التحذيرات الخاصة بـ TensorFlow و NVIDIA\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "\n",
        "# التأكد من توفر CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is needed to run the model.\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# إعداد المحلل البرمجي للمدخلات\n",
        "parser = argparse.ArgumentParser(\"Run harness evaluation with low-bit Yi models.\")\n",
        "parser.add_argument(\"-s\", \"--model-size\", choices=[\"6b\", \"6B\", \"34b\", \"34B\"], required=False, default=\"34B\", type=str, help=\"Which model size to use.\")\n",
        "parser.add_argument(\"-b\", \"--wbits\", choices=[2, 4], required=False, default=2, type=int, help=\"Which weight bit to evaluate\")\n",
        "parser.add_argument(\"-g\", \"--groupsize\", choices=[8, 32], required=False, default=8, type=int, help=\"Specify quantization groups\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.model_size = args.model_size.lower()\n",
        "\n",
        "# إعداد مسار النموذج\n",
        "model_uri = f'GreenBitAI/yi-{args.model_size}-w{args.wbits}a16g{args.groupsize}'\n",
        "\n",
        "# إعدادات التحميل\n",
        "asym = False\n",
        "bits = args.wbits\n",
        "double_groupsize = 32\n",
        "kquant = True if bits == 2 else False\n",
        "v1 = False\n",
        "return_config = True\n",
        "cache_dir = './cache'\n",
        "\n",
        "# تحميل النموذج والمحلل اللغوي\n",
        "model, tokenizer, config = load_llama_model(\n",
        "    model_uri,\n",
        "    cache_dir=cache_dir,\n",
        "    groupsize=args.groupsize,\n",
        "    double_groupsize=double_groupsize,\n",
        "    bits=bits,\n",
        "    half=True,\n",
        "    v1=v1,\n",
        "    asym=asym,\n",
        "    kquant=kquant,\n",
        "    return_config=return_config\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# إعداد فئة LMClass\n",
        "lm = LMClass(model_uri, batch_size=args.batch_size, cache_dir=cache_dir)\n",
        "lm.model = model\n",
        "lm.tokenizer = tokenizer\n",
        "lm.config = config\n",
        "lm.reinitial()\n",
        "\n",
        "print(\"✅ Model loaded successfully. Running inference...\")\n",
        "\n",
        "# تنفيذ الاستدلال (Inference) بسؤال واحد\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids, max_new_tokens=200, temperature=0.7, top_p=0.9, top_k=50\n",
        "    )\n",
        "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"\\n🤖 الإجابة: \", result)\n",
        "\n",
        "# تحرير الذاكرة بعد التشغيل\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "GChsZelROYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "بدون ديالوج"
      ],
      "metadata": {
        "id": "A05F5I47OmSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال بدون حوار بعد تعديل كود yi_harness.py"
      ],
      "metadata": {
        "id": "EWKc6S44Pa9E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqB_MpduPh9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!CUDA_VISIBLE_DEVICES=0 python yi_harness.py -s 6b -b 4 -g 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX8cm4F2OhuL",
        "outputId": "c2385dcc-3fe4-4bf3-bc80-d2ce299ae7d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741915051.408378   29707 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741915051.419398   29707 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1741915051.462981   29707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741915051.463130   29707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741915051.463140   29707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1741915051.463146   29707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "Some weights of LlamaModel were not initialized from the model checkpoint at GreenBitAI/yi-6b-w4a16g32 and are newly initialized: ['layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[0m\u001b[0m\u001b[1m\u001b[33mTotal 3.81 Gib VRAM used.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[33mConverted as Half.\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32mLoaded the model in 9.35 seconds.\u001b[0m\n",
            "\u001b[0mvocab size: \u001b[0m \u001b[0m64000\u001b[0m\n",
            "\u001b[0m✅ Model loaded successfully. Running inference...\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "\u001b[0m\n",
            "🤖 الإجابة: \u001b[0m \u001b[0mWho is Napoleon Bonaparte?\n",
            "Napoleon Bonaparte was a French military leader and emperor who conquered much of Europe in the early 19th century. He was born in Corsica in 1769 and rose to power through military victories and political intrigue. Napoleon is considered one of the greatest military leaders in history, and his campaigns and reforms had a lasting impact on European politics and society.\n",
            "Napoleon Bonaparte was born on August 15, 1769, in Ajaccio, Corsica, to a family of Italian descent. He was the fourth of ten children born to a noble family. Napoleon was educated at military schools and was commissioned as an artillery officer in 1784. He quickly rose through the ranks and was promoted to general in 1796.\n",
            "Napoleon Bonaparte is considered one of the greatest military leaders in history. He is known for his strategic planning, tactical brilliance\u001b[0m\n",
            "\u001b[0m\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "\n",
        "/content/low_bit_llama/model.py\n",
        "\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from colorama import init, Fore, Style\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "init(autoreset=True)\n",
        "\n",
        "class QuantLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, groupsize=-1, double_groupsize=-1, bits=4, v1 = True, asym=True):\n",
        "        super().__init__()\n",
        "\n",
        "        bits=bits\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bits=bits\n",
        "        self.maxq = 2 ** self.bits - 1\n",
        "        groupsize = groupsize if groupsize != -1 else in_features\n",
        "        self.groupsize = groupsize\n",
        "\n",
        "        if double_groupsize==-1:\n",
        "            double_groupsize=out_features\n",
        "\n",
        "        self.asym = asym\n",
        "\n",
        "        self.disable_bias = True\n",
        "        self.initialize(in_features, out_features, groupsize, double_groupsize, bits, v1, asym)\n",
        "\n",
        "    def initialize(self, in_features, out_features, groupsize, double_quantize_groupsize, bits, v1, asym):\n",
        "\n",
        "        if asym:\n",
        "            self.register_buffer('qzeros', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features / 256 * (bits * 8))), dtype=torch.int32))\n",
        "            if bits == 4:\n",
        "                self.register_buffer('qscales', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), double_quantize_groupsize), dtype=torch.uint8))\n",
        "            else:\n",
        "                self.register_buffer('qscales', torch.empty((math.ceil(in_features/groupsize), out_features), dtype=torch.uint8))\n",
        "\n",
        "        else:\n",
        "            self.register_buffer('qstatistic', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), double_quantize_groupsize), dtype=torch.uint8))\n",
        "            self.register_buffer('qzeros_zeros', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), 1), dtype=torch.half))\n",
        "            self.register_buffer('qzeros_scales', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), 1), dtype=torch.half))\n",
        "\n",
        "        if not v1:\n",
        "            self.register_buffer('qscales_zeros', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), 1), dtype=torch.half))\n",
        "            self.register_buffer('qscales_scales', torch.empty((math.ceil(in_features/groupsize), math.ceil(out_features/double_quantize_groupsize), 1), dtype=torch.half))\n",
        "        else:\n",
        "            self.register_buffer('qscales_zeros', torch.empty((1, out_features, 1), dtype=torch.half))\n",
        "            self.register_buffer('qscales_scales', torch.empty((1, out_features, 1), dtype=torch.half))\n",
        "\n",
        "        self.register_buffer('g_idx', torch.tensor([i // groupsize  for i in range(in_features)], dtype=torch.int32))\n",
        "        self.register_buffer('qweight', torch.empty(math.ceil(in_features / 256 * (bits * 8)), out_features, dtype=torch.int32))\n",
        "        self.register_buffer(\"wf\", torch.tensor(list(range(0,32,bits)), dtype=torch.int32).unsqueeze(0))\n",
        "        self.register_buffer('bias', torch.empty(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.bits in [2, 4, 8, 16]:\n",
        "            weight_unpack = torch.bitwise_right_shift(torch.unsqueeze(self.qweight, 1).expand(-1, 32 // self.bits, -1), self.wf.unsqueeze(-1)).to(torch.int16 if self.bits == 8 else torch.int8).view(-1, self.qweight.size(-1))\n",
        "            torch.bitwise_and(weight_unpack,(2 ** self.bits) - 1, out=weight_unpack)\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "        if self.asym:\n",
        "            zeros_unpack = torch.bitwise_right_shift(torch.unsqueeze(self.qzeros, 2).expand(-1, -1, 32 // self.bits), self.wf.unsqueeze(0)).to(torch.int16 if self.bits == 8 else torch.int8)\n",
        "            torch.bitwise_and(zeros_unpack, (2 ** self.bits) - 1, out=zeros_unpack)\n",
        "\n",
        "            zeros_unpack = zeros_unpack + 1\n",
        "            zeros_unpack = zeros_unpack.reshape(-1, self.out_features)\n",
        "            zeros_unpack = zeros_unpack[self.g_idx.long()]\n",
        "\n",
        "            if self.bits == 2:\n",
        "                qscales = self.qscales.unsqueeze(-1)\n",
        "            else:\n",
        "                qscales = self.qscales\n",
        "\n",
        "            scales = ((qscales.to(x.dtype)-self.qscales_zeros)*self.qscales_scales).view(math.ceil(self.in_features/self.groupsize), self.out_features)[self.g_idx.long()]\n",
        "\n",
        "            weight = ((weight_unpack - zeros_unpack)*scales).type(x.dtype)\n",
        "\n",
        "        else:\n",
        "            qstatistic = self.qstatistic.to(torch.uint8)\n",
        "            qscales = (qstatistic & 0xF0) >> 4\n",
        "            qzeros = qstatistic & 0x0F\n",
        "\n",
        "            scales = ((qscales.to(x.dtype)-self.qscales_zeros)*self.qscales_scales).view(math.ceil(self.in_features/self.groupsize), self.out_features)[self.g_idx.long()]\n",
        "            zeros = ((qzeros.to(x.dtype)-self.qzeros_zeros)*self.qzeros_scales).view(math.ceil(self.in_features/self.groupsize), self.out_features)[self.g_idx.long()]\n",
        "\n",
        "            weight = (weight_unpack*scales-zeros).type(x.dtype)\n",
        "\n",
        "        out = torch.matmul(x, weight)\n",
        "\n",
        "        if not self.disable_bias:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "\n",
        "def make_quant(module, names, name='', groupsize=-1, double_groupsize=-1, bits=4, v1=True, asym=True, kquant=False):\n",
        "    if isinstance(module, QuantLinear):\n",
        "        return\n",
        "    for attr in dir(module):\n",
        "        tmp = getattr(module, attr)\n",
        "        name1 = name + '.' + attr if name != '' else attr\n",
        "        if name1 in names:\n",
        "            if kquant and (\"v_proj\" in name1 or \"down_proj\" in name1):\n",
        "                wbits = int(bits*2)\n",
        "                kgroupsize = 32\n",
        "            else:\n",
        "                wbits = bits\n",
        "                kgroupsize = groupsize\n",
        "            setattr(\n",
        "                module, attr, QuantLinear(tmp.in_features, tmp.out_features, groupsize=kgroupsize, double_groupsize=double_groupsize, bits=wbits, v1=v1, asym=asym)\n",
        "            )\n",
        "    for name1, child in module.named_children():\n",
        "        make_quant(child, names, name + '.' + name1 if name != '' else name1, groupsize=groupsize, double_groupsize=double_groupsize, bits=bits, v1=v1, asym=asym, kquant=kquant)\n",
        "\n",
        "\n",
        "def model_to_half(model):\n",
        "    model.half()\n",
        "    for n, m in model.named_modules():\n",
        "        if isinstance(m, QuantLinear):\n",
        "            m.qscales_scales = m.qscales_scales.half()\n",
        "            m.qscales_zeros = m.qscales_zeros.half()\n",
        "            m.bias = m.bias.half()\n",
        "    print(Style.BRIGHT + Fore.YELLOW + 'Converted as Half.')\n",
        "\n",
        "\n",
        "def find_layers(module, layers=[nn.Conv2d, nn.Linear], name=''):\n",
        "    if type(module) in layers:\n",
        "        return {name: module}\n",
        "    res = {}\n",
        "    for name1, child in module.named_children():\n",
        "        res.update(find_layers(\n",
        "            child, layers=layers, name=name + '.' + name1 if name != '' else name1\n",
        "        ))\n",
        "    return res\n",
        "\n",
        "\n",
        "def load_llama_model(model_uri, cache_dir, groupsize=-1, double_groupsize=-1, bits=4, half=False, v1=True, asym=False, device_map=\"auto\", seqlen=2048, kquant=False, return_config=False):\n",
        "    import accelerate\n",
        "    from transformers import LlamaConfig, AutoConfig, AutoModel, AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
        "    from transformers.utils.hub import cached_file\n",
        "    print(Style.BRIGHT + Fore.CYAN + \"Loading Model ...\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    with accelerate.init_empty_weights():\n",
        "        config = AutoConfig.from_pretrained(model_uri, cache_dir=cache_dir)\n",
        "        model = AutoModelForCausalLM.from_config(config)\n",
        "        _ = AutoModel.from_pretrained(model_uri, torch_dtype=torch.float16, cache_dir=cache_dir, trust_remote_code=False)\n",
        "        model_path = os.path.join(cache_dir, \"models--\" + model_uri.replace(\"/\", \"--\"), \"snapshots/\")\n",
        "        subdirectories = [d for d in os.listdir(model_path) if os.path.isdir(os.path.join(model_path, d))]\n",
        "        model_path = os.path.join(model_path, subdirectories[0])\n",
        "\n",
        "        model = model.eval()\n",
        "        for i, layer in enumerate(model.model.layers):\n",
        "            layers = find_layers(layer)\n",
        "            for name in ['lm_head']:\n",
        "                if name in layers:\n",
        "                    del layers[name]\n",
        "                if kquant and (bits == 2) and (i >=len(model.model.layers)-3):\n",
        "                    r_kquant=True\n",
        "                else:\n",
        "                    r_kquant=False\n",
        "                make_quant(layer, layers, groupsize=groupsize, double_groupsize=double_groupsize, bits=bits, v1=v1, asym=asym, kquant=r_kquant)\n",
        "\n",
        "    model = accelerate.load_checkpoint_and_dispatch(\n",
        "        model=model,\n",
        "        checkpoint=model_path,\n",
        "        device_map=device_map,\n",
        "        no_split_module_classes=[\"LlamaDecoderLayer\"]\n",
        "    )\n",
        "\n",
        "    print(Style.BRIGHT + Fore.YELLOW + 'Total {:.2f} Gib VRAM used.'.format(torch.cuda.memory_allocated() / 1024 / 1024 / 1024))\n",
        "\n",
        "    model.seqlen = seqlen\n",
        "\n",
        "    if half:\n",
        "        model_to_half(model)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_uri, cache_dir=cache_dir, use_fast=False, trust_remote_code=True)\n",
        "\n",
        "    print(Style.BRIGHT + Fore.GREEN + f\"Loaded the model in {(time.time()-t0):.2f} seconds.\")\n",
        "\n",
        "    if return_config:\n",
        "        return model, tokenizer, config\n",
        "    else:\n",
        "        return model, tokenizer\n",
        "\n",
        "def load_llama_model_lora(model_uri, lora_uri, cache_dir, bits = 32, groupsize=-1, device_map=\"auto\", seqlen=2048, max_memory=None):\n",
        "    import accelerate\n",
        "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
        "\n",
        "    if max_memory is None:\n",
        "        max_memory = {0: '24Gib', 'cpu': '48Gib'}\n",
        "\n",
        "    print(Style.BRIGHT + Fore.CYAN + \"Loading Model ...\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    with accelerate.init_empty_weights():\n",
        "        config = LlamaConfig.from_pretrained(model_uri, cache_dir=cache_dir)\n",
        "        model = LlamaForCausalLM(config)\n",
        "        model = model.eval()\n",
        "        layers = find_layers(model)\n",
        "        for name in ['lm_head']:\n",
        "            if name in layers:\n",
        "                del layers[name]\n",
        "        make_quant(model, layers, groupsize=groupsize, bits = bits)\n",
        "\n",
        "    accelerate.load_checkpoint_in_model(\n",
        "        model,\n",
        "        checkpoint=hf_hub_download(repo_id=model_uri, filename=\"pytorch_model.bin\", cache_dir=cache_dir),\n",
        "        device_map={'': 'cpu'}\n",
        "    )\n",
        "\n",
        "    model.seqlen = seqlen\n",
        "    # rotary_emb fix\n",
        "    for n, m in model.named_modules():\n",
        "        if 'rotary_emb' in n:\n",
        "            cos_cached = m.cos_cached.clone().cpu()\n",
        "            sin_cached = m.sin_cached.clone().cpu()\n",
        "            break\n",
        "\n",
        "    from peft import PeftModel\n",
        "    from peft_tuners_lora import LinearLowbitLt\n",
        "\n",
        "    _ = hf_hub_download(repo_id=lora_uri, filename=\"adapter_config.json\", cache_dir=cache_dir)\n",
        "    lora_model = hf_hub_download(repo_id=lora_uri, filename=\"adapter_model.bin\", cache_dir=cache_dir)\n",
        "    lora_path = Path(lora_model).parent\n",
        "\n",
        "    model = PeftModel.from_pretrained(model, lora_path, device_map={'': 'cpu'}, torch_dtype=torch.float32, is_trainable=True)\n",
        "    print(Style.BRIGHT + Fore.GREEN + '{} Lora Applied.'.format(lora_path))\n",
        "\n",
        "    model.seqlen = seqlen\n",
        "\n",
        "    print('Apply half ...')\n",
        "    for n, m in model.named_modules():\n",
        "        if isinstance(m, QuantLinear) or ((lora_path is not None) and isinstance(m, LinearLowbitLt)):\n",
        "            m.qscales_scales=m.qscales_scales.half()\n",
        "            m.qscales_zeros=m.qscales_zeros.half()\n",
        "            if m.bias is not None:\n",
        "                m.bias = m.bias.half()\n",
        "\n",
        "    print('Dispatching model ...')\n",
        "    device_map = accelerate.infer_auto_device_map(model, max_memory=max_memory, no_split_module_classes=[\"LlamaDecoderLayer\"])\n",
        "    model = accelerate.dispatch_model(model, device_map=device_map, offload_buffers=True, main_device=0)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(Style.BRIGHT + Fore.YELLOW + 'Total {:.2f} Gib VRAM used.'.format(torch.cuda.memory_allocated() / 1024 / 1024))\n",
        "\n",
        "    # rotary_emb fix\n",
        "    for n, m in model.named_modules():\n",
        "        if 'rotary_emb' in n:\n",
        "            if getattr(m, '_hf_hook', None):\n",
        "                if isinstance(m._hf_hook, accelerate.hooks.SequentialHook):\n",
        "                    hooks = m._hf_hook.hooks\n",
        "                else:\n",
        "                    hooks = [m._hf_hook]\n",
        "                for hook in hooks:\n",
        "                    if hook.offload:\n",
        "                        if n + '.sin_cached' not in hook.weights_map.dataset.state_dict.keys():\n",
        "                            hook.weights_map.dataset.state_dict[n + '.sin_cached'] = sin_cached.clone().cpu()\n",
        "                            hook.weights_map.dataset.state_dict[n + '.cos_cached'] = cos_cached.clone().cpu()\n",
        "\n",
        "    tokenizer = LlamaTokenizer.from_pretrained(model_uri, cache_dir=cache_dir)\n",
        "    tokenizer.truncation_side = 'left'\n",
        "\n",
        "    print(Style.BRIGHT + Fore.GREEN + f\"Loaded the model in {(time.time()-t0):.2f} seconds.\")\n",
        "\n",
        "    return model, tokenizer\n"
      ],
      "metadata": {
        "id": "ds2BHB6-Oivj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "شغال\n",
        "/content/low_bit_llama/evaluate.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tqdm\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_eval(model, testenc, dev = torch.device('cuda:0')):\n",
        "    print('Evaluating ...')\n",
        "    model.to(dev)\n",
        "    testenc = testenc.input_ids\n",
        "    nsamples = testenc.numel() // model.seqlen\n",
        "\n",
        "    use_cache = model.config.use_cache\n",
        "    model.config.use_cache = False\n",
        "    layers = model.model.layers\n",
        "\n",
        "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
        "    layers[0] = layers[0].to(dev)\n",
        "\n",
        "    dtype = next(iter(model.parameters())).dtype\n",
        "    inps = torch.zeros((nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev)\n",
        "    cache = {'i': 0, 'attention_mask': None}\n",
        "\n",
        "    class Catcher(nn.Module):\n",
        "\n",
        "        def __init__(self, module):\n",
        "            super().__init__()\n",
        "            self.module = module\n",
        "\n",
        "        def forward(self, inp, **kwargs):\n",
        "            inps[cache['i']] = inp\n",
        "            cache['i'] += 1\n",
        "            cache['attention_mask'] = kwargs['attention_mask']\n",
        "            cache['position_ids'] = kwargs['position_ids']\n",
        "            raise ValueError\n",
        "\n",
        "    layers[0] = Catcher(layers[0])\n",
        "    for i in range(nsamples):\n",
        "        batch = testenc[:, (i * model.seqlen):((i + 1) * model.seqlen)].to(dev)\n",
        "        try:\n",
        "            model(batch)\n",
        "        except ValueError:\n",
        "            pass\n",
        "    layers[0] = layers[0].module\n",
        "\n",
        "    layers[0] = layers[0].cpu()\n",
        "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outs = torch.zeros_like(inps)\n",
        "    attention_mask = cache['attention_mask']\n",
        "    position_ids = cache['position_ids']\n",
        "\n",
        "    for i in tqdm.tqdm(range(len(layers))):\n",
        "        # print(i, end=\" \")\n",
        "        layer = layers[i].cpu()\n",
        "        layer = layer.to(dev)\n",
        "        for j in range(nsamples):\n",
        "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, position_ids=position_ids)[0]\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        torch.cuda.empty_cache()\n",
        "        inps, outs = outs, inps\n",
        "    # print(\".\")\n",
        "\n",
        "    if model.model.norm is not None:\n",
        "        model.model.norm = model.model.norm.to(dev)\n",
        "    model.lm_head = model.lm_head.to(dev)\n",
        "\n",
        "    testenc = testenc.to(dev)\n",
        "    nlls = []\n",
        "    for i in range(nsamples):\n",
        "        hidden_states = inps[i].unsqueeze(0)\n",
        "        if model.model.norm is not None:\n",
        "            hidden_states = model.model.norm(hidden_states)\n",
        "        lm_logits = model.lm_head(hidden_states)\n",
        "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
        "        shift_labels = testenc[:, (i * model.seqlen):((i + 1) * model.seqlen)][:, 1:]\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "        neg_log_likelihood = loss.float() * model.seqlen\n",
        "        nlls.append(neg_log_likelihood)\n",
        "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
        "    print(ppl.item())\n",
        "\n",
        "    model.config.use_cache = use_cache\n"
      ],
      "metadata": {
        "id": "LJ1Bo798O3F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "شغال\n",
        "/content/low_bit_llama/datautils.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import LlamaTokenizer, AutoTokenizer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "\n",
        "\n",
        "def get_wikitext2(nsamples, seed, seqlen, model, cache_dir, tokenizer):\n",
        "    from datasets import load_dataset\n",
        "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train', cache_dir=cache_dir)\n",
        "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test', cache_dir=cache_dir)\n",
        "\n",
        "    if tokenizer is None:\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(model, cache_dir=cache_dir)\n",
        "    else:\n",
        "        pass\n",
        "    trainenc = tokenizer(\"\\n\\n\".join(traindata['text']), return_tensors='pt')\n",
        "    testenc = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt')\n",
        "\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "\n",
        "def get_ptb(nsamples, seed, seqlen, model, cache_dir, tokenizer):\n",
        "    from datasets import load_dataset\n",
        "    traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train', cache_dir=cache_dir)\n",
        "    valdata = load_dataset('ptb_text_only', 'penn_treebank', split='validation', cache_dir=cache_dir)\n",
        "    if tokenizer is None:\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(model, cache_dir=cache_dir)\n",
        "    else:\n",
        "        pass\n",
        "    trainenc = tokenizer(\"\\n\\n\".join(traindata['sentence']), return_tensors='pt')\n",
        "    testenc = tokenizer(\"\\n\\n\".join(valdata['sentence']), return_tensors='pt')\n",
        "\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "\n",
        "def get_c4(nsamples, seed, seqlen, model, cache_dir, tokenizer):\n",
        "    from datasets import load_dataset\n",
        "    traindata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'train': 'en/c4-train.00000-of-01024.json.gz'}, split='train', cache_dir=cache_dir\n",
        "    )\n",
        "    valdata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'validation': 'en/c4-validation.00000-of-00008.json.gz'}, split='validation', cache_dir=cache_dir\n",
        "    )\n",
        "    if tokenizer is None:\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(model, cache_dir=cache_dir)\n",
        "    else:\n",
        "        pass\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        while True:\n",
        "            i = random.randint(0, len(traindata) - 1)\n",
        "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
        "            if trainenc.input_ids.shape[1] >= seqlen:\n",
        "                break\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "\n",
        "    import random\n",
        "    random.seed(0)\n",
        "    valenc = []\n",
        "    for _ in range(256):\n",
        "        while True:\n",
        "            i = random.randint(0, len(valdata) - 1)\n",
        "            tmp = tokenizer(valdata[i]['text'], return_tensors='pt')\n",
        "            if tmp.input_ids.shape[1] >= seqlen:\n",
        "                break\n",
        "        i = random.randint(0, tmp.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        valenc.append(tmp.input_ids[:, i:j])\n",
        "    valenc = torch.hstack(valenc)\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, input_ids):\n",
        "            self.input_ids = input_ids\n",
        "    valenc = TokenizerWrapper(valenc)\n",
        "\n",
        "    return trainloader, valenc\n",
        "\n",
        "\n",
        "def get_loaders(name, nsamples=128, seed=0, seqlen=2048, model='', cache_dir='cache', tokenizer=None):\n",
        "    if 'wikitext2' in name:\n",
        "        return get_wikitext2(nsamples, seed, seqlen, model, cache_dir, tokenizer)\n",
        "    if 'ptb' in name:\n",
        "        return get_ptb(nsamples, seed, seqlen, model, cache_dir, tokenizer)\n",
        "    if 'c4' in name:\n",
        "        return get_c4(nsamples, seed, seqlen, model, cache_dir, tokenizer)\n"
      ],
      "metadata": {
        "id": "GTPvXUY_O9Z6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}